%&latex
\documentclass[a4paper]{article}

\usepackage[a4paper,margin=1in]{geometry}
\usepackage[affil-it]{authblk}
\usepackage{cite}
\usepackage[unicode]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{commath}

\newcommand{\Co}[1]{}
% operators that are separated from the operand by a space
\DeclareMathOperator{\Sgn}{sgn}
\DeclareMathOperator{\Supp}{supp}
\DeclareMathOperator{\Dom}{dom}
\DeclareMathOperator{\Sp}{span}
% autosize delimiters
\newcommand{\AP}[1]{\left(#1\right)}
\newcommand{\AB}[1]{\left[#1\right]}
\newcommand{\AC}[1]{\left\{#1\right\}}
\newcommand{\APM}[2]{\left(#1\;\middle\vert\;#2\right)}
\newcommand{\ABM}[2]{\left[#1\;\middle\vert\;#2\right]}
\newcommand{\ACM}[2]{\left\{#1\;\middle\vert\;#2\right\}}
% probability theory
\newcommand{\Pa}[2]{\underset{#1}{\operatorname{Pr}}\AB{#2}}
\newcommand{\CP}[3]{\underset{#1}{\operatorname{Pr}}\ABM{#2}{#3}}
\newcommand{\PP}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{Pr}}}
\newcommand{\PPP}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{Pr}}}
\newcommand{\E}[1]{\underset{#1}{\operatorname{E}}}
\newcommand{\Ea}[2]{\underset{#1}{\operatorname{E}}\AB{#2}}
\newcommand{\CE}[3]{\underset{#1}{\operatorname{E}}\ABM{#2}{#3}}
\newcommand{\EE}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{E}}}
\newcommand{\EEE}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{E}}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\I}[1]{\underset{#1}{\operatorname{I}}}
\newcommand{\CI}[3]{\underset{#1}{\operatorname{I}}\ABM{#2}{#3}}
\newcommand{\Ia}[2]{\underset{#1}{\operatorname{I}}\AB{#2}}
\newcommand{\II}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{I}}}
\newcommand{\III}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{I}}}
\newcommand{\KL}[2]{\operatorname{D}_{\mathrm{KL}}\AP{#1\middle\vert\middle\vert#2}}
\newcommand{\RD}[3]{\operatorname{D}_{#1}\AP{#2\middle\vert\middle\vert#3}}
\newcommand{\Dtv}{\operatorname{d}_{\text{tv}}}
\newcommand{\Dtva}[1]{\operatorname{d}_{\text{tv}}\AP{#1}}
\newcommand{\En}{\operatorname{H}}
\newcommand{\Ena}[1]{\operatorname{H}\AP{#1}}
% power set
\newcommand{\PS}[1]{\mathcal{P}\AP{#1}}
% differential
\newcommand{\D}{\mathrm{d}}
% arg
\newcommand{\Argmin}[1]{\underset{#1}{\operatorname{arg\,min}}\,}
\newcommand{\Argmax}[1]{\underset{#1}{\operatorname{arg\,max}}\,}
% numbers
\newcommand{\Nats}{\mathbb{N}}
\newcommand{\Ints}{\mathbb{Z}}
\newcommand{\Rats}{\mathbb{Q}}
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\Coms}{\mathbb{C}}
% linear algebra
\newcommand{\PD}{\mathrm{PD}}
\newcommand{\PSD}{\mathrm{PSD}}
% empty string
\newcommand{\Estr}{\boldsymbol{\lambda}}
% limits
\newcommand{\Lim}[1]{\lim_{#1 \rightarrow \infty}}
\newcommand{\LimInf}[1]{\liminf_{#1 \rightarrow \infty}}
\newcommand{\LimSup}[1]{\limsup_{#1 \rightarrow \infty}}
% more delimiters
\newcommand{\Abs}[1]{\left\vert #1 \right\vert}
\newcommand{\Norm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\Floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\Ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\Chev}[1]{\left\langle #1 \right\rangle}
\newcommand{\Quote}[1]{\left\ulcorner #1 \right\urcorner}
% arrows
\newcommand{\K}{\xrightarrow{\mathrm{k}}}
\newcommand{\PF}{\xrightarrow{\circ}}
% Paper specific
\newcommand{\B}{B}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\St}{\mathcal{S}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\El}{\mathrm{L}}
\newcommand{\Hy}{\mathcal{H}}
\DeclareMathOperator{\RVO}{\dim_{RVO}}
\DeclareMathOperator{\MB}{\dim_{MB}}
\DeclareMathOperator{\LD}{\dim_{loc}}
\newcommand{\DRVO}{D_{\mathrm{RVO}}}
\newcommand{\DMB}{D_{\mathrm{MB}}}
\newcommand{\DL}{D_{\mathrm{loc}}}
\newcommand{\N}{\mathrm{N}}
\newcommand{\V}{\mathrm{V}}
\newcommand{\Q}{\mathrm{Q}}
\newcommand{\EU}{\mathrm{EU}}
\newcommand{\Reg}{\mathrm{R}}
\newcommand{\PSR}{\text{PS}}
\newcommand{\LS}{\mathrm{LS}}
\newcommand{\CS}{\mathrm{CS}}
\newcommand{\W}{\mathrm{W}}
\newcommand{\AT}{\mathrm{A}}
\newcommand{\THy}{\mathrm{H}_*}
\newcommand{\SHy}{\mathrm{H}}
\newcommand{\Ev}{\mathcal{E}}
\newcommand{\De}{\Delta}
\newcommand{\CSE}{G}

\begin{document}

\textbf{TLDR:}\Co{b} I derive a variant of the RL regret bound by [Osband and Van Roy (2014)](https://arxiv.org/abs/1406.1853), that applies to learning without resets of environments without traps. The advantage of this regret bound over those known in the literature, is that it scales with certain learning-theoretic dimensions rather than number of states and actions. My goal is building on this result to derive this type of regret bound for [DRL](https://agentfoundations.org/item?id=1656), and, later on, other settings interesting from an AI\ alignment perspective.

***

[Previously](https://www.alignmentforum.org/posts/zTf946PQwN2AN3X3Y/entropic-regret-i-deterministic-mdps) I derived a regret bound for \textit{deterministic}\Co{i} environments that scales with prior entropy and "prediction dimension". That bound behaves as $O\AP{\sqrt{1-\gamma}}$ in the episodic setting but only as $O\AP{\sqrt[3]{1-\gamma}}$ in the setting without resets. Moreover, my attempts to generalize the result to stochastic environments led to bounds that are \textit{even weaker}\Co{i} (have a lower exponent). Therefore, I decided to put that line of attack on hold, and use Osband and Van Roy's technique instead, leading to an $O\AP{\sqrt{1-\gamma}}$ bound in the stochastic setting without resets. This bound doesn't scale down with the entropy of the prior, but this does not seem as important as dependence on $\gamma$.

\begin{Huge}Results\end{Huge}

[Russo and Van Roy](https://papers.nips.cc/paper/4909-eluder-dimension-and-the-sample-complexity-of-optimistic-exploration) introduced the concept of "eluder dimension"  for the benefit of the multi-armed bandit setting, and Osband and Van Roy extended it to a form suitable for studying reinforcement learning. We will consider the following, slightly modified version of their definition.

Given a real vector space $\Y$, we will use $\PSD(\Y)$ to denote the set of positive semidefinite bilinear forms on $\Y$ and $\PD(\Y)$ to denote the set of positive definite bilinear forms on $\Y$. Given a bilinear form $\B:\Y\times\Y\rightarrow\Reals$, we will slightly abuse notation by also regarding it as a linear functional $\B:\Y\otimes\Y\rightarrow\Reals$. Thereby, we have $\B(v \otimes w) = \B(v, w)$ and $\B v^{\otimes 2}=\B (v,v)$. Also, if $\Y$ is finite-dimensional and $\B$ is non-degenerate, we will denote $\B ^{-1}:\Y^*\times\Y^*\rightarrow\Reals$ the unique bilinear form which satisfies

$$\forall v\in\Y,\alpha\in\Y^*:\AP{\forall\beta\in\Y^*:\B ^{-1}(\alpha,\beta)=\beta v}\iff\AP{\forall w\in\Y:\B (v,w)=\alpha w}$$ 

\textbf{Definition 1}\Co{b}

\textit{Consider a set $\X$, a real vector space $\Y$, some $\F\subseteq\AC{\X\rightarrow\Y}$ and a family $\AC{\B _x\in\PSD(\Y)}_{x\in\X}$. Consider also $n\in\Nats$, a sequence $\AC{x_k\in\X}_{k\in[n]}$ and $x^*\in\X$. $x^*$ is said to be} $\AP{\F,\B }$-dependant on $\AC{x_k}$ \textit{when, for any $f,\tilde{f}\in\F$}\Co{i}

$$\sum_{k=0}^{n-1}\B _{x_k}\AP{f\AP{x_k}-\tilde{f}\AP{x_k}}^{\otimes 2}\leq1\implies \B _{x^*}\AP{f\AP{x^*}-\tilde{f}\AP{x^*}}^{\otimes 2}\leq1$$

\textit{Otherwise, $x^*$ is said to be}\Co{i} $\AP{\F,\B }$-independent of $\AC{x_k}$.

\textbf{Definition 2}\Co{b}

\textit{Consider a set $\X$, a real vector space $\Y$ and some $\F\subseteq\AC{\X\rightarrow\Y}$. The}\Co{i} Russo-Van Roy-Osband dimension (RVO dimension) $\RVO{\F}$ \textit{is the supremum of the set of $n\in\Nats$ for which there is $\AC{x_k\in\X}_{k\in[n]}$ and $\B $ s.t. for all $m\in[n]$, $x_m$ is $\AP{\F,\B }$-independent of $\AC{x_k\in\X}_{k\in[m]}$.}\Co{i}

We have the following basic bounds on RVO dimension.

\textbf{Proposition 1}\Co{b}

\textit{Consider a set $\X$, a real vector space $\Y$ and some $\F\subseteq\AC{\X\rightarrow\Y}$. Then}\Co{i}

$$\RVO{\F}\leq\Abs{\X}$$

\textbf{Proposition 2}\Co{b}

\textit{Consider a set $\X$, a real vector space $\Y$ and some $\F\subseteq\AC{\X\rightarrow\Y}$. Then}\Co{i}

$$\RVO{\F}\leq\frac{\Abs{\F}\AP{\Abs{\F}-1}}{2}$$

Another concept we need to formulate the regret bound is the Minkowski–Bouligand dimension.

\textbf{Definition 3}\Co{b}

\textit{Consider a set $\X$, a real vector space $\Y$, some $\F\subseteq\AC{\X\rightarrow\Y}$ and a family $\AC{\B _x\in\PSD(\Y)}_{x\in\X}$. A set $A\subseteq\F$ is said to be a}\Co{i} $\B $-covering of $\F$ \textit{when}\Co{i}

$$\forall f\in\F\exists\tilde{f}\in A: \sup_{x\in\X}{\B _x\AP{f(x)-\tilde{f}(x)}^{\otimes 2}}<1$$

\textbf{Definition 4}\Co{b}

\textit{Consider a set $\X$, a real vector space $\Y$, some $\F\subseteq\AC{\X\rightarrow\Y}$ and a family $\AC{\B _x\in\PSD(\Y)}_{x\in\X}$. The}\Co{i} covering number $\N(\F,\B )$ \textit{is the infimum of the set of $n\in\Nats$ for which there is a $\B $-covering of $\F$ of size $n$.}\Co{i}

\textbf{Definition 5}\Co{b}

\textit{Consider a finite set $\X$, a finite-dimensional real vector product space $\Y$ and some $\F\subseteq\AC{\X\rightarrow\Y}$. Fix any $\AC{\B \in\PD(\Y)}_{x\in\X}$.  The}\Co{i} Minkowski–Bouligand dimension (MB dimension) of $\F$ \textit{is defined by}\Co{i}

$$\MB{\F}:=\limsup_{\epsilon \rightarrow 0}{\frac{\ln{\N\AP{\F,\epsilon^{-2} \B }}}{\ln\frac{1}{\epsilon}}}$$

It is easy to see the above is indeed well-defined, i.e. doesn't depend on the choice of $\B $. This is because given any $\B ,\tilde{\B }$, there are constants $c_1,c_2\in\Reals^+$ s.t. for all $\F$ and $\epsilon$

$$c_1 \N\AP{\F,\epsilon^{-2} \B } \leq \N\AP{\F,\epsilon^{-2} \tilde{\B }} \leq c_2\N\AP{\F,\epsilon^{-2} \B }$$

For finite $\F$ and $\epsilon\ll1$, it's obvious that $\N\AP{\F,\epsilon^{-2}\B }=\Abs{\F}$, and in particular $\MB\F=0$. It is also possible to show that, for any $\F$, $\MB{\F}\leq\Abs{\X}\dim{\Y}$.

Note that, in general, MB dimension is fractional.

We will need yet another (but rather simple) notion of "dimension".

\textbf{Definition 6}\Co{b}

\textit{Consider a set $\X$, a vector space $\Y$ and some $\F\subseteq\AC{\X\rightarrow\Y}$. The}\Co{i} local dimension of $\F$ \textit{is defined by}\Co{i}

$$\LD{\F}:=\max_{x\in\X}{\dim\Sp\ACM{f(x)}{f\in\F}}$$

Obviously $\LD{\F}\leq\Abs{\F}$ and $\LD{\F}\leq\dim{\Y}$.

Consider finite non-empty sets $\St$ (states) and $\A$ (actions). Observe that $\Delta\St$ can be regarded as a subset of the vector space $\Reals^\St$. This allows us to speak of the RVO, MB and local dimensions of a hypothesis class of transition kernels $\Hy\subseteq\AC{\St\times\A\K\St}$ (that is, in this case $\X=\St\times\A$ and $\Y=\Reals^\St$). 

\Co{Finally, there is a certain regularity condition in our main theorem that depends on the following parameters of MDPs.

\textbf{Definition 7}\Co{b}

\textit{Consider finite non-empty sets $\St$ and $\A$, $\R:\St\rightarrow[0,1]$ (reward function) and $\T:\St\times\A\K\St$ (transition kernel). The value function $\V_{\T\R}(s,\gamma)$ is always continuous and piecewise differentiable w.r.t. $\gamma$. Let $\partial_+\V_{\T\R}(s,\gamma)$ and $\partial_-\V_{\T\R}(s,\gamma)$ denote its right and left derivative respectively. We denote}\Co{i}

$$\partial_{\max}\V_{\T\R}(s,\gamma):=\sup_{x\in(\gamma,1)}{\partial_+\V_{\T\R}(s,x)}$$

$$\partial_{\min}\V_{\T\R}(s,\gamma):=\inf_{x\in(\gamma,1)}{\partial_-\V_{\T\R}(s,x)}$$

Note that, since $\V_{\T\R}(s,\gamma)$ is the maximum of a finite set of differentiable functions (the value functions corresponding to the deterministic stationary policies $\St\rightarrow\A$), we have $\partial_+\V_{\T\R}(s,\gamma)\geq\partial_-\V_{\T\R}(s,\gamma)$.}

We can now formulate the regret bound.

\textbf{Theorem 1}\Co{b}

\textit{There is some $C\in\Reals^+$ s.t. the following holds.}\Co{i}

\textit{Consider any finite non-empty sets $\St$ and $\A$, $\R:\St\rightarrow[0,1]$, closed set $\Hy\subseteq\AC{\St\times\A\K\St}$ and Borel probability measure $\zeta$ on $\Hy$ (prior). We define the maximal bias span $\tau_{\zeta\R}$ by}\Co{i}

$$\tau_{\zeta\R}:=\limsup_{\gamma\rightarrow1}{\max_{\T\in\Hy}\frac{\max_{s\in\St}\V_{\T\R}(s,\gamma)-\min_{s\in\St}\V_{\T\R}(s,\gamma)}{1-\gamma}}$$

\textit{Denote $\DL:=\LD{\Hy}$, $\DMB:=\MB{\Hy}$ and $\DRVO:=\RVO{\Hy}$. Then, there is a family of policies $\AC{\pi^\dagger_\gamma:\St^*\times\St\K\A}_{\gamma\in(0,1)}$ s.t.}\Co{i}

$$\limsup_{\gamma \rightarrow 1}\frac{\Ea{\T\sim\zeta}{\EU^*_{\T\R}(\gamma)-\EU^{\pi^\dagger_\gamma}_{\T\R}(\gamma)}}{\tau_{\zeta\R}\DL\sqrt{\AP{\DMB+1}\DRVO(1-\gamma)\ln{\frac{1}{1-\gamma}}}}\leq C$$

Here (like in previous essays), $\V_{\T\R}(s,\gamma)$ is the value function for transition kernel $\T$, reward function $\R$, state $s$ and geometric time discount parameter $\gamma$; $\EU^{\pi}_{\T\R}(\gamma)$ is the expected utility for policy $\pi$; $\EU^*_{\T\R}(\gamma)$ is the maximal expected utility over policies. The expression in the numerator is, thereby, the Bayesian regret.

The implicit condition $\tau_{\zeta\R}<\infty$ implies that for any $\T\in\Hy$ and $s,s'\in\St$, $\V_{\T\R}^0(s)=\V_{\T\R}^0\AP{s'}$. This is a no-traps condition stronger than the condition $\A^0_{\T\R}(s) = \A$ we used before: not only that long-term value cannot be lost \textit{in expectation}\Co{i}, it cannot be lost at all. For any \textit{finite}\Co{i} $\Hy$ satisfying this no-traps condition, we have

$$\tau_{\zeta\R}=\max_{\T\in\Hy}\AP{\max_{s\in\St}{\V^1_{\T\R}(s)}-\min_{s\in\St}{\V^1_{\T\R}(s)}}<\infty$$

A few directions for improving on this result:

* It is not hard to see from the proof that it is also possible to write down a concrete bound for fixed $\gamma$ (rather than considering the $\gamma\rightarrow 1$ limit), but its form is somewhat convoluted.

* It is probably possible to get an *anytime* policy with this form of regret, using PSRL with \textit{dynamic}\Co{i} episode duration.

* It is interesting to try to make do with the weaker no-traps condition $\A^0_{\T\R}(s) = \A$, especially since a stronger no-traps conditions would translate to a stronger condition on the advisor in DRL.

* It is interesting to study RVO dimension in more detail. For example, I'm not even sure whether Proposition 2 is the best possible bound in terms of $\Abs{\F}$ or it's e.g. possible to get a linear bound.

* Like I said in the start, I was unable to derive a satisfactory "entropic" regret bound using RVO dimension. However, at the time I did not try to use local dimension: its significance only became apparent to me when working on the current approach.

* It seems tempting to generalize local dimension by allowing the values of $f(x)$ to lie on some \textit{nonlinear} manifold of given dimension for any given $x$. This approach, if workable, might require a substantially more difficult proof.

* The "cellular decision processes" discussed [previously](https://www.alignmentforum.org/posts/zTf946PQwN2AN3X3Y/entropic-regret-i-deterministic-mdps) in "Proposition 3" have exponentially high local dimension, meaning that this regret bound is ineffective for them. We can consider a variant in which, on every time step, only one cell or a very small number of cells (possibly chosen randomly) change. This would have low local dimension. One way to interpret it is, as a continuous time process in which each cell has a certain *rate* of changing its state.

\begin{Huge}Proofs\end{Huge}

\textbf{Proof of Proposition 1}\Co{b}

TBD \textbf{Q.E.D.}\Co{b}

\textbf{Proof of Proposition 2}\Co{b}

TBD \textbf{Q.E.D.}\Co{b} % graph must be a tree

Given a measurable space $X$, some $\mu,\nu\in\Delta X$ and measurable function $f:X\rightarrow\Reals$, we will use the notation

$$\Ea{x\sim\mu-\nu}{f(x)}:=\Ea{x\sim\mu}{f(x)}-\Ea{x\sim\nu}{f(x)}$$

Given finite sets $\St,\A$, some $\T:\St\times\A\K\St$ and $\pi:\St\rightarrow\A$, we will use the notation $\T\pi:\St\K\St$ defined by

$$\T\pi(s):=\T\AP{s,\pi(s)}$$

\textbf{Proposition A.N1}\Co{b}

\textit{In the setting of Theorem 1, fix $T\in\Nats^+$ and $\gamma\in(0,1)$. Let $\Pi:\Hy\times\St\rightarrow\A$ be a Borel measurable mapping s.t. $\Pi(\T)$ is an optimal policy, i.e.}\Co{i}

$$\EU^{\Pi(\T)}_{\T\R}(\gamma)=\EU^{*}_{\T\R}(\gamma)$$

\textit{Let $\pi_{\zeta\Pi T}^{\PSR}: \St^*\times\St\K\A$ be the policy implemented by a PSRL algorithm with prior $\zeta$ and episode length $T$, s.t. whenever hypothesis $\T$ is sampled, policy $\Pi(\T)$ is followed. Denote the Bayesian regret by}\Co{i}

$$\Reg(\gamma):=\Ea{\T\sim\zeta}{\EU^*_{\T\R}(\gamma)-\EU^{\pi_{\zeta\Pi T}^{\PSR}}_{\T\R}(\gamma)}$$

\textit{Let $(\Omega,P)$ be a probability space governing both the uncertainty about the true hypothesis, the stochastic behavior of the environment and the random sampling inside the algorithm.}\Co{i} [See the proof of "Lemma 1" in [this](https://www.alignmentforum.org/posts/zTf946PQwN2AN3X3Y/entropic-regret-i-deterministic-mdps) previous essay or the proof of "Theorem 1" in [another](https://agentfoundations.org/item?id=1739) previous essay.]\textit{ Furthermore, let $\THy:\Omega\rightarrow\Hy$ be a random variable representing the true hypothesis, $\AC{\SHy_n:\Omega\rightarrow\Hy}_{n\in\Nats}$ be the random variables s.t. $\SHy_n$ represents the hypothesis sampled at time $n$ (i.e. during episode number $\Floor{n/T}$), $\AC{\Theta_n:\Omega\rightarrow\St}_{n\in\Nats}$ be random variables s.t. $\Theta_n$ represents the state at time $n$ and $\AC{\AT_n:\Omega\rightarrow\A}_{n\in\Nats}$ be random variables s.t. $\AT_n$ represents the action taken at time $n$. Denote $\Ev_n:=\SHy_*\Pi\AP{\SHy_n}$ and $\bar{\Ev}_n:=\SHy_{n}\Pi\AP{\SHy_*}$. Then}\Co{i}

$$\Reg(\gamma)=\sum_{n=0}^\infty\gamma^{n}\Ea{}{\Ea{\SHy_n\AP{\Theta_n,\AT_n}-\THy\AP{\Theta_n,\AT_n}}{\V_{\SHy_n\R}(\gamma)}}+\sum_{l=0}^\infty{\gamma^{lT}}\Ea{}{\Ea{\Ev_{lT}^T\AP{\Theta_{lT}}-\bar{\Ev}_{lT}^T\AP{\Theta_{lT}}}{\V_{\SHy_*\R}(\gamma)}}$$

\textbf{Proof of Proposition A.N1}\Co{b}

TBD \textbf{Q.E.D.}\Co{b}

\textbf{Proposition A.N6}\Co{b}

\textit{Consider a real finite-dimensional normed vector space $V$ and a linear subspace $W\subseteq V$. Then, there exists a $\B \in\PSD(V)$ s.t.}\Co{i}

1. \textit{For any $v\in V$, $\B v^{\otimes 2}\leq\Norm{v}^2$}\Co{i}

2. \textit{For any $w\in W$, $\AP{\dim{W}}^2 \B w^{\otimes 2}\geq \Norm{w}^2$}\Co{i}

\textbf{Proof of Proposition A.N6}\Co{b}

% Use the Kadec-Snobar (can also be cited: Koenig-Jaegermann) projection constant bound and John's ellipsoid 
TBD \textbf{Q.E.D.}\Co{b}

\textbf{Proposition A.N4}\Co{b}

\textit{Consider a finite-dimensional real vector space $\Y$, some $\B \in\PD(\Y)$ and a Borel probability measure $\mu\in\Delta\Y$ s.t. $\Pa{y\sim\mu}{\B y^{\otimes 2} \leq 1} = 1$. Let $y_0:=\Ea{y\sim\mu}{y}$ and $\sigma:=\sqrt{e}$. Then, $\mu$ is $\sigma$-sub-Gaussian w.r.t. $\B $, i.e., for any $\alpha\in\Y^*$}\Co{i}

$$\Ea{y\sim\mu}{\exp\AP{\alpha\AP{y-y_0}}} \leq \exp\AP{\frac{\sigma^2\B ^{-1}\alpha^{\otimes 2}}{2}}$$

\textbf{Proof of Proposition A.N4}\Co{b}

TBD \textbf{Q.E.D.}\Co{b}

\textbf{Definition A.N1}\Co{b}

\textit{Consider a set $\X$, a finite-dimensional real vector space $\Y$, some $\F\subseteq\AC{\X\rightarrow\Y}$ and a family $\AC{\B _x\in\PSD(\Y)}_{x\in\X}$. Assume $\F$ is compact w.r.t. the product topology on $\X\rightarrow\Y\cong\prod_{x\in\X}\Y$. Consider also some $n\in\Nats$, $\bold{x}\in\X^n$, $\bold{y}\in\Y^n$ and $r\in\Reals^+$. We then use the notation}\Co{i}

$$\LS^{\F}[\bold{xy},\B]:=\Argmin{f\in\F}{\sum_{m=0}^{n-1}\B _{\bold{x}_m}\AP{f\AP{\bold{x}_m}-\bold{y} }^{\otimes2}}$$

$$\CS^{\F}[\bold{xy},B]:=\ACM{f\in\F}{\sum_{m=0}^{n-1}\B _{\bold{x}_m}\AP{f\AP{\bold{x}_m}-\LS_\B ^\F[\bold{xy}]\AP{\bold{x}_m}}^{\otimes2}\leq 1}$$

I chose the notation $\LS$ as an abbreviation of "least squares" and $\CS$ as an abbreviation of "confidence set". Note that $\LS$ is somewhat ambiguous (and therefore, so is $\CS$) since there might be multiple minima, but this will not be important in the following (i.e. an arbitrary minimum can be chosen).

\textbf{Proposition A.N5}\Co{b}

\textit{There is some $C_{\mathrm{A.N5}}\in\Reals^+$ s.t. the following holds.}\Co{i}

\textit{Consider finite sets $\X,\St$, some $\F\subseteq\AC{\X\K\St}$ and a family $\AC{\B _x\in\PSD\AP{\Reals^\St}}_{x\in\X}$. Let $\AC{\mathfrak{H}_n\subseteq\PS{\X^\omega\times\St^\omega}}_{n\in\Nats}$ be the natural filtration, i.e.}\Co{i}

$$\mathfrak{H}_n:=\ACM{A'\subseteq\X^\omega\times\St^\omega}{A'=\ACM{\bold{xs}}{\bold{xs}_{:n}\in A},\ A\subseteq\X^n\times\St^n}$$

\textit{Consider also $f^*\in\F$ and $\mu\in\Delta\AP{\X^\omega\times\St^\omega}$ s.t. for any $n\in\Nats$, $x\in\X$, and $s\in\St$}\Co{i}

$$\CP{\bold{xs}\sim\mu}{\bold{s}_n=s}{\bold{x}_n=x,\ \mathfrak{H}_n} = f^*(s\mid x)$$

\textit{Fix $\epsilon\in\Reals^+$, $\delta\in(0,1)$. Denote}\Co{i}

$$\beta(t):=C_{\mathrm{A.N5}}\AP{\ln{\frac{\N(\F,\epsilon^{-2}\B )}{\delta}}+\epsilon t\ln{\frac{et}{\delta}}}$$

\textit{Then,}\Co{i}

$$\Pa{\bold{xs}\sim\mu}{f^*\not\in\bigcap_{n=0}^\infty\CS^\F\AB{\bold{xs}_{:n},\frac{\B }{\beta(n+1)}}} \leq \delta$$

\textit{Here, $\N$ and $\CS$ are defined by thinking of $\St$ and $\Delta\St$ as subsets of $\Y=\Reals^\St$.}\Co{i}

\textbf{Proof of Proposition A.N5}\Co{b}

% A.N4 + B.N2
TBD \textbf{Q.E.D.}\Co{b}

\Co{b}

\textbf{Definition A.N2}\Co{b}

\textit{Consider a set $\X$, some $x\in\X$, a real vector space $\Y$, some $\F\subseteq\AC{\X\rightarrow\Y}$ and a family $\AC{\B _x\in\PSD(\Y)}_{x\in\X}$. The}\Co{i} $\B $-width of $\F$ at $x$ \textit{is defined by}\Co{i}

$$\W^\F(x,B):=\sup_{f,\tilde{f}\in\F}\sqrt{\B _x\AP{f(x)-\tilde{f}(x)}^{\otimes2}}$$  

\textbf{Proposition A.N2}\Co{b}

\textit{There is some $C_{\mathrm{A.N2}}\in\Reals^+$ s.t. the following holds.}\Co{i}

\textit{Consider a set $\X$, a real vector space $\Y$, some $\F\subseteq\AC{\X\rightarrow\Y}$ and a family $\AC{\B _x\in\PSD(\Y)}_{x\in\X}$. Consider also some $\bold{x}\in\X^\omega$, $\bold{y}\in\Y^\omega$, $T\in\Nats^+$, $\gamma\in(0,1)$, $\theta\in\Reals^+$, $\eta_0,\eta_1\in\Reals^+$ and $\delta\in(0,1)$. Denote}\Co{i}

$$\beta(t):=\eta_0 + \eta_1t\ln{\frac{et}{\delta}}$$

For any $n\in\Nats$, define $\F_n$ by

$$\F_n:=\CS^\F\AB{\bold{xy}_{:n},\frac{\B }{\beta(n+1)}}$$

Then,

$$\sum_{l=0}^\infty\sum_{m=0}^{T-1}{\gamma^{lT+m}[[\W^{F_{lT}}\AP{\bold{x}_{lT+m},B}>\theta]]} \leq C_{\mathrm{A.N2}}\RVO{\F}\cdot\AP{\theta^{-2}\beta\AP{\frac{1}{1-\gamma}}+T}\ln{\frac{1}{\theta}}$$

\textbf{Proof of Proposition A.N2}\Co{b}

TBD \textbf{Q.E.D.}\Co{b}

\textbf{Proposition A.N3}\Co{b}

\textit{There is some $C_{\mathrm{A.N3}}\in\Reals^+$ s.t. the following holds.}\Co{i}

\textit{Consider a set $\X$, a real vector space $\Y$, some $\F\subseteq\AC{\X\rightarrow\Y}$ and a family $\AC{\B _x\in\PSD(\Y)}_{x\in\X}$. Assume that for any $x\in\X$ and $f\in\F$, $\B _x{f(x)}^{\otimes2}\leq 1$. Consider also some $\bold{x}\in\X^\omega$, $\bold{y}\in\Y^\omega$, $T\in\Nats^+$, $\gamma\in(0,1)$, $\eta_0,\eta_1\in\Reals^+$ and $\delta\in(0,1)$. Define $\beta$ and $\F_n$ the same way as in Proposition A.N2. Denote $D:=\RVO{\F}$. Then,}\Co{i}

$$\sum_{l=0}^\infty\sum_{m=0}^{T-1}{\gamma^{lT+m}\W^{F_{lT}}\AP{\bold{x}_{lT+m},B}} \leq C_{\mathrm{A.N3}}\AP{1+D T\ln\frac{1}{1-\gamma}+\sqrt{D\beta\AP{\frac{1}{1-\gamma}}\frac{1}{1-\gamma}\ln{\frac{1}{1-\gamma}}}}$$

\textbf{Proof of Proposition A.N3}\Co{b}

TBD \textbf{Q.E.D.}\Co{b}

\textbf{Proof of Theorem 1}\Co{b}

We take $\pi^\dagger_\gamma:=\pi^\PSR_{\zeta\Pi T}$ where $\Pi$ is as in Proposition A.N1 and $T\in\Nats^+$ will be specified later. Denote the Bayesian regret by

$$\Reg(\gamma):=\Ea{\T\sim\zeta}{\EU^*_{\T\R}(\gamma)-\EU^{\pi_{\gamma}^{\dagger}}_{\T\R}(\gamma)}$$

By Proposition A.N1

$$\Reg(\gamma)=\sum_{n=0}^\infty\gamma^{n}\Ea{}{\Ea{\SHy_n\AP{\Theta_n,\AT_n}-\THy\AP{\Theta_n,\AT_n}}{\V_{\SHy_n\R}(\gamma)}}+\sum_{l=0}^\infty{\gamma^{lT}}\Ea{}{\Ea{\Ev_{lT}^T\AP{\Theta_{lT}}-\bar{\Ev}_{lT}^T\AP{\Theta_{lT}}}{\V_{\SHy_*\R}(\gamma)}}$$

$$\Reg(\gamma)\leq\sum_{n=0}^\infty\gamma^{n}\Ea{}{\Abs{\Ea{\SHy_n\AP{\Theta_n,\AT_n}-\THy\AP{\Theta_n,\AT_n}}{\V_{\SHy_n\R}(\gamma)}}}+\sum_{l=0}^\infty{\gamma^{lT}}\Ea{}{\Abs{\Ea{\Ev_{lT}^T\AP{\Theta_{lT}}-\bar{\Ev}_{lT}^T\AP{\Theta_{lT}}}{\V_{\SHy_*\R}(\gamma)}}}$$

We will use the notation

$$\De\V(\gamma):=\max_{\T\in\Hy}{\AP{\max_{s\in\St}{\V_{\T\R}(s,\gamma)}-\min_{s\in\St}{\V_{\T\R}(s,\gamma)}}}$$

It follows that

$$\Reg(\gamma)\leq\Delta\V(\gamma)\AP{\sum_{n=0}^\infty\gamma^{n}\Ea{}{\Dtva{\SHy_n\AP{\Theta_n,\AT_n},\THy\AP{\Theta_n,\AT_n}} }+\sum_{l=0}^\infty\gamma^{lT}\Ea{}{\Dtva{\Ev_{lT}^T\AP{\Theta_{lT}},\bar{\Ev}_{lT}^T\AP{\Theta_{lT}}}}}$$

$$\Reg(\gamma)\leq\Delta\V(\gamma)\AP{\sum_{n=0}^\infty\gamma^{n}\Ea{}{\Dtva{\SHy_n\AP{\Theta_n,\AT_n},\THy\AP{\Theta_n,\AT_n}} }+\frac{1}{1-\gamma^T}}$$

Consider $\Y=\Reals^\St$ equipped with the $L^1$ norm. Given $s\in\St$ and $a\in\A$, consider also the subspace

$$W_{sa}:=\Sp\ACM{\T(s,a)}{\T\in\Hy}$$

By Proposition A.N6, there is $\B_{sa}\in\PSD\AP{\Y}$ s.t.

1. For any $\mu\in\Delta\St$

$$\B_{sa}\mu^{\otimes2}\leq1$$

2. For any $\T,\tilde{\T}\in\Hy$

$$\frac{1}{4}\DL^2 B_{sa}\AP{\T(s,a)-\tilde{\T}(s,a)}^{\otimes2} \geq \Dtva{\T(s,a),\tilde{\T}(s,a)}^2$$

We now apply Proposition A.N5 with $\delta:=\frac{1}{2}(1-\gamma)^2$ and $\epsilon:=(1-\gamma)^2$. We get

$$\Pa{}{\SHy_*\in\bigcap_{n=0}^\infty\CS^\Hy\AB{\Theta\AT_{:n}\Theta_n,\frac{\B }{\beta(n+1)}}} \geq 1-\frac{1}{2}(1-\gamma)^2$$

Here, $\beta$ was defined in Proposition A.N5.

Since the hypothesis $\SHy_n$ is sampled from the posterior, for any $l\in\Nats$ we also have

$$\Pa{}{\SHy_{lT}\in\CS^\Hy\AB{\Theta\AT_{:lT}\Theta_{lT},\frac{\B }{\beta(lT+1)}}} \geq 1-\frac{1}{2}(1-\gamma)^2$$

$$\Pa{}{\SHy_*,\SHy_{lT}\in\CS^\Hy\AB{\Theta\AT_{:lT}\Theta_{lT},\frac{\B }{\beta(lT+1)}}} \geq 1-(1-\gamma)^2$$

Denote

$$\CSE_n:=\AC{\SHy_*,\SHy_{lT}\in\CS^\Hy\AB{\Theta\AT_{:lT}\Theta_{lT},\frac{\B }{\beta(lT+1)}}}\subseteq\Omega$$

We get

$$\Reg(\gamma)\leq\Delta\V(\gamma)\sum_{n=0}^\infty\gamma^{n}\AP{\Ea{}{\Dtva{\SHy_n\AP{\Theta_n,\AT_n},\THy\AP{\Theta_n,\AT_n}};\CSE_n }+(1-\gamma)^2}$$

$$\Reg(\gamma)\leq\Delta\V(\gamma)\AP{\sum_{n=0}^\infty\gamma^{n}\Ea{}{\Dtva{\SHy_n\AP{\Theta_n,\AT_n},\THy\AP{\Theta_n,\AT_n}};\CSE_n }+1-\gamma+\frac{1}{1-\gamma^T}}$$

Using property 2 of B

$$\Reg(\gamma)\leq\Delta\V(\gamma)\AP{\frac{1}{2}\DL\sum_{n=0}^\infty\gamma^{n}\Ea{}{\sqrt{B_{\Theta_n\AT_n}\AP{\SHy_n\AP{\Theta_n,\AT_n}-\THy\AP{\Theta_n,\AT_n}}^{\otimes2}};\CSE_n }+1-\gamma+\frac{1}{1-\gamma^T}}$$

Denote

$$\Hy_l:=\CS^\Hy\AB{\Theta\AT_{:lT}\Theta_{lT},\frac{\B }{\beta(lT+1)}}$$

Clearly

$$\Pa{}{\sqrt{B_{\Theta_n\AT_n}\AP{\SHy_n\AP{\Theta_n,\AT_n}-\THy\AP{\Theta_n,\AT_n}}^{\otimes2}}\leq\W^{\Hy_{\Floor{n/T}}}\AP{\Theta_n\AT_n,B};\CSE_n}=1$$

Using this inequality, dropping the $;G_n$ (since it can only the right hand side smaller) and moving the sum inside the expected value, we get

$$\Reg(\gamma)\leq\Delta\V(\gamma)\AP{\frac{1}{2}\DL\Ea{}{\sum_{n=0}^\infty\gamma^{n}\W^{\Hy_{\Floor{n/T}}}\AP{\Theta_n\AT_n,B} }+1-\gamma+\frac{1}{1-\gamma^T}}$$

Denote 

$$\phi(\gamma):=\beta\AP{\frac{1}{1-\gamma}}\frac{1}{1-\gamma}\ln{\frac{1}{1-\gamma}}$$

Applying Proposition A.N3, we conclude

$$\Reg(\gamma)\leq\Delta\V(\gamma)\AP{\frac{\DL C_{\mathrm{A.N3}}}{2}\AP{1+\DRVO T\ln\frac{1}{1-\gamma}+\sqrt{\DRVO\phi(\gamma)}}+1-\gamma+\frac{1}{1-\gamma^T}}$$

Denote the second factor on the right hand side $F(\gamma)$, so that the inequality becomes 

$$\Reg(\gamma)\leq\De\V(\gamma)F(\gamma)$$

Now, we analyze the $\gamma\rightarrow1$ limit.

$$\limsup_{\gamma\rightarrow1}{\frac{\Reg(\gamma)}{\sqrt{(1-\gamma)\ln{\frac{1}{1-\gamma}}}}}\leq \limsup_{\gamma\rightarrow1}{\frac{\De\V(\gamma)F(\gamma)}{\sqrt{(1-\gamma)\ln{\frac{1}{1-\gamma}}}}}$$

We assume $\tau_{\zeta\R}<\infty$, otherwise the theorem is vacuous. Multiplying the numerator and denominator on the right hand side by $\sqrt{1-\gamma}$, we get

$$\limsup_{\gamma\rightarrow1}{\frac{\Reg(\gamma)}{\sqrt{(1-\gamma)\ln{\frac{1}{1-\gamma}}}}}\leq  \tau_{\zeta\R}\limsup_{\gamma\rightarrow1}{\sqrt{\frac{1-\gamma}{\ln{\frac{1}{1-\gamma}}}}\cdot F(\gamma)}$$

We will now analyze the contribution of each term in $F(\gamma)$ to the right hand side.

??? Set the value of $T$ ???

TBD \textbf{Q.E.D.}\Co{b}

\begin{Huge}Appendix\end{Huge}

The proposition below appeared in Osband and Van Roy as "Lemma 1", so we state it without proof.

\textbf{Proposition B.N1 (Osband-Van Roy)}\Co{b}

\textit{TBD}\Co{i}

% episode decoupling seems to be redundant, it is already taken care of using the "Lipschitz constant"
\Co{...

\textbf{Proposition B.N3}\Co{b}

Consider some $\gamma\in(0,1)$, $\tau\in(0,\infty)$, $T\in\Nats^+$, a universe..., some $\pi^*: ? \rightarrow \A$ and some $\pi^0: ? \K \A$. Assume that $\gamma \geq \gamma_M$. For any $n \in \Nats$, let $\pi^*_n$ be a policy s.t. for any $h \in ?$

$$\pi^*_n(h):=\begin{cases} \pi^0(h) \text{ if } \Abs{h} < nT \\ \pi^*(h) \text{ otherwise} \end{cases}$$

Assume that for any $h \in ?$

i. $$\pi^*(s) \in \A_{M}^\omega\AP{S(h)}$$

ii. $$\Supp{\pi^0(h)} \subseteq \A_{M}^0\AP{S(h)}$$

iii. For any $\theta\in(\gamma,1)$ $$\Abs{\frac{\D\V_{M}\AP{S(h),\theta}}{\D\theta}} \leq \tau$$

Then

$$\EU^{*}_\upsilon(\gamma)-\EU^{\pi^0}_\upsilon(\gamma) \leq (1-\gamma)\sum_{n=0}^\infty \sum_{m=0}^{T-1} \gamma^{nT+m}\left(\E{x\sim\mu\bowtie\pi^*_n}\left[r\left(x_{:nT+m}\right)\right]-\E{x\sim\mu\bowtie\pi^0}\left[r\left(x_{:nT+m}\right)\right]\right) + \frac{2\tau\gamma^T(1-\gamma)}{1-\gamma^T}$$}

The next proposition appeared (in slightly greater generality) in Osband and Van Roy as "Proposition 5".

\textbf{Proposition B.N2 (Osband-Van Roy)}\Co{b}

\textit{There is some $C_{\mathrm{B.N2}}\in\Reals^+$ s.t. the following holds.}\Co{i}

\textit{Consider a finite set $\X$, the vector space $\Y:=\Reals^d$ for some $d\in\Nats$ and some $\F\subseteq\AC{\X\rightarrow\Y}$. Let $\AC{\mathfrak{H}_n\subseteq\PS{\X^\omega\times\Y^\omega}}_{n\in\Nats}$ be the natural filtration, i.e.}\Co{i}

$$\mathfrak{H}_n:=\ACM{A'\subseteq\X^\omega\times\Y^\omega}{A'=\ACM{\bold{xy}}{\bold{xy}_{:n}\in A},\ A\subseteq\X^n\times\Y^n\text{ Borel}}$$

\textit{Consider also $f^*\in\F$ and $\mu\in\Delta\AP{\X^\omega\times\Y^\omega}$ s.t. for any $n\in\Nats$ and $x\in\X$}\Co{i}

$$\CE{\bold{xy}\sim\mu}{\bold{y}_n}{\bold{x}_n=x,\ \mathfrak{H}_n} = f^*(x)$$

\textit{Assume that $M\in\Reals^+$ is s.t. $\bold{y}_n\cdot\bold{y}_n\leq M^2$ with $\mu$-probability $1$ for all $n\in\Nats$. Assume also that $\sigma\in\Reals^+$ is s.t. $\mu$ is $\sigma$-sub-Gaussian, i.e., for any $\alpha\in\Y$, $n\in\Nats$ and $x\in\X$}\Co{i}

$$\CE{\bold{xy}\sim\mu}{\exp\AP{\alpha\cdot\AP{\bold{y}_n-f^*(x)}}}{\bold{x}_n=x,\ \mathfrak{H}_n} \leq \exp\AP{\frac{\sigma^2\AP{\alpha\cdot\alpha}}{2}}$$

\textit{Fix $\epsilon\in\Reals^+$, $\delta\in(0,1)$. Define $\beta:\Reals^+\rightarrow\Reals$ and, for each $n\in\Nats$, $Q_n\in\PD(\Y)$ by}\Co{i}

$$\beta(t):=C_{\mathrm{B.N2}}\AP{\sigma^2 \ln{\frac{\N(\F,\epsilon)}{\delta}}+\epsilon t\AP{M+\sigma\ln{\frac{et}{\delta}}}}$$

$$Q_n(v,w):=\frac{v\cdot w}{\beta(n+1)}$$

\textit{Then,}\Co{i}

$$\Pa{\bold{xy}\sim\mu}{f^*\not\in\bigcap_{n=0}^\infty\CS^\F\AB{\bold{xy}_{:n},Q_n}} \leq \delta$$

Note that we removed a square root in the definition of $\beta$ compared to equation (7) in Osband and Van Roy. This only makes $\beta$ larger (up to a constant factor) and therefore, only makes the claim weaker.

\end{document}


