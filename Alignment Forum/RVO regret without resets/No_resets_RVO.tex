%&latex
\documentclass[a4paper]{article}

\usepackage[a4paper,margin=1in]{geometry}
\usepackage[affil-it]{authblk}
\usepackage{cite}
\usepackage[unicode]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{commath}

\newcommand{\Co}[1]{}
% operators that are separated from the operand by a space
\DeclareMathOperator{\Sgn}{sgn}
\DeclareMathOperator{\Supp}{supp}
\DeclareMathOperator{\Dom}{dom}
% autosize delimiters
\newcommand{\AP}[1]{\left(#1\right)}
\newcommand{\AB}[1]{\left[#1\right]}
\newcommand{\AC}[1]{\left\{#1\right\}}
\newcommand{\APM}[2]{\left(#1\;\middle\vert\;#2\right)}
\newcommand{\ABM}[2]{\left[#1\;\middle\vert\;#2\right]}
\newcommand{\ACM}[2]{\left\{#1\;\middle\vert\;#2\right\}}
% probability theory
\newcommand{\Pa}[2]{\underset{#1}{\operatorname{Pr}}\AB{#2}}
\newcommand{\CP}[3]{\underset{#1}{\operatorname{Pr}}\ABM{#2}{#3}}
\newcommand{\PP}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{Pr}}}
\newcommand{\PPP}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{Pr}}}
\newcommand{\E}[1]{\underset{#1}{\operatorname{E}}}
\newcommand{\Ea}[2]{\underset{#1}{\operatorname{E}}\AB{#2}}
\newcommand{\CE}[3]{\underset{#1}{\operatorname{E}}\ABM{#2}{#3}}
\newcommand{\EE}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{E}}}
\newcommand{\EEE}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{E}}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\I}[1]{\underset{#1}{\operatorname{I}}}
\newcommand{\CI}[3]{\underset{#1}{\operatorname{I}}\ABM{#2}{#3}}
\newcommand{\Ia}[2]{\underset{#1}{\operatorname{I}}\AB{#2}}
\newcommand{\II}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{I}}}
\newcommand{\III}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{I}}}
\newcommand{\KL}[2]{\operatorname{D}_{\mathrm{KL}}\AP{#1\middle\vert\middle\vert#2}}
\newcommand{\RD}[3]{\operatorname{D}_{#1}\AP{#2\middle\vert\middle\vert#3}}
\newcommand{\Dtv}{\operatorname{d}_{\text{tv}}}
\newcommand{\Dtva}[1]{\operatorname{d}_{\text{tv}}\AP{#1}}
\newcommand{\En}{\operatorname{H}}
\newcommand{\Ena}[1]{\operatorname{H}\AP{#1}}
% power set
\newcommand{\PS}[1]{\mathcal{P}\AP{#1}}
% differential
\newcommand{\D}{\mathrm{d}}
% arg
\newcommand{\Argmin}[1]{\underset{#1}{\operatorname{arg\,min}}\,}
\newcommand{\Argmax}[1]{\underset{#1}{\operatorname{arg\,max}}\,}
% numbers
\newcommand{\Nats}{\mathbb{N}}
\newcommand{\Ints}{\mathbb{Z}}
\newcommand{\Rats}{\mathbb{Q}}
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\Coms}{\mathbb{C}}
% empty string
\newcommand{\Estr}{\boldsymbol{\lambda}}
% limits
\newcommand{\Lim}[1]{\lim_{#1 \rightarrow \infty}}
\newcommand{\LimInf}[1]{\liminf_{#1 \rightarrow \infty}}
\newcommand{\LimSup}[1]{\limsup_{#1 \rightarrow \infty}}
% more delimiters
\newcommand{\Abs}[1]{\left\vert #1 \right\vert}
\newcommand{\Norm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\Floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\Ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\Chev}[1]{\left\langle #1 \right\rangle}
\newcommand{\Quote}[1]{\left\ulcorner #1 \right\urcorner}
% arrows
\newcommand{\K}{\xrightarrow{\text{k}}}
\newcommand{\PF}{\xrightarrow{\circ}}
% Paper specific
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\St}{\mathcal{S}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\Hy}{\mathcal{H}}
\newcommand{\RVO}{\dim_{\text{RVO}}}
\newcommand{\MB}{\dim_{\text{MB}}}
\newcommand{\N}{\mathrm{N}}
\newcommand{\V}{\mathrm{V}}
\newcommand{\EU}{\mathrm{EU}}

\begin{document}

\textbf{TLDR:}\Co{b} I derive a variant of the RL regret bound by [Osband and Van Roy](https://arxiv.org/abs/1406.1853), that applies to learning without resets of environments without traps. The advantage of this regret bound over those known in the literature, is that it scales with certain learning-theoretic dimensions rather than number of states and actions. My goal is building on this result to derive this type of regret bound for [DRL](https://agentfoundations.org/item?id=1656), and, later on, other settings interesting from an AI\ alignment perspective.

***

[Previously](https://www.alignmentforum.org/posts/zTf946PQwN2AN3X3Y/entropic-regret-i-deterministic-mdps) I derived a regret bound for \textit{deterministic}\Co{i} environments that scales with prior entropy and "prediction dimension". That bound behaves as $O\AP{\sqrt{1-\gamma}}$ in the episodic setting but only as $O\AP{\sqrt[3]{1-\gamma}}$ in the setting without resets. Moreover, my attempts to generalize the result to stochastic environments led to bounds that are \textit{even weaker}\Co{i} (have a lower exponent). Therefore, I decided to put that line of attack on hold, and use Osband and Van Roy's technique instead, leading to an $O\AP{\sqrt{1-\gamma}}$ bound in the stochastic setting without resets. The main disadvantage is, this bound doesn't scale down with the entropy of the prior, but this does not seem as important as dependence on $\gamma$.

\begin{Huge}Results\end{Huge}

[Russo and Van Roy](https://papers.nips.cc/paper/4909-eluder-dimension-and-the-sample-complexity-of-optimistic-exploration) introduced the concept of "eluder dimension" for the benefit of the multi-armed bandit setting, and Osband and Van Roy extended it to a form suitable for studying reinforcement learning. The following two definitions are adapted from the latter.

\textbf{Definition 1}\Co{b}

\textit{Consider a set $\X$, a real inner product space $\Y$, some $\F\subseteq\AC{\X\rightarrow\Y}$ and $\epsilon\in\Reals^+$. Consider also $n\in\Nats$, a sequence $\AC{x_k\in\X}_{k\in[n]}$ and $x^*\in\X$. $x^*$ is said to be} $\AP{\F,\epsilon}$-dependant on $\AC{x_k}$ \textit{when, for any $f,\tilde{f}\in\F$}\Co{i}

$$\sum_{k=0}^{n-1}\Norm{f\AP{x_k}-\tilde{f}\AP{x_k}}^2 \leq \epsilon^2 \implies \Norm{f\AP{x^*}-\tilde{f}\AP{x^*}}\leq\epsilon$$

\textit{Otherwise, $x^*$ is said to be}\Co{i} $\AP{\F,\epsilon}$-independent of $\AC{x_k}$.

\textbf{Definition 2}\Co{b}

\textit{Consider a set $\X$, a real inner product space $\Y$, some $\F\subseteq\AC{\X\rightarrow\Y}$ and $\epsilon\in\Reals^+$. The}\Co{i} eluder dimension $\dim_{\text{e}}(\F,\epsilon)$ \textit{is the supremum of the set of $n\in\Nats$ for which there is $\AC{x_k\in\X}_{k\in[n]}$ and $\epsilon'\geq\epsilon$ s.t. for all $m\in[n]$, $x_m$ is $\AP{\F,\epsilon'}$-independent of $\AC{x_k\in\X}_{k\in[m]}$.}\Co{i}

% Is eluder dimension logarithmic for cellular automata?

As opposed to other learning-theoretic dimensions, eluder dimension depends on the parameter $\epsilon$. However, in natural examples it seems to be always bounded by a logarithmic function of $\epsilon$. This motivates the following definition

\textbf{Definition 3}\Co{b}

\textit{Consider a set $\X$, a real inner product space $\Y$ and some $\F\subseteq\AC{\X\rightarrow\Y}$. Then, the}\Co{i} Russo-Van Roy-Osband dimension (RVO dimension) of $\F$ \textit{is defined by}\Co{i}

$$\RVO{\F}:=\limsup_{\epsilon \rightarrow 0}{\frac{\dim_{\text{e}}(\F,\epsilon)}{\ln\frac{1}{\epsilon}}}$$

Another concept we need to formulate the regret bound is the Minkowski–Bouligand dimension.

\textbf{Definition 4}\Co{b}

\textit{Consider a set $\X$, a real inner product space $\Y$, some $\F\subseteq\AC{\X\rightarrow\Y}$ and $\epsilon\in\Reals^+$. A set $A\subseteq\F$ is said to be an}\Co{i} $\epsilon$-covering of $\F$ \textit{when}\Co{i}

$$\forall f\in\F\exists g\in A: \sup_{x\in\X}\Norm{f(x)-g(x)}<\epsilon$$

That is, we always consider the covering number of function families w.r.t. the $\sup$ norm.

\textbf{Definition 5}\Co{b}

\textit{Consider a set $\X$, a real inner product space $\Y$, some $\F\subseteq\AC{\X\rightarrow\Y}$ and $\epsilon\in\Reals^+$.\ The}\Co{i} covering number $\N(\F,\epsilon)$ \textit{is the infimum of the set of $n\in\Nats$ for which there is an $\epsilon$-covering of $\F$ of size $n$.}\Co{i}

\textbf{Definition 6}\Co{b}

\textit{Consider a set $\X$, a real inner product space $\Y$ and some $\F\subseteq\AC{\X\rightarrow\Y}$. Then, the}\Co{i} Minkowski–Bouligand dimension (MB dimension) of $\F$ \textit{is defined by}\Co{i}

$$\MB{\F}:=\limsup_{\epsilon \rightarrow 0}{\frac{\ln{\N(\F,\epsilon)}}{\ln\frac{1}{\epsilon}}}$$

Note that, in general, RVO and MB dimensions are fractional.

Consider finite non-empty sets $\St$ (states) and $\A$ (actions). Note that $\Delta\St$ can be regarded as a subset of the vector space $\Reals^\St$ and the later can be equipped with the inner product $\Chev{v,w}:=\sum_{s\in\St} v_s w_s$. This allows us to speak of the RVO and MB dimensions of a hypothesis class of transition kernels $\Hy\subseteq\AC{\St\times\A\K\St}$ (that is, in this case $\X=\St\times\A$ and $\Y=\Delta\St$). We can now formulate the regret bound.

\textbf{Theorem 1}\Co{b}

\textit{There is some $C\in\Reals^+$ s.t. the following holds.}\Co{i}

\textit{Consider any finite non-empty sets $\St$ and $\A$, $\R:\St\rightarrow[0,1]$ (reward function), closed set $\Hy\subseteq\AC{\St\times\A\K\St}$ and Borel probability measure $\zeta$ on $\Hy$ (prior). Assume that for any $\T\in\Hy$ and $s\in\St$, $\A^0_{\T\R}(s) = \A$ (no traps). We define $\tau_{\zeta\R}$ by}\Co{i}

$$\tau_{\zeta\R}:=\Ea{\T\sim\zeta}{\max_{s\in\St}\Abs{\V^1_{\T\R}(s)}}$$

\textit{Then, there is a family of policies $\AC{\pi^\dagger_\gamma:\St^*\times\St\K\A}_{\gamma\in(0,1)}$ s.t. for any $\epsilon\in\Reals^+$}\Co{i}

$$\limsup_{\gamma \rightarrow 1}\frac{\Ea{\T\sim\zeta}{\EU^*_{\T\R}(\gamma)-\EU^{\pi^\dagger_\gamma}_{\T\R}(\gamma)}}{\tau_{\zeta\R}\ln{\frac{1}{1-\gamma}}\sqrt{\AP{\MB\Hy+\epsilon}\AP{\RVO\Hy+\epsilon}(1-\gamma)}}\leq C$$

Here (like in previous essays), $\V^1_{\T\R}(s)$ is the first derivative of the value function at $\gamma=1$ for transition kernel $\T$, reward function $\R$ and state $s$; $\EU^{\pi}_{\T\R}(\gamma)$ is the expected utility for policy $\pi$ and geometric time discount parameter $\gamma$; $\EU^*_{\T\R}(\gamma)$ is the maximal expected utility over policies.
\end{document}


