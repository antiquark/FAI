%
\documentclass{article}

\usepackage[affil-it]{authblk}
\usepackage{cite}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{commath}
\usepackage{bm}

\numberwithin{equation}{section}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
%\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[section]
%\newtheorem{conjecture}{Conjecture}[section]

%\theoremstyle{remark}
%\newtheorem{note}{Note}[section]

\newcommand{\Words}{{\{ 0, 1 \}^*}}
\newcommand{\WordsLen}[1]{{\{ 0, 1 \}^{#1}}}
\newcommand{\Bool}{\{0,1\}}

\DeclareMathOperator{\Sgn}{sgn}
\DeclareMathOperator{\Supp}{supp}
\DeclareMathOperator{\Stab}{stab}
\DeclareMathOperator{\Img}{Im}
\DeclareMathOperator{\Prb}{Pr}
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Ent}{H}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Sym}{Sym}
\DeclareMathOperator{\T}{T}
\DeclareMathOperator{\R}{r}
\DeclareMathOperator{\A}{a}
\DeclareMathOperator{\M}{M}
\DeclareMathOperator{\UM}{UM}
\DeclareMathOperator{\En}{c}

\newcommand{\KL}[2]{\operatorname{D}_{\mathrm{KL}}(#1 \| #2)}
\newcommand{\Dtv}{\operatorname{d}_{\textnormal{tv}}}

\newcommand{\Argmin}[1]{\underset{#1}{\operatorname{arg\,min}}\,}
\newcommand{\Argmax}[1]{\underset{#1}{\operatorname{arg\,max}}\,}

\newcommand{\Nats}{\mathbb{N}}
\newcommand{\Ints}{\mathbb{Z}}
\newcommand{\Rats}{\mathbb{Q}}
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\Coms}{\mathbb{C}}

\newcommand{\Lim}[1]{\lim_{#1 \rightarrow \infty}}
\newcommand{\LimInf}[1]{\liminf_{#1 \rightarrow \infty}}
\newcommand{\LimSup}[1]{\limsup_{#1 \rightarrow \infty}}

\newcommand{\Abs}[1]{\lvert #1 \rvert}
\newcommand{\Norm}[1]{\lVert #1 \rVert}
\newcommand{\Floor}[1]{\lfloor #1 \rfloor}
\newcommand{\Ceil}[1]{\lceil #1 \rceil}
\newcommand{\Chev}[1]{\langle #1 \rangle}
\newcommand{\Quote}[1]{\ulcorner #1 \urcorner}

\newcommand{\GrowR}{\Gamma_{\mathfrak{R}}}
\newcommand{\GrowA}{\Gamma_{\mathfrak{A}}}
\newcommand{\Grow}{\Gamma:=(\GrowR,\GrowA)}
\newcommand{\MGrow}{\mathrm{M}\Gamma}
\newcommand{\Fall}{\mathcal{E}}

\newcommand{\Alg}{\xrightarrow{\textnormal{alg}}}
\newcommand{\Markov}{\xrightarrow{\textnormal{mk}}}
\newcommand{\Scheme}{\xrightarrow{\Gamma}}
\newcommand{\MScheme}{\xrightarrow{\MGrow}}

\begin{document}

\title{Optimal Predictors: A Bayesian Notion of Approximation Algorithm (Draft)}


\author{Vadim Kosoy}
\affil{Affiliation TBD}

\date{\today}

\maketitle

\begin{abstract}
The concept of an "approximation algorithm" is usually only applied to optimization problems since in optimization problems the performance of the algorithm on any given input is a continuous parameter. We introduce a new concept of approximation applicable to decision problems and functions, inspired by Bayesian probability. From the perspective of a Bayesian reasoner with limited computational resources, the answer to a problem that cannot be solved exactly is uncertain and therefore should be described by a random variable. It thus should make sense to talk about the expected value of this random variable, an idea we formalize in the language of average-case complexity theory by introducing the concept of "optimal predictor." We show that optimal predictors exhibit many parallels with "classical" probability theory, prove some existence theorems and demonstrate some applications to artificial general intelligence.%
\end{abstract}%

\section*{Introduction}
%
Imagine you are strolling in the city with a friend when a car passes by with the license plate number "7614829". Your friend proposes a wager, claiming that the number is composite and offering 10 : 1 odds in your favor. Knowing that your friend has no exceptional ability in mental arithmetic and that it's highly unlikely they saw this car before, you realize they are just guessing. Your mental arithmetic is also insufficient to test the number for primality, but is sufficient to check that $7614829 \equiv 1 \pmod{3}$ and $\frac{1}{\ln 7614829} \approx 0.06$. Arguing from the prime number theorem and observing that 7614829 is odd and is divisible neither by 3 nor by 5, you conclude that the probability 7614829 is prime is $\frac{1}{\ln 7614829} \times 2 \times \frac{3}{2} \times \frac{5}{4} \approx 22\%$. Convinced that the odds are in your favor you accept the bet\footnote{Alas, $7614829 = 271 \times 28099$.}.

From the perspective of frequentist probability the question "what is the probability 7614829 is prime?" seems meaningless, since it is either prime or not so there is no frequency to observe (unless the frequency is 0 or 1). From a Bayesian perspective, probability represents a degree of confidence, however in classical Bayesian probability theory it is assumed the only source of uncertainty is lack of information. The number 7614829 already contains all information needed to determine whether it's prime so the probability again has to be 0 or 1. However, real life uncertainty is not only information-theoretic but also complexity-theoretic. Even when we have all information to obtain the answer, out computational resources are limited so we remain uncertain. The rigorous formalization of this idea is the main goal of the present work.

The idea of assigning probabilities to purely mathematical questions was studied by several authors\cite{Gaifman_2004,Hutter_2013,Demski_2012,Christiano_2014,Garrabrant_2015}, mainly in the setting of formal logic. That is, their approach was looking for functions from the set of sentences in some formal logical language to $[0,1]$. However, although there is a strong intuitive case for assigning probabilities to sentences like $\varphi_1:=\text{"7614829 is prime"}$ it is much less clear there is a meaningful assignment of probabilities to sentences like $\varphi_2 := \text{"there are no odd perfect numbers"}$ or (even worse) $\varphi_3 := \text{"there is no cardinality } \kappa \text{ s.t. } \aleph_0 < \kappa < 2^{\aleph_0} \text{."}$.

A wager on $\varphi_1$ can be resolved in a predetermined finite amount of time (the amount of time it takes to test it directly). On the other hand, it is unknown how long the resolution of $\varphi_2$ will take. It is possible that there is an odd perfect number but finding it (or otherwise becoming certain of its existence) will take a very long time. It is also possible there is no odd perfect number, a fact that cannot be directly verified because of its infinite nature. It is possible that there a proof of $\varphi_1$ within some formal theory, but accepting such a proof as resolution requires us to be completely certain of the consistency of the theory (whereas it is arguable that the consistency of formal mathematical theories, especially more abstract theories like ZFC, is itself only known empirically and in particular with less than absolute certainty). Moreover, there is no knowing a priori whether a proof exists or how long it will take to find it. For $\varphi_3$ there is no way to "directly" verify neither the sentence nor its negation, and it is actually known to be independent of ZFC.

In the present work we avoid choosing a specific category of mathematical questions. Instead, we consider the abstract setting of arbitrary distributional decision problems. This leads to the perspective that an assignment of probabilities is a form of \emph{approximate} solution to a problem. This is not the same sense of approximation as used in optimization problems, where the approximation error is the difference between the ideal solution and the actual solution. Instead, the approximation error is the prediction accuracy of our probability assignment. This is also different from average-complexity theory where the solution is required to be exact on most input instances. However the language of average-complexity theory (in particular the concept of a distributional decision problem) turns out to be well-suited to our purpose.
The concept of "optimal predictor" that arises from the approach turns out to behave much like probabilities, or more generally expected values, in "classical" probability theory. They display an appropriate form of calibration. The "expected values" are linear in general and multiplicative for functions that are independent in an appropriate sense. There is a natural parallel of conditional probabilities. For simple examples constructed from one-way functions we get the probability values we expect. Also they are well behaved in the complexity-theoretic sense that a natural class of reductions transforms optimal predictors into optimal predictors, and complete problems for these reductions exist for important complexity classes.

Optimal predictors turn out to be unique up to a certain equivalence relation. The existence of optimal predictors depends on the specific variety you consider. We show that in the non-uniform case (allowing advice) there is a variety of optimal predictors that exist for completely arbitrary problems. Uniform optimal predictors of this kind exist for a certain class of problems we call "generatable" which can be very roughly regarded as an average-case analogue of $\textsc{NP} \cap \textsc{coNP}$. More generally mapping the class of problems which admit optimal predictors allows for much further research.

Assignment of probabilities to mathematical questions is interesting in the context of artificial general intelligence\cite{Hutter_2013,Christiano_2014}. In this context is useful to consider situations in which an agent reasons about itself or several agents reason about each other \cite{Fallenstein_2015}. We give a formal model of such situations in our setting and use the Kakutani-Glicksberg-Fan theorem to prove they still admit existence of optimal predictors. We then use this to model agents playing a game in normal form and show that such agents converge to the analogue of Nash equilibrium (or even a proper equilibrium, depending on the precise implementation) in the time bounded case. That is, each agent plays a near-optimal response among those it can find within the allotted time. We suggest more potential applications for optimal predictors to decision theory and the theory of self-modifying agents.

The structure of the paper is as follows. Section~\ref{sec:fundamentals} introduces the main definitions and gives a simple example using one-way functions. Section~\ref{sec:probability} shows the parallel between properties of optimal predictors and classical probability theory. Section~\ref{sec:reductions} discusses behavior of optimal predictors and reductions and shows $\textsc{SampNP}$ has a complete problem under appropriate reductions. Section~\ref{sec:e_and_u} discusses existence and uniqueness of optimal predictors. Section~\ref{sec:reflective} discusses applications to AGI. Section~\ref{sec:discussion} discusses possible avenues for further research. The Appendix reviews relevant material about hard-core predicates and one-way functions.

\setcounter{section}{-1}

\section{Notation}
%
\subsection{Sets, Numbers and Functions}

$\Nats$ is the set of natural numbers. We will use the convention in which natural numbers start from 0, so $\Nats = \{0, 1, 2 \ldots \}$. 

$\Ints$ is the ring of integers, $\Rats$ is the field of rational numbers, $\Reals$ is the field of real numbers.

For $F \in \{\Rats,\Reals\}$, $F^{>0} := \{x \in F \mid x > 0\}$, $F^{\geq 0} := \{x \in F \mid x \geq 0\}$.

For any $t \in \Reals$, $\Floor{t} := \max \{n \in \Ints \mid n \leq t\}$, $\Ceil{t} := \min \{n \in \Ints \mid n \geq t\}$.

$\log: \Reals^{\geq 0} \rightarrow \Reals \sqcup \{-\infty\}$ will denote the logarithm in base 2.

Given $n \in \Nats$, sets $X_1, X_2 \ldots X_n$, $x \in \prod_{i=1}^n X_i$ and $m \in \{1,2 \ldots n\}$, $x_m \in X_m$ is the $m$-th component of the $n$-tuple $x$ i.e. $x=(x_1, x_2 \ldots x_n)$.

Given a set $X$ and $x,y \in X$, $\delta_{xy}$ (or $\delta_{x,y})$ will denote the the Kronecker delta

$$\delta_{xy} := \begin{cases}1 & \text{if } x=y \\ 0 & \text{if } x \ne y \end{cases}$$

Given a set $X$ and a subset $Y$, $\chi_Y: X \rightarrow \Bool$ will denote the characteristic function of $Y$ (when $X$ is assumed to be known from the context)

$$\chi_Y(x):=\begin{cases}1 & \text{if } x \in Y \\ 0 & \text{if } x \not\in Y \end{cases}$$

$\theta: \Reals \rightarrow \Bool$ will denote the Heaviside step function $\theta:=\chi_{[0,\infty)}$. ${\Sgn: \Reals \rightarrow \Bool}$ will denote the function $2 \theta - 1$.
\subsection{Measures and Probabilities}

For $X$ a measurable space, $\mu$ a probability measure on $X$, $V$ a finite dimensional vector space over $\Reals$ and $f: X \rightarrow V$, $\E_{x \sim \mu}[f(x)]$ will denote the expected value of $f$ with respect to $\mu$, i.e. $\E_{x \sim \mu}[f(x)] := \int_X f(x) d\mu(x)$. We will the abbreviated notations $\E_\mu[f(x)]$, $\E[f(x)]$, $\E_\mu[f]$, $\E[f]$ when no confusion is likely to occur.

Given a topological space $X$ and a Borel probability measure $\mu$ on $X$, $\Supp \mu$ will denote the support of $\mu$. In particular when $X$ is discrete, ${\Supp \mu = \{x \in X \mid \mu(x) > 0\}}$.

Given $X,Y$ measurable spaces, $\mu$ a measure on $X$ and $f: X \rightarrow Y$ a measurable mapping, $f_*(\mu)$ will denote the corresponding pushforward measure on $Y$.

Given $X,Y$ measurable spaces, the notation $f: X \xrightarrow{\textnormal{mk}} Y$ signifies $f$ is a Markov kernel with source $X$ and target $Y$. Given $x \in X$, $f_x$ is the corresponding probability measure on $Y$ and $f(x)$ is a random variable sampled from $f_x$. Given $\mu$ a probability measure on $X$, $\mu \ltimes f$ (resp. $f \rtimes \mu$) is the semidirect product measure on $X \times Y$ (resp. $Y \times X$).

For $X$ a measurable space, $\mu$ a probability measure on $X$ and $A$ a measurable subset of $X$ s.t. $\mu(A) > 0$, $\mu \mid A$ will denote the corresponding conditional probability measure, i.e. $(\mu \mid A)(B):=\frac{\mu(B \cap A)}{\mu(A)}$. Given $Y$ another measurable space, $f: X \Markov Y$ and $A$ a measurable subset of $Y$ s.t. $(\mu \ltimes f)(B \times Y) > 0$, $\mu \mid f^{-1}(A)$ will denote the probability measure on $X$ defined by ${(\mu \mid f^{-1}(A))(B):=(\mu \ltimes f \mid X \times A)(B \times Y)}$. Note that when $f$ is deterministic (i.e. $f_x$ is a Dirac measure for every $x$), this corresponds to conditioning by the inverse image of $A$ with respect to $f$. When $A=\{a\}$ we will use the shorthand notation $\mu \mid f^{-1}(a)$.

Given $X$ a measurable space and $\mu$, $\nu$ probability measures on $X$, $\Dtv(\mu,\nu)$ will denote the total variation distance between $\mu$ and $\nu$.

For $X$ a discrete measurable space, a probability measure on $X$ can be represented by a function $\mu: X \rightarrow [0,1]$ s.t. $\sum_{x \in X} \mu(x) = 1$. Abusing notation, we will make no distinction between the function and the probability measure.

\subsection{Algorithms}

$\Words$ is the set of all finite binary strings (words). For any $x \in \Words$, $\Abs{x}$ is the length of $x$ i.e. $x \in \WordsLen{\Abs{x}}$. For any $x \in \Words$ and $n \in \Nats$, $x_{\leq n}$ stands for the prefix of $x$ of length $n$ if $\Abs{x} \geq n$ and $x$ otherwise. Given $x,y \in \Words$, $xy$ stands for the concatenation of $x$ and $y$ (in particular $\Abs{xy}=\Abs{x}+\Abs{y}$). Given $n \in \Nats$ and $x,y \in \WordsLen{n}$, $x \cdot y$ stands for $\bigoplus_{i=1}^n x_i y_i$. For any $n \in \Nats$, $U^n$ is the uniform probability distribution on $\WordsLen{n}$.

Given $n \in \Nats$ and ${x_1, x_2 \ldots x_n \in \Words}$, $\Chev{x_1,x_2 \ldots x_n} \in \Words$ denotes the encoding of $(x_1,x_2 \ldots x_n)$ obtained by repeating each bit of $x_1, x_2 \ldots x_n$ twice and inserting the separators 01.
\begin{definition}

An \emph{encoded set} is a set $X$ together with an injection ${\En_X: X \rightarrow \Words}$ (the encoding) s.t. $\Img \En_X$ is decidable in polynomial time.

\end{definition}

There are standard encodings we implicitly use throughout. $\bm{1}$ denotes an encoded set with 1 element $\bullet$ whose encoding is the empty string. $\Words$ is an encoded set with the trivial encoding ${\En_\Words(x):=x}$. $\Nats$ is an encoded set where $\En_\Nats(n)$ is the binary representation of $n$. $\Rats$ is an encoded set where ${\En_\Rats(\frac{n}{m}):=\Chev{n,m}}$ for an irreducible fraction $\frac{n}{m}$. For any encoded set $X$ and $L \in \textsc{P}$, $\{x \in X \mid \En_X(x) \in L\}$ is an encoded set whose encoding is the restriction of $\En_X$. For $X,Y$ encoded sets, $X \times Y$ is an encoded set with encoding $\En_{X \times Y}(x,y):=\Chev{\En_X(x),\En_Y(y)}$.

Given $n \in \Nats$, encoded sets $X_1, X_2 \ldots X_n$ and encoded set $Y$ we use the notation $A: \prod_{i=1}^n X_i \Alg Y$ to mean a Turing machine with $n$ input tapes that halts on every input for which the $i$-th tape is initialized to a value in $\Img \En_X$ and produces an output in $\Img \En_Y$. Given $\{x_i \in X_i\}_{i=1}^n$ the notation $A(x_1, x_2 \ldots x_n)$ stands for the unique $y \in Y$ s.t. applying $A$ to the input composed of $\En_{X_i}(x_i)$ results in output $\En_Y(y)$. We use different input tapes for different components of the input instead of encoding the $n$-tuple as a single word in order to allow $A$ to process some components of the input in time smaller than the length of other components. This involves abuse of notation since a Cartesian product of encoded sets is naturally an encoded set, but hopefully this won't cause much confusion.

Given $A: X \Alg Y$ and $x \in X$, $\T_A(x)$ stands for the number of time steps in the computation of $A(x)$.

For any $n \in \Nats$, we fix $\mathcal{U}_n$, a prefix free universal Turing machine with $n+1$ input tapes: 1 program tape and $n$ tapes that serve as input to the program. Given $A: \prod_{i=1}^n X_i \Alg\ Y$, $\Quote{A} \in \Words$ denotes the corresponding program for $\mathcal{U}_n$.

\section{Fundamentals}
\label{sec:fundamentals}

\subsection{Optimal Predictors}

We start with a simple model to help build intuition and motivate the following definitions.

Consider finite sets $X$ and $Y$, a probability distribution $\mu: X \rightarrow [0,1]$, a mapping $m: X \rightarrow Y$ and a function $f: X \rightarrow \Reals$. Suppose $x$ was sampled from $\mu$ and we were told $y := m(x)$ (but not told $x$ itself). Our expected value of $f(x)$ in these conditions is $\E[f(x)] = \E_{x' \sim \mu}[f(x') \mid m(x') = y]$.

Let $P: X \rightarrow \Reals$ be the function $P(x) := \E_{x' \sim \mu}[f(x') \mid m(x) = m(x)]$. How can we characterize $P$ without referring to the concept of a conditional expected value? For any $Q: X \rightarrow \Reals$ we can consider the "error" $\E_\mu[(Q - f)^2]$. $Q$ is called "efficient" when it factors as $Q = q \circ m$ for some $q: Y \rightarrow \Reals$. It is easy to see that $P$ has the least error among all efficient functions.

Note that the characterization of $P$ depends not only on $f$ but also on $\mu$. That is, the accuracy of an estimator depends on the prior probabilities to encounter different questions. In general, we assume that the possible questions are indexed by elements of $\Words$. Thus we need to consider a probability distribution on $\Words$. However, in the spirit of average-complexity theory we will only require our estimators to be \emph{asymptotically} optimal. Therefore instead of considering a single probability distribution we consider a family of probability distribution indexed by an integer parameter, where the role of the parameter is defining the relevant limit. We thereby arrive at the following:

\begin{definition}

A \emph{word ensemble} $\mu$ is a family of probability distributions $\{\mu^k: \Words \rightarrow [0,1]\}_{k \in \Nats}$.

\end{definition}

We now introduce our abstraction for a "class of mathematical questions" (with quantitative real-valued answers). This abstraction is a trivial generalization of the concept of a distributional decision problem from average-case complexity theory (see e.g. \cite{Bogdanov_2006}).

\begin{definition}

A \emph{distributional estimation problem} is a pair $(\mu,f)$ where $\mu$ is a word ensemble and $f: \Supp \mu \rightarrow \Reals$ is bounded.

\end{definition}

In the motivational model, the estimator was restricted to lie in a class of functions that factor through a fixed mapping. Of course we are interested in more realistic notions of efficiency. In the present work we consider restrictions on time complexity, access to random bits and size of advice strings. Spatial complexity is also of interest but treating it is out of our current scope. It is possible to consider weaker or stronger restrictions which we represent using the following abstraction:

\begin{definition}

Fix $n$. A \emph{growth space} $\Gamma$ of rank $n$ is a set of functions ${\gamma: \Nats^n \rightarrow \Nats}$ s.t.

\begin{enumerate}[(i)]

\item If $\gamma_1, \gamma_2 \in \Gamma$ then $\gamma_1 + \gamma_2 \in \Gamma$.

\item If $\gamma_1 \in \Gamma$, $\gamma_2: \Nats^n \rightarrow \Nats$ and $\forall K \in \Nats^n: \gamma_2(K) \leq \gamma_1(K)$ then $\gamma_2 \in \Gamma$.

\item $0 \in \Gamma$

\end{enumerate}

\begin{example}

For any $n \in \Nats$, $\Gamma_0^n$ is a growth space of rank $n$. $\gamma \in \Gamma_0^n$ iff $\gamma \equiv 0$.

\end{example}

\end{definition}

\begin{example}

For any $n \in \Nats$, $\Gamma_{\text{poly}}^n$ is a growth space of rank $n$. $\gamma \in \Gamma_{\text{poly}}^n$ iff there is a polynomial $p: \Nats^n \rightarrow \Nats$ s.t. $\gamma(K) \leq p(K)$.

\end{example}

\begin{example}

For any $n \in \Nats$, $\Gamma_{\text{log}}^n$ is a growth space of rank $n$. $\gamma \in \Gamma_{\text{log}}^n$ iff there is $c \in \Nats$ s.t. $\gamma(K_1, K_2 \ldots K_n) \leq c \sum_{i=1}^n \log(K_i+1)$.

\end{example}

We now introduce our notion of an "efficient" algorithm.

\begin{definition}

Fix $n \in \Nats$ and $\Gamma=(\GrowR$, $\GrowA)$ a pair of growth spaces of rank $n$. Given encoded sets $X$ and $Y$, a \emph{$\Gamma$-scheme of signature $X \rightarrow Y$} is a triple $(S,\R_S,\A_S)$ where $S: \Nats^n \times X \times \Words^2 \Alg Y$, $\R_S: \Nats^n \times \Words \Alg \Nats$ and $\A_S: \Nats^n \rightarrow \Words$ are s.t.

\begin{enumerate}[(i)]

\item There is a polynomial $p: \Nats^n \rightarrow \Nats$ s.t. for any $K \in \Nats^n$, $x \in X$ and $y \in \WordsLen{\R_S(K)}$, $\T_S(K,x,y,\A_S(K)) \leq p(K)$.

\item There is a polynomial $q: \Nats^n \rightarrow \Nats$ s.t. for any $K \in \Nats^n$, ${\T_{\R_S}(K,\A_S(K)) \leq q(K)}$.

\item The function $r: \Nats^n \rightarrow n$ defined by $r(K):=\R_S(K,\A_S(K))$ lies in $\GrowR$.

\item $\Abs{\A_S} \in \GrowA$

\end{enumerate}

Abusing notation, we denote the $\Gamma$-scheme $(S,\R_S,\A_S)$ by $S$. $S^K(x,y,z)$ will denote $S(K,x,y,z)$, $S^K(x,y)$ will denote $S(K,x,y,\A_S(K))$ and $S^K(x)$ will denote the $Y$-valued random variable which equals $S(K,x,y,a(K))$ for $y$ sampled from $U^{\R_S(K)}$. We think of $S$ as a randomized algorithm with advice where $y$ are the internal coin tosses and $\A_S$ is the advice\footnote{Note that the number of random bits $\R_S(k,j)$ has to be efficiently computable modulo the advice $\A_S(k,j)$ rather than being an arbitrary function. This requirement is needed to prevent using the function $\R_S$ as advice in itself. In particular, when $\GrowA=\Gamma_0^2$, $S$ represents a uniform randomized algorithm.}. Similarly, $\R_S(K)$ will denote $\R_S(K,\A_S(K))$.

We will use the notation $S: X \Scheme Y$ to signify $S$ is a $\Gamma$-scheme of signature $X \rightarrow Y$.

\end{definition}

Instead of requiring the time complexity to be polynomial in $K$, we could have used a third growth space which determines the allowed time complexity. However, we make do without this generalization in the current work.

It will also be useful to consider families of $\Gamma$-schemes satisfying uniform resource bounds.

\begin{definition}

Fix $n \in \Nats$, $\Gamma=(\GrowR$, $\GrowA)$ a pair of growth spaces of rank $n$ and encoded sets $X$, $Y$. A set $F$ of $\Gamma$-schemes of signature $X \rightarrow Y$ is called a \emph{uniform family} when

\begin{enumerate}[(i)]

\item There is a polynomial $p_1: \Nats^n \rightarrow \Nats$ s.t. for any $S \in F$, $K \in \Nats^n$, $x \in X$ and $y \in \WordsLen{\R_S(K)}$, $\T_S(K,x,y,\A_S(K)) \leq p_1(K)$.

\item There is a polynomial $p_2: \Nats^n \rightarrow \Nats$ s.t. for any $S \in F$ and $K \in \Nats^n$, $\T_{\R_S}(K,\A_S(K)) \leq p_2(K)$.

\item $\max_{S \in F} \R_S \in \GrowR$

\item There is $l \in \GrowA$ s.t. for any $S \in F$ and $K \in \Nats^n$, ${\Abs{\Quote{S}} + \Abs{\Quote{\R_S}} + \Abs{\A_S(K)} \leq l(K)}$.

\end{enumerate}

\end{definition}

The details of this definition are motivated by the following proposition.

\begin{proposition}
\label{prp:fam_diag}

Fix $n \in \Nats$, $\Gamma=(\GrowR$, $\GrowA)$ a pair of growth spaces of rank $n$ and encoded sets $X$, $Y$. Consider $F$ a uniform family of $\Gamma$-schemes of signature $X \rightarrow Y$ and a collection $\{\mathcal{S}_K \in F\}_{K \in \Nats^n}$. Then, there is $\Delta_\mathcal{S}: X \xrightarrow{
\Gamma} Y$ s.t. for any $K \in \Nats^n$, $x \in X$ and $y \in Y$, $\Pr[\Delta_\mathcal{S}^K(x)=y] = \Pr[\mathcal{S}_K^K(x)=y]$.

\end{proposition}

\begin{proof}

We take $\A_{\Delta_{\mathcal{S}}}(k,j):=\Chev{\Quote{\mathcal{S}_K},\Quote{\R_{\mathcal{S}_K}},\A_{\mathcal{S}_K}(K)}$. $\R_{\Delta_{\mathcal{S}}}$ is constructed so that $\R_{\Delta_{\mathcal{S}}}(K)=\R_{\mathcal{S}_K}(K)$. $\Delta_{\mathcal{S}}$ is constructed so that $\Delta_{\mathcal{S}}^K(x,z)=\mathcal{S}_K^K(x,z)$.

\end{proof}

Note that the concept of a uniform family is non-trivial only when $1 \in \GrowA$, otherwise condition (iv) allows only families of at most one member.

Fix $\Gamma$ a pair of growth spaces of rank 2. The first parameter serves to define asymptotic behavior and can be roughly thought of as determining the size of the input. The second parameter serves to control the resources available to the predictor. To illustrate the significance of the second parameter using the informal\footnote{This example cannot be formalized in the framework as presented here since the set of prime numbers is in $\textsc{P}$. We can probably tackle it by introducing restrictions on spatial resources, but this out of the current scope.} example from Section 1, the question "what is the probability 7614829 is prime?" depends on the amount of available resources. For example, we can use additional resources to test for divisibility by additional smaller primes (or in some more clever way) until eventually we are able to test primality and assign a probability in $\{0,1\}$.

Given a distributional estimation problem $(\mu,f)$ and $Q: \Words \Scheme \Rats$, we can consider the estimation error $\E_{(x,y) \sim \mu^k \times U^{\R_Q(k,j)}}[(Q^{kj}(x,y) - f(x))^2]$. It makes little sense to require this error to be minimal for every $(k,j) \in \Nats^2$, since we can always hard-code a finite number of answers into $Q$ without violating the resource restrictions. Instead we require minimization up to an asymptotically small error. Since it makes sense to consider different kind of asymptotic requirements, we introduce an abstraction that corresponds to this choice.

\begin{definition}

Given $n \in \Nats$, a \emph{fall space of rank $n$} is a set $\Fall$ of bounded functions $\varepsilon: \Nats^n \rightarrow \Reals^{\geq 0}$ s.t.

\begin{enumerate}[(i)]

\item If $\varepsilon_1, \varepsilon_2 \in \Fall$ then $\varepsilon_1 + \varepsilon_2 \in \Fall$.

\item If $\varepsilon_1 \in \Fall$, $\varepsilon_2: \Nats^n \rightarrow \Reals^{\geq 0}$ and $\forall K \in \Nats^n: \varepsilon_2(K) \leq \varepsilon_1(K)$ then $\varepsilon_2 \in \Fall$.

\item There is a polynomial $h: \Nats^n \rightarrow \Nats$ s.t. $2^{-h} \in \Fall$.

\end{enumerate}

\end{definition}

\begin{example}

Given $n \in \Nats$, we define $\Fall_{\text{neg}}^n$, a fall space of rank $n$. For any $\varepsilon: \Nats^n \rightarrow \Reals^{\geq 0}$ bounded, $\varepsilon \in \Fall_{\text{neg}}^n$ iff for any $d \in \Nats$ and polynomials ${p_1,p_2 \ldots p_{n-1}: \Nats \rightarrow \Nats}$

$$\Lim{k} k^d \max_{j_1 \leq p_1(k)} \max_{j_2 \leq p_2(k)} \ldots \max_{j_{n-1} \leq p_{n-1}(k)} \varepsilon(k,j_1,j_2 \ldots j_{n-1}) = 0$$

\end{example}

\begin{example}

Given $n \in \Nats$, we define $\Fall_{\text{uneg}}^n$, a fall space of rank $n$. For any ${\varepsilon: \Nats^n \rightarrow \Reals^{\geq 0}}$ bounded, $\varepsilon \in \Fall_{\text{uneg}}^n$ iff for any $d \in \Nats$, ${J_1,J_2 \ldots J_{n-1}: \Nats \Alg \Nats}$, and polynomials ${p_1,p_2 \ldots p_{n-1}: \Nats \rightarrow \Nats}$, ${q_1,q_2 \ldots q_{n-1}: \Nats \rightarrow \Nats}$, if $J_i \leq p_i$ and $\T_{J_i} \leq q_i$ then

$$\Lim{k} k^d \varepsilon(k,J_1(k),J_2(k) \ldots J_{n-1}(k)) = 0$$

\end{example}

We note a few simple properties of fall spaces which will be useful in the following.

\begin{proposition}
\label{prp:err_spc_zero}

For any fall space $\Fall$, $0 \in \Fall$.

\end{proposition}

\begin{proof}

Follows from conditions (ii) and (iii), since $0 \leq 2^{-h}$.

\end{proof}

\begin{proposition}

For any fall space $\Fall$, $\varepsilon \in \Fall$ and $c \in \Reals^{\geq 0}$, $c \varepsilon \in \Fall$.

\end{proposition}

\begin{proof}

By induction, condition (i) implies that for any $m \in \Nats$, $m\varepsilon \in \Fall$. It follows that $c\varepsilon \in \Fall$ since $c\varepsilon \leq \Ceil{c}\varepsilon$.

\end{proof}

\begin{proposition}

For any fall space $\Fall$ and $\varepsilon_1, \varepsilon_2 \in \Fall$, $\max(\varepsilon_1,\varepsilon_2) \in \Fall$

\end{proposition}

\proof{$$\max(\varepsilon_1,\varepsilon_2) \leq \varepsilon_1+\varepsilon_2$$}

\begin{proposition}
\label{prp:fall_space_closed_wrt_power}

For any fall space $\Fall$, $\varepsilon \in \Fall$ and $\alpha \in \Reals$, if $\alpha \geq 1$ then $\varepsilon^\alpha \in \Fall$.

\end{proposition}

\begin{proof}

$$\varepsilon^\alpha = (\sup \varepsilon)^\alpha (\frac{\varepsilon}{\sup \varepsilon})^\alpha \leq  (\sup \varepsilon)^\alpha \frac{\varepsilon}{\sup \varepsilon} \in \Fall$$

\end{proof}

\begin{proposition}

Consider $\Fall$ a fall space and $\alpha \in \Reals^{>0}$. Define ${\Fall^\alpha := \{\varepsilon^\alpha \mid \varepsilon \in \Fall\}}$. Then, $\Fall^\alpha$ is a fall space.

\end{proposition}

\begin{proof}

To check condition (i), consider $\varepsilon_1, \varepsilon_2 \in \Fall$. 

If $\alpha > 1$, $(\varepsilon_1^\alpha + \varepsilon_2^\alpha)^\frac{1}{\alpha} \leq \varepsilon_1 + \varepsilon_2 \in \Fall$ hence $(\varepsilon_1^\alpha + \varepsilon_2^\alpha)^\frac{1}{\alpha} \in \Fall$ and $\varepsilon_1^\alpha + \varepsilon_2^\alpha \in \Fall^\alpha$.

If $\alpha \leq 1$, $(\varepsilon_1^\alpha + \varepsilon_2^\alpha)^\frac{1}{\alpha} = 2^\frac{1}{\alpha}(\frac{\varepsilon_1^\alpha + \varepsilon_2^\alpha}{2})^\frac{1}{\alpha} \leq 2^\frac{1}{\alpha} \frac{\varepsilon_1+\varepsilon_2}{2} \in \Fall$ hence $(\varepsilon_1^\alpha + \varepsilon_2^\alpha)^\frac{1}{\alpha} \in \Fall$ and $\varepsilon_1^\alpha + \varepsilon_2^\alpha \in \Fall^\alpha$.

Conditions (ii) and (iii) are obvious.

\end{proof}

\begin{proposition}

Consider $\Fall$ a fall space and $\alpha_1,\alpha_2 \in \Reals^{>0}$ with $\alpha_1 \leq \alpha_2$. Then, ${\Fall^{\alpha_2} \subseteq \Fall^{\alpha_1}}$.

\end{proposition}

\begin{proof}

Follows from Proposition~\ref{prp:fall_space_closed_wrt_power}.

\end{proof}

We are now ready to give our central definition, which corresponds to a notion of "expected value" for distributional estimation problems.

\begin{definition}
\label{def:op}

Fix $\Gamma$ a pair of growth spaces of rank 2 and $\Fall$ a fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem and $P: \Words \Scheme \Rats$ with bounded range. $P$ is called an \emph{$\Fall(\Gamma)$-optimal predictor for $(\mu,f)$} when for any $Q: \Words \Scheme \Rats$ there is $\varepsilon \in \Fall$ s.t.

\begin{equation}
\label{eqn:op}
\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2] + \varepsilon(k,j)
\end{equation}

\end{definition}

Distributional \emph{decision} problems are the special case when the range of $f$ is $\Bool$. In this special case, the outputs of an optimal predictors can be thought of as probabilities\footnote{With some caveats. First, $P$ can take values outside $[0,1]$ but it's easy to see that clipping all values to $[0,1]$ preserves optimality. Second, $P^{kj}(x,y)=1$ doesn't imply $f(x) = 1$ and $P^{kj}(x,y)=0$ doesn't imply $f(x)=0$. We can try to fix this using a logarithmic error function instead of the squared norm, however this creates other difficulties and is outside the scope of the present work.}.

\subsection{Basic Properties}

In this subsection we discuss some basic properties of optimal predictors which will be used in the following.

Note that $\varepsilon$ in (\ref{eqn:op}) depends on $Q$. However in some sense the optimality condition is automatically uniform w.r.t. the resources required by $Q$.

\begin{proposition}
\label{prp:unif}

Fix $\Gamma=(\GrowR,\GrowA)$ a pair of growth spaces of rank 2 and $\Fall$ a fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem, $P$ an $\Fall(\Gamma)$-optimal predictor for $(\mu,f)$ and $F$ a uniform family of $\Gamma$-schemes of signature $\Words \rightarrow \Rats$. Then there is $\varepsilon \in \Fall$ s.t. for any $Q \in F$, equation~\ref{eqn:op} holds.

\end{proposition}

\begin{proof}

For any $k,j \in \Nats$, $\{\E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2] \mid Q \in F\}$ is a finite set because $F$ is a uniform family so the runtime of $Q^{kj}$ is bounded by a polynomial in $k,j$ that doesn't depend on $Q$. Therefore we can choose ${Q_{kj} \in \Argmin{Q \in F} \E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2]}$. By Proposition~\ref{prp:fam_diag}, there is $\bar{Q}: \Words \Scheme \Rats$ s.t. $\bar{Q}^{kj}(x)$ is distributed the same as $Q_{kj}^{kj}(x)$.

Since $P$ is an $\Fall(\Gamma)$-optimal predictor, there is $\varepsilon \in \Fall$ s.t.

\begin{equation}
\label{eqn:prp__unif__prf1}
\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_{\bar{Q}}(k,j)}}[(\bar{Q}^{kj} - f)^2] + \varepsilon(k,j)
\end{equation}

For any $Q \in F$, we have 

$$\E_{\mu^k \times U^{\R_{\bar{Q}}(k,j)}}[(\bar{Q}^{kj} - f)^2]=\E_{\mu^k \times U^{\R_{Q_{kj}}(k,j)}}[(Q_{kj}^{kj} - f)^2]$$

\begin{equation}
\label{eqn:prp__unif__prf2}
\E_{\mu^k \times U^{\R_{\bar{Q}}(k,j)}}[(\bar{Q}^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2]
\end{equation}

Combining \ref{eqn:prp__unif__prf1} and \ref{eqn:prp__unif__prf2} we get the desired result.

\end{proof}

As usual, random is no more powerful than advice. This is demonstrated by the following two propositions.

\begin{proposition}

Fix $\Gamma=(\GrowR,\GrowA)$ a pair of growth spaces of rank 2 and $\Fall$ a fall space of rank 2. Observe that $\bar{\Gamma}_{\mathfrak{R}}:=\GrowR+\GrowA$ is a growth space and denote $\bar{\Gamma}:=(\bar{\Gamma}_{\mathfrak{R}},\GrowA)$. Consider $(\mu,f)$ a distributional estimation problem and $P$ an $\Fall(\Gamma)$-optimal predictor for $(\mu,f)$. Then, $P$ is also an $\Fall(\bar{\Gamma})$-optimal predictor for $(\mu,f)$.

\end{proposition}

\begin{proof}

Consider any $Q: \Words \xrightarrow{\bar{\Gamma}} \Rats$. Suppose $\R_Q=r_{\mathfrak{R}}+r_{\mathfrak{A}}$ where $r_{\mathfrak{R}} \in \GrowR$ and $r_{\mathfrak{A}} \in \GrowA$. For any $k,j \in \Nats$, choose ${\bar{\A}_Q(k,j) \in \Argmin{y \in \WordsLen{r_{\mathfrak{A}}(k,j)}} \E_{(x,z) \sim \mu^k \times U^{r_{\mathfrak{R}}(k,j)}}[(Q^{kj}(x,yz) - f(x))^2]}$. As easy to see, there is $\bar{Q}: \Words \Scheme \Rats$ s.t. for all $k,j \in \Nats$, $\R_{\bar{Q}}(k,j) = r_{\mathfrak{R}}(k,j)$, $\A_{\bar{Q}}(k,j):=\Chev{\A_Q(k,j),\bar{\A}_Q(k,j)}$ and for any $x \in \Supp \mu^k$ and $z \in \WordsLen{r_{\mathfrak{R}}(k,j)}$, ${\bar{Q}^{kj}(x,z)=Q^{kj}(x,\bar{\A}_Q(k,j)z)}$.

It follows that there is $\varepsilon \in \Fall$ s.t.

$$\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{r_{\mathfrak{R}}(k,j)}}[(\bar{Q}^{kj} - f)^2] + \varepsilon(k,j)$$

Obviously $\E_{\mu^k \times U^{r_{\mathfrak{R}}(k,j)}}[(\bar{Q}^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2]$ therefore

$$\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2] + \varepsilon(k,j)$$

\end{proof}

\begin{proposition}

Fix $\Gamma=(\GrowR,\GrowA)$ a pair of growth spaces of rank 2 and $\Fall$ a fall space of rank 2. Denote $\bar{\Gamma}_{\mathfrak{R}}:=\GrowR+\GrowA$ and $\bar{\Gamma}:=(\bar{\Gamma}_{\mathfrak{R}},\GrowA)$. Consider $(\mu,f)$ a distributional estimation problem and $\bar{P}$ an $\Fall(\bar{\Gamma})$-optimal predictor for $(\mu,f)$. Then, there exists an $\Fall(\Gamma)$-optimal predictor for $(\mu,f)$.

\end{proposition}

\begin{proof}

Suppose $\R_{\bar{P}}=r_{\mathfrak{R}}+r_{\mathfrak{A}}$ where $r_{\mathfrak{R}} \in \GrowR$ and $r_{\mathfrak{A}} \in \GrowA$. For any ${k,j \in \Nats}$, choose ${\bar{\A}_P(k,j) \in \Argmin{y \in \WordsLen{r_{\mathfrak{A}}(k,j)}} \E_{(x,z) \sim \mu^k \times U^{r_{\mathfrak{R}}(k,j)}}[(\bar{P}^{kj}(x,yz) - f(x))^2]}$. We can construct $P: \Words \Scheme \Rats$ so that for all $k,j \in \Nats$, $\R_P(k,j) = r_{\mathfrak{R}}(k,j)$, $\A_P(k,j):=\Chev{\A_{\bar{P}}(k,j),\bar{\A}_P(k,j)}$ and for any $x \in \Supp \mu^k$ and $z \in \WordsLen{r_{\mathfrak{R}}(k,j)}$, ${P^{kj}(x,z)=\bar{P}^{kj}(x,\bar{\A}_P(k,j)z)}$. Clearly ${\E_{\mu^k \times U^{r_{\mathfrak{R}}(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_{\bar{P}}(k,j)}}[(\bar{P}^{kj} - f)^2]}$ and therefore $P$ is an $\Fall(\Gamma)$-optimal predictor for $(\mu,f)$.

\end{proof}

Although the word ensemble plays a central role in the definition of an optimal predictor, the dependence on the word ensemble is lax in some sense. To see this, consider the following proposition.

\begin{definition}

Given $n \in \Nats$, a growth space $\Gamma$ of rank $n$ and a fall space $\Fall$ of rank $n$, $\Fall$ is called \emph{$\Gamma$-ample} when there is $\zeta: \Nats^n \rightarrow (0,\frac{1}{2}]$ s.t.  $\zeta \in \Fall$ and $\Floor{\log \frac{1}{\zeta}} \in \Gamma$.

\end{definition}

\begin{proposition}
\label{prp:weight}

Fix $\Grow$ a pair of growth spaces of rank 2 and $\Fall$ a $\GrowA$-ample fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem, $P$ an $\Fall(\Gamma)$-optimal predictor for $(\mu,f)$, $Q: \Words \Scheme \Rats$ and ${W: \Words \Scheme \Rats^{\geq 0}}$ bounded s.t. $\R_W \geq \max(\R_P, \R_Q)$. Denote ${\mu^{kj}_{P,W}:=\mu^k \times U^{\R_P(k,j)} \times U^{\R_W(k,j)-\R_P(k,j)}}$, ${\mu^{kj}_{Q,W}:=\mu^k \times U^{\R_Q(k,j)} \times U^{\R_W(k,j)-\R_Q(k,j)}}$. Then, there is $\varepsilon \in \Fall$ s.t.

\begin{equation}
\E_{\mu^{kj}_{P,W}}[W^{kj}(P^{kj} - f)^2] \leq \\ \E_{\mu^{kj}_{Q,W}}[W^{kj}(Q^{kj} - f)^2] + \varepsilon(k,j)
\end{equation}

\end{proposition}

To relationship to the role of the word ensemble is as follows.

\begin{samepage}
\begin{corollary}

Fix $\Grow$ a pair of growth spaces of rank 2 and $\Fall$ a $\GrowA$-ample fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem and $P$ an $\Fall(\Gamma)$-optimal predictor for $(\mu,f)$. Suppose $\Gamma^1:=(\GrowR^1,\GrowA^2)$ is a pair of growth spaces of rank 1 s.t. for any $\gamma \in \GrowR^1$ the function ${\gamma^2(k,j):=\gamma(k)}$ is in $\GrowR$ and for any $\gamma \in \GrowA^1$ the function $\gamma^2(k,j):=\gamma(k)$ is in $\GrowA$. Consider ${W: \Words \xrightarrow{\Gamma^1} \Rats^{\geq 0}}$ bounded s.t. for any $k \in \Nats$ there is $x \in \Supp \mu^k$ and $y \in \WordsLen{\R_W(k)}$ s.t. $W^k(x,y) > 0$. Define 

$${\Fall_W:=\{\varepsilon_W: \Nats^2 \rightarrow \Reals^{\geq 0} \textnormal{ bounded} \mid  \E_{\mu^k \times U^{\R_W(k)}}[W^k]\varepsilon_W(k,j) \in \Fall\}}$$

It is easy to see $\Fall_W$ is a fall space. Define the word ensemble $\nu$ by ${\nu^k(x):=\frac{\E_{U^{\R_W(k)}}[W^k(x)] \mu^k(x)}{\E_{\mu^k \times U^{\R_W(k)}}[W^k(x)]}}$. Then, $P$ is an $\Fall_W(\Gamma)$-optimal predictor for $(\nu,f)$.

\end{corollary}
\end{samepage}

\begin{proof}

Consider any $Q: \Words \Alg \Rats$. Proposition~\ref{prp:weight} implies there is $\varepsilon \in \Fall$ s.t.

$$\E_{\mu^k \times U^{\R_P(k,j)} \times U^{\R_W(k)}}[W^k(P^{kj} - f)^2] \leq \\ \E_{\mu^k \times U^{\R_Q(k,j)} \times U^{\R_W(k)}}[W^k(Q^{kj} - f)^2] + \varepsilon(k,j)$$

$$\E_{\mu^k \times U^{\R_P(k,j)}}[\E_{U^{\R_W(k)}}[W^k](P^{kj} - f)^2] \leq \\ \E_{\mu^k \times U^{\R_Q(k,j)}}[\E_{U^{\R_W(k)}}[W^k](Q^{kj} - f)^2] + \varepsilon(k,j)$$

Dividing both sides of the inequality by $\E_{\mu^k \times U^{\R_W(k)}}[W^k(x)]$ we get

$$\E_{\nu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \\ \E_{\nu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2] + \frac{\varepsilon(k,j)}{\E_{\mu^k \times U^{\R_W(k)}}[W^k(x)]}$$

Let $M$ be the supremum of the left hand side.

$$\E_{\nu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \\ \E_{\nu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2] + \min(\frac{\varepsilon(k,j)}{\E_{\mu^k \times U^{\R_W(k)}}[W^k(x)]},M)$$

The second term on the right hand side is clearly in $\Fall_W$.

\end{proof}

We now give the proof of Proposition~\ref{prp:weight}.

\begin{proof}[Proof of \ref{prp:weight}]

Consider $\zeta: \Nats^2 \rightarrow (0,\frac{1}{2}]$ s.t.  $\zeta \in \Fall$ and $\Floor{\log \frac{1}{\zeta}} \in \GrowA$. For any $k,j \in \Nats$ and $t \in \Reals$, let $\rho_\zeta^{kj}(t) \in \Argmin{s \in \Rats \cap [t-\zeta(k,j),t+\zeta(k,j)]} \Abs{\En_\Rats(s)}$. Denote $M:= \sup W$. It is easy to see that there is $\gamma \in \GrowA$ s.t. for any $t \in [0, M]$, ${\Abs{\En_\Rats(\rho_\zeta^{kj}(t))} \leq \gamma(k,j)}$.

For any $t \in \Reals$ there is $Q_t: \Words \Scheme \Rats$ s.t. $\R_Q=\R_W$ and for any $x \in \Supp \mu^k$ and ${y \in \WordsLen{\R_W(k,j)}}$

$$Q_t^{kj}(x,y)=\begin{cases}Q^{kj}(x,y_{\leq \R_Q(k,j)}) \text{ if } W^{kj}(x,y) \geq \rho^{kj}_\zeta(t) \\ P^{kj}(x,y_{\leq \R_P(k,j)}) \text{ if } W^{kj}(x,y) < \rho^{kj}_\zeta(t)\end{cases}$$

Moreover we can construct the $Q_t$ for all $t \in [0, M]$ s.t. they form a uniform family. By Proposition~\ref{prp:unif} there is $\varepsilon \in \Fall$ s.t. for all $t \in [0, M]$

$$\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj}-f)^2] \leq \E_{\mu^k \times U^{\R_W(k,j)}}[(Q_t^{kj}-f)^2] + \varepsilon(k,j)$$

$$\E_{(x,y) \sim \mu^k \times U^{\R_W(k,j)}}[(P^{kj}(x,y_{\leq \R_P(k,j)})-f(x))^2-(Q_t^{kj}(x,y)-f(x))^2] \leq \varepsilon(k,j)$$

The expression inside the expected values vanishes when $W^{kj}(x,y) < \rho^{kj}_\zeta(t)$. In other cases, $Q_t^{kj}(x,y) = Q^{kj}(x,y_{\leq \R_Q(k,j)})$. We get

$$\E_{(x,y) \sim \mu^k \times U^{\R_W(k,j)}}[\theta(W^{kj}(x,y)-\rho_\zeta^{kj}(t)) \cdot ((P^{kj}(x,y_{\leq \R_P(k,j)})-f(x))^2-(Q^{kj}(x,y_{\leq \R_Q(k,j)})-f(x))^2)] \leq \varepsilon(k,j)$$

We integrate both sides of the inequality over $t$ from 0 to $M$.

\begin{equation}
\label{eqn:prp__weight__prf1}
\E[\int_0^M\theta(W^{kj}-\rho_\zeta^{kj}(t)) \dif t \cdot ((P^{kj}-f)^2-(Q^{kj}-f)^2)] \leq M \varepsilon(k,j)
\end{equation}

For any $s \in \Reals$

$$\int_0^M \theta(s-\rho_\zeta^{kj}(t)) \dif t = \int_0^{s-\zeta(k,j)} \theta(s-\rho_\zeta^{kj}(t)) \dif t + \int_{s-\zeta(k,j)}^{s+\zeta(k,j)} \theta(s-\rho_\zeta^{kj}(t)) \dif t + \int_{s+\zeta(k,j)}^M \theta(s-\rho_\zeta^{kj}(t)) \dif t$$

$\Abs{\rho_\zeta^{kj}(t)-t} \leq \zeta(k,j)$ therefore the integrand in the first term is 1 and in the last term 0:

$$\int_0^M \theta(s-\rho_\zeta^{kj}(t)) \dif t = \int_0^{s-\zeta(k,j)} \dif t + \int_{s-\zeta(k,j)}^{s+\zeta(k,j)} \theta(s-\rho_\zeta^{kj}(t)) \dif t$$

$$\int_0^M \theta(s-\rho_\zeta^{kj}(t)) \dif t = s-\zeta(k,j) + \int_{s-\zeta(k,j)}^{s+\zeta(k,j)} \theta(s-\rho_\zeta^{kj}(t)) \dif t$$

$$\int_0^M \theta(s-\rho_\zeta^{kj}(t)) \dif t - s = \zeta(k,j) + \int_{s-\zeta(k,j)}^{s+\zeta(k,j)} \theta(s-\rho_\zeta^{kj}(t)) \dif t$$

\begin{equation}
\label{eqn:prp__weight__prf2}
\int_0^M \theta(s-\rho_\zeta^{kj}(t)) \dif t - s \in [0,3\zeta(k,j)]
\end{equation}

Combining \ref{eqn:prp__weight__prf1} and \ref{eqn:prp__weight__prf2} we conclude that for some $M' \in \Reals^{\geq 0}$

$$\E[W^{kj} \cdot ((P^{kj}-f)^2-(Q^{kj}-f)^2)] \leq M \varepsilon(k,j) + M'\zeta(k,j)$$

\end{proof}

\subsection{Orthogonality Theorems}

There is a variant of Definition~\ref{def:op} which is nearly equivalent in many cases and often useful.

We can think of functions $f: \Supp \mu \rightarrow \Reals$ as vectors in a real inner product space with inner product $\Chev{f,g}:=\E_\mu[fg]$. Informally, we can think of $\Gamma$-schemes as a subspace (although a $\Gamma$-scheme is not even a function) and an $\Fall(\Gamma)$-optimal predictor for $(\mu,f)$ as the nearest point to $f$ in this subspace. Now, given an inner product space $V$, a vector $f \in V$, an actual subspace $W \subseteq V$ and $p = \Argmin{q \in W} \Norm{q - f}^2$, we have $\forall v \in W: \Chev{p-f,v}=0$. This motivates the following:

\begin {definition}

Fix $\Gamma$ a pair of growth spaces of rank 2 and $\Fall$ a fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem and $P: \Words \Scheme \Rats$ with bounded range. $P$ is called an \emph{$\Fall^\sharp(\Gamma)$-optimal predictor for $(\mu,f)$} when for any $S: \Words \Scheme \Rats$ with $\R_S \geq \R_P$

\begin{equation}
\label{eqn:op_sharp}
\Abs{\E_{(x,y,z) \sim \mu^k \times U^{\R_P(k,j)} \times U^{\R_S(k,j)-\R_P(k,j)}}[(P^{kj}(x,y) - f(x))S^{kj}(x,yz)]} \in \Fall
\end{equation}

\end {definition}

The following theorem is the analogue in our language of the previous fact about inner product spaces.

\begin{theorem}
\label{thm:ort}

Fix $\Gamma=(\GrowR$, $\GrowA)$ a pair of growth spaces of rank 2 and $\Fall$ a fall space of rank 2. Assume there is $\zeta: \Nats^2 \rightarrow (0,\frac{1}{4}]$ s.t. $\zeta \in \Fall^{\frac{1}{2}}$ and ${\Floor{\log \log \frac{1}{\zeta}} \in \GrowA}$\footnote{If $\Floor{\log(k+2)}, \Floor{\log(j+2)} \in \GrowA$ (equivalently $\Gamma_{\text{log}}^2 \subseteq \GrowA$) then this condition holds for any $\Fall$ since we can take $\zeta = 2^{-h}$ for $h$ polynomial.}. Consider $(\mu,f)$ a distributional estimation problem and $P$ an $\Fall(\Gamma)$-optimal predictor for $(\mu,f)$. Then, $P$ is also an $\Fall^{\frac{1}{2}\sharp}(\Gamma)$-optimal predictor for $(\mu,f)$.

\end{theorem}

\begin{proof}

Assume without loss of generality that there is a polynomial ${h: \Nats^2 \rightarrow \Nats}$ s.t. $\zeta \geq 2^{-h}$ (otherwise we can take any polynomial $h$ s.t. $2^{-h} \in \Fall$ and consider $\zeta':=\zeta+2^{-h}$). Fix $S: \Words \Scheme \Rats$ with $\R_S \geq \R_P$. Consider any ${\sigma: \Nats^2 \rightarrow \{ \pm 1 \}}$ and $n: \Nats^2 \rightarrow \Nats$ s.t. $n \leq \log \frac{1}{\zeta}$ (in particular $n \leq h$). Define ${t(k,j) := \sigma(k,j) 2^{-n(k,j)}}$. It is easy to see there is $Q_t: \Words \Scheme \Rats$ s.t. given $k,j \in \Nats$, $x \in \Supp \mu^k$, ${y \in \WordsLen{\R_P(k,j)}}$ and $z \in \WordsLen{\R_P(k,j) - \R_S(k,j)}$, $Q_t^{kj}(x,yz) = P^{kj}(x,y) + t(k,j) S^{kj}(x,yz)$. Moreover, we can construct $Q_t$ for all admissible choices of $t$ (but fixed $S$) to get a uniform family.

Applying Proposition~\ref{prp:unif}, we conclude that there is $\varepsilon \in \Fall$ which doesn't depend on $t$ s.t.

$$\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_S(k,j)}}[(Q_t^{kj} - f)^2] + \varepsilon(k,j)$$

$$\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} + t(k,j)S^{kj}  - f)^2] + \varepsilon(k,j)$$

$$\E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f)^2 - (P^{kj} + t(k,j)S^{kj} - f)^2] \leq \varepsilon(k,j)$$

$$-\E_{\mu^k \times U^{\R_S(k,j)}}[(t(k,j)S^{kj} + 2 (P^{kj} - f)) S^{kj}] t(k,j) \leq \varepsilon(k,j)$$

$$-\E_{\mu^k \times U^{\R_S(k,j)}}[(S^{kj})^2] t(k,j)^2 + 2 \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}] t(k,j) \leq \varepsilon(k,j)$$

$$2 \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}] t(k,j) \leq \E_{\mu^k \times U^{\R_S(k,j)}}[(S^{kj})^2] t(k,j)^2 + \varepsilon(k,j)$$

$$2 \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}] t(k,j) \leq (\sup \Abs{S^{kj}})^2 t(k,j)^2 + \varepsilon(k,j)$$

$$2 \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}] \sigma(k,j) 2^{-n(k,j)} \leq (\sup \Abs{S^{kj}})^2 4^{-n(k,j)} + \varepsilon(k,j)$$

Multiplying both sides by $2^{n(k,j)-1}$ we get

$$\E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}] \sigma(k,j) \leq \frac{1}{2}((\sup \Abs{S^{kj}})^2 2^{-n(k,j)} + \varepsilon(k,j) 2^{n(k,j)})$$

Let $\sigma(k,j):=\Sgn \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}]$.

$$\Abs{\E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}]} \leq \frac{1}{2}((\sup \Abs{S^{kj}})^2 2^{-n(k,j)} + \varepsilon(k,j) 2^{n(k,j)})$$

Let $n(k,j):=\min(\Floor{\frac{1}{2}\log \max(\frac{1}{\varepsilon(k,j)},1)},\Floor{\log \frac{1}{\zeta(k,j)}})$.

$$\Abs{\E[(P^{kj} - f) S^{kj}]} \leq (\sup \Abs{S^{kj}})^2 \max(\min(\varepsilon(k,j)^{\frac{1}{2}},1),\zeta(k,j)) + \frac{1}{2}\varepsilon(k,j) \min(\max(\varepsilon(k,j)^{-\frac{1}{2}},1),\zeta(k,j)^{-1})$$

$$\Abs{\E[(P^{kj} - f) S^{kj}]} \leq (\sup \Abs{S^{kj}})^2 \max(\varepsilon(k,j)^{\frac{1}{2}},\zeta(k,j)) + \frac{1}{2} \max(\varepsilon(k,j)^{\frac{1}{2}},\varepsilon(k,j))$$

The right hand side is obviously in $\Fall^{\frac{1}{2}}$.

\end{proof}

Conversely, we have the following:

\begin{theorem}

Fix $\Gamma=(\GrowR$, $\GrowA)$ a pair of growth spaces of rank 2 and $\Fall$ a fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem and $P$ an $\Fall^\sharp(\Gamma)$-optimal predictor for $(\mu,f)$. Then, $P$ is also an $\Fall(\Gamma)$-optimal predictor for $(\mu,f)$.

\end{theorem}

\begin{proof}

Consider any $Q: \Words \Scheme \Rats$. We have

$$\E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj}-f)^2]=\E_{\mu^k \times U^{\R_Q(k,j)} \times U^{\R_P(k,j)}}[(Q^{kj}-P^{kj}+P^{kj}-f)^2]$$

$$\E[(Q^{kj}-f)^2]=\E[(Q^{kj}-P^{kj})^2]+2\E[(Q^{kj}-P^{kj})(P^{kj}-f)]+\E[(P^{kj}-f)^2]$$

$$\E[(P^{kj}-f)^2]+\E[(Q^{kj}-P^{kj})^2]=\E[(Q^{kj}-f)^2]+2\E[(P^{kj}-Q^{kj})(P^{kj}-f)]$$

$$\E[(P^{kj}-f)^2] \leq \E[(Q^{kj}-f)^2] + 2\E[(P^{kj}-Q^{kj})(P^{kj}-f)]$$

Applying \ref{eqn:op_sharp}, we conclude that there is $\varepsilon \in \Fall$ s.t. \ref{eqn:op} holds.

\end{proof}

\subsection{Simple Example}
\label{sec:fundamentals__one_way}

The concept of an optimal predictor is in some sense complementary to the concept of pseudorandom: a pseudorandom process deterministically produces output that appears random to bounded algorithms whereas optimal predictors compute the moments of the perceived random distributions of the outputs of deterministic processes. To demonstrate this complementarity and give an elementary example of an optimal predictor, we use the concept of a hard-core predicate (which may be regarded as en elementary example of pseudorandom).

\begin{theorem}
\label{thm:hard_core}

Consider $\mu$ a word ensemble s.t. for any different $k,l \in \Nats$, $\Supp \mu^k \cap \Supp \mu^l = \varnothing$, $f: \Supp \mu \rightarrow \Words$ one-to-one and $B$ a hard-core predicate of $(\mu,f)$. For every $k \in \Nats$, define $\mu_f^k:=f_*^k(\mu^k).$ Define ${K: \Supp \mu \rightarrow \Nats}$ by $\forall x \in \Supp \mu^k: K(x):=k$. Finally, define $\chi_B: \Supp \mu_f \rightarrow \Bool$ by ${\chi_B(f(x)):=B^{K(x)}(x)}$.

Denote $\Gamma:=(\Gamma_{\textnormal{poly}}^2,\Gamma_0^2)$. Let $P: \Words \Scheme \Rats$ satisfy $P \equiv \frac{1}{2}$. Then, $P$ is an $\Fall_{\textnormal{uneg}}^2(\Gamma)$-optimal predictor\footnote{Because of the way $\Fall_{\text{uneg}}^2$ is defined, we can also think of $P$ as a $(\Gamma_{\text{poly}}^1,\Gamma_0^1)$-scheme which is optimal among such schemes up to an error in $\Fall_{\text{neg}}^1$.} for $(\mu_f, \chi_B)$.

\end{theorem}

\begin{proof}

Assume to the contrary that $P$ is not optimal. Then there is ${Q: \Words \Scheme \Rats}$, $d \in \Nats$, $J: \Nats \Alg \Nats$, polynomials $p,q: \Nats \rightarrow \Nats$, an infinite set ${I \subseteq \Nats}$ and $\epsilon \in \Reals^{>0}$ s.t. $J \leq p$, $\T_J \leq q$ and

$$ \forall k \in I: \E_{\mu_f^k}[(\frac{1}{2}-\chi_B)^2] \geq \E_{\mu_f^k \times U^{\R_Q(k,J(k))}}[(Q^{k,J(k)}-\chi_B)^2] +\frac{\epsilon}{k^d}$$

$$ \forall k \in I: \E_{\mu_f^k \times U^{\R_Q(k,J(k))}}[(Q^{k,J(k)}-\chi_B)^2] \leq \frac{1}{4} - \frac{\epsilon}{k^d} $$

$$ \forall k \in I: \E_{\mu_f^k}[(\E_{U^{\R_Q(k,J(k))}}[Q^{k,J(k)}]-\chi_B)^2] \leq \frac{1}{4} - \frac{\epsilon}{k^d} $$

Denoting $\Gamma^1:=(\Gamma_{\text{poly}}^1,\Gamma_0^1)$, there is $G: \Words \xrightarrow{\Gamma^1} \Bool$ s.t. for all ${x \in \Words}$, ${\Abs{\E[Q^{k,J(k)}(x)]-\Pr[G^k(x)=1]}\leq 2^{-k}}$ ($G^k$ works by evaluating ${\alpha \leftarrow Q^{k,J(k)}}$ and then returning 1 with probability $\alpha \pm 2^{-k}$ and 0 with probability $1-\alpha \pm 2^{-k}$, where the $2^{-k}$ error comes from rounding a rational number to a binary fraction). Denoting $\delta(x):=\E[Q^{k,J(k)}(x)]-\Pr[G^k(x)=1]$

$$ \forall k \in I: \E_{\mu_f^k}[(\Prb_{U^{\R_G(k)}}[G^k=1]+\delta-\chi_B)^2] \leq \frac{1}{4} - \frac{\epsilon}{k^d} $$

$$ \forall k \in I: \E_{\mu_f^k}[(\Prb_{U^{\R_G(k)}}[G^k=1]-\chi_f)^2]+2 \E_{\mu_f^k}[(\Prb_{U^{\R_G(k)}}[G^k=1]-\chi_B)\delta]+\E_{\mu_f^k}[\delta^2] \leq \frac{1}{4} - \frac{\epsilon}{k^d}$$

$$ \forall k \in I: \E_{\mu_f^k}[(\Prb_{U^{\R_G(k)}}[G^k=1]-\chi_B)^2]-2 \cdot 2^{-k}- 4^{-k} \leq \frac{1}{4} - \frac{\epsilon}{k^d}$$

Since $2^{-k}$ falls faster than $k^{-d}$, there is $I_1 \subseteq \Nats$ infinite and $\epsilon_1 \in \Reals^{>0}$ s.t.

$$ \forall k \in I_1: \E_{\mu_f^k}[(\Prb_{U^{\R_G(k)}}[G^k=1]-\chi_B)^2] \leq \frac{1}{4} - \frac{\epsilon_1}{k^d}$$

$$ \forall k \in I_1: \E_{\mu_f^k}[\Abs{\Prb_{U^{\R_G(k)}}[G^k=1]-\chi_B}] \leq \sqrt{\frac{1}{4} - \frac{\epsilon_1}{k^d}} $$

$$ \forall k \in I_1: \E_{\mu_f^k}[\Prb_{U^{\R_G(k)}}[G^k \ne \chi_B]] \leq \sqrt{\frac{1}{4} - \frac{\epsilon_1}{k^d}} $$

$$ \forall k \in I_1: \E_{x \sim \mu^k}[\Prb_{U^{\R_G(k)}}[G^k(f(x)) \ne B^k(x)]] \leq \sqrt{\frac{1}{4} - \frac{\epsilon_1}{k^d}} $$

$$ \forall k \in I_1: \Prb_{\mu^k \times U^{\R_G(k)}}[G^k(f(x)) \ne B^k(x)] \leq \sqrt{\frac{1}{4} - \frac{\epsilon_1}{k^d}} $$

Since $\sqrt{t}$ is a concave function and the derivative of $\sqrt{t}$ is $\frac{1}{2\sqrt{t}}$, we have $\sqrt{t} \leq \sqrt{t_0} + \frac{t-t_0}{2\sqrt{t_0}}$. We get

$$ \forall k \in I_1: \Prb_{\mu^k \times U^{\R_G(k)}}[G^k(f(x)) \ne B^k(x)] \leq \frac{1}{2}-\frac{\epsilon_1}{k^d}$$

$$ \forall k \in I_1: \Prb_{\mu^k \times U^{\R_G(k)}}[G^k(f(x)) = B^k(x)] \geq \frac{1}{2}+\frac{\epsilon_1}{k^d}$$

This contradicts the definition of hard-core predicate.

\end{proof}

\begin{corollary}
\label{thm:one_way}

Consider $f: \Words \Alg \Words$ a one-to-one one-way function. For every $k \in \Nats$, define $f^{(k)}: \WordsLen{k} \times \WordsLen{k} \rightarrow \Words$ by ${f^{(k)}(x,y):=\Chev{f(x),y}}$. Define $\mu_{(f)}^k:=f_*^{(k)}(U^k \times U^k).$ Finally, define $\chi_f: \Supp \mu \rightarrow \Bool$ by ${\chi_f(\Chev{f(x),y}):=x \cdot y}$.

Denote $\Gamma:=(\Gamma_{\textnormal{poly}}^2,\Gamma_0^2)$. Let $P: \Words \Scheme \Rats$ satisfy $P \equiv \frac{1}{2}$. Then, $P$ is an $\Fall_{\textnormal{uneg}}^2(\Gamma)$-optimal predictor for $(\mu_{(f)}, \chi_f)$.

\end{corollary}

\begin{proof}

Follows immediately from Theorem~\ref{thm:hard_core} and Theorem~\ref{thm:goldreich_levin}.

\end{proof}

The following is the non-uniform version of Theorem~\ref{thm:hard_core} which we state without proof since the proof is a straightforward adaptation of the above.

\begin{theorem}
\label{thm:hard_core_circ}

Consider $\mu$ a word ensemble s.t. for any different $k,l \in \Nats$, $\Supp \mu^k \cap \Supp \mu^l = \varnothing$, $f: \Supp \mu \rightarrow \Words$ one-to-one and $B$ a non-uniformly hard-core predicate of $(\mu,f)$. 

Denote $\Gamma:=(\Gamma_{\textnormal{poly}}^2,\Gamma_{\textnormal{poly}}^2)$. Let $P: \Words \Scheme \Rats$ satisfy $P \equiv \frac{1}{2}$. Then, $P$ is an $\Fall_{\textnormal{neg}}^2(\Gamma)$-optimal predictor\footnote{Because of the way $\Fall_{\text{neg}}^2$ is defined, we can also think of $P$ as a $(\Gamma_{\text{poly}}^1,\Gamma_{\text{poly}}^1)$-scheme which is optimal among such schemes up to an error in $\Fall_{\text{neg}}^1$.} for $(\mu_f, \chi_B)$.

\end{theorem}

\begin{corollary}

Consider $f: \Words \Alg \Words$ a one-to-one non-uniformly hard to invert one-way function.

Denote $\Gamma:=(\Gamma_{\textnormal{poly}}^2,\Gamma_{\textnormal{poly}}^2)$. Let $P: \Words \Scheme \Rats$ satisfy $P \equiv \frac{1}{2}$. Then, $P$ is an $\Fall_{\textnormal{neg}}^2(\Gamma)$-optimal predictor for $(\mu_f, \chi_f)$.

\end{corollary}

\begin{proof}

Follows immediately from Theorem~\ref{thm:hard_core_circ} and Theorem~\ref{thm:goldreich_levin_circ}.

\end{proof}

\section{Optimal Predictors and Probability Theory}
\label{sec:probability}

\subsection{Calibration}

From a Bayesian perspective, a good probability assignment should be calibrated. For example, suppose there 100 people in a room and you assign each person a probability they are married. If there are 60 people you assigned probabilities in the range 70\%-80\%, the number of married people among these 60 should be close to the interval $60 \times [0.7, 0.8] = [42,48]$. The same requirement can be made for expected value assignments. For example, if you now need to assign an expected value to the age of each person and you assigned an expected age in the range 30-40 to some sufficiently large group of people, the mean age in the group should be close to the interval $[30,40]$. 

We will now show that optimal predictors satisfy an analogous property.

\begin{theorem}
\label{thm:calib}

Fix $\Grow$ a pair of growth spaces of rank 2 and $\Fall$ a $\GrowA$-ample fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem, $P$ an $\Fall(\Gamma)$-optimal predictor for $(\mu,f)$ and ${W: \Words \Scheme \Rats^{\geq 0}}$ bounded s.t. $\R_W \geq \R_P$ and for every $k,j \in \Nats$ there is $x \in \Supp \mu^k$ and $y \in U^{\R_W(k,j)}$ with $W^{kj}(x,y) > 0$. Denote ${\alpha(k,j):=\E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}]}$ and ${\delta(k,j):=\E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}(P^{kj}-f)]}$. Then, $\frac{\delta^2}{\alpha} \in \Fall$.

\end{theorem}

To see the relationship between Theorem~\ref{thm:calib} and calibration, consider the following corollary.

\begin{corollary}
\label{crl:calib}

Fix $\Grow$ a pair of growth spaces of rank 2 and $\Fall$ a $\GrowA$-ample fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem, $P$ an $\Fall(\Gamma)$-optimal predictor for $(\mu,f)$ and $A,B: \bm{1} \Scheme \Rats$ s.t. $\R_A \equiv 0$ and $\R_B \equiv 0$. Denote ${\alpha(k,j):=\Prb_{\mu^k \times U^{\R_P(k,j)}}[A^{kj} \leq P^{kj} \leq B^{kj}]}$. Then, there is $\varepsilon \in \Fall$ s.t. 

\begin{equation}
\label{eqn:crl__calib}
A^{kj} - \sqrt{\frac{\varepsilon(k,j)}{\alpha(k,j)}} \leq \E[f \mid A^{kj} \leq P^{kj} \leq B^{kj}] \leq B^{kj} + \sqrt{\frac{\varepsilon(k,j)}{\alpha(k,j)}}
\end{equation}

\end{corollary}

The appearance of $\alpha$ in the denominator in \ref{eqn:crl__calib} is not surprising since we only expect calibration to hold for large sample size.

We now proceed with the proofs.

\begin{proof}[Proof of Corollary \ref{crl:calib}]

Construct $W: \Words \Scheme \Bool$ s.t. ${W^{kj}(x,y)=\theta(P^{kj}(x,y)-A^{kj})\theta(B^{kj}-P^{kj}(x,y))}$. Denote $\delta(k,j):=\E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}(P^{kj}-f)]$ and $\varepsilon:=\frac{\delta^2}{\alpha}$. According to Theorem~\ref{thm:calib}, $\varepsilon \in \Fall$.
We get

$$\frac{\E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}(P^{kj}-f)]^2}{\alpha(k,j)} = \varepsilon(k,j)$$

$$\frac{\E_{\mu^k \times U^{\R_W(k,j)}}[\theta(P^{kj}(x,y)-A^{kj})\theta(B^{kj}-P^{kj}(x,y))(P^{kj}-f)]^2}{\alpha(k,j)} = \varepsilon(k,j)$$

$$\frac{(\E_{\mu^k \times U^{\R_W(k,j)}}[\theta(P^{kj}(x,y)-A^{kj})\theta(B^{kj}-P^{kj}(x,y))]\E[P^{kj}-f \mid A^{kj} \leq P^{kj} \leq B^{kj}])^2}{\alpha(k,j)} = \varepsilon(k,j)$$

$$\frac{(\alpha(k,j)\E[P^{kj}-f \mid A^{kj} \leq P^{kj} \leq B^{kj}])^2}{\alpha(k,j)} = \varepsilon(k,j)$$

$$\alpha(k,j)\E[P^{kj}-f \mid A^{kj} \leq P^{kj} \leq B^{kj}]^2 = \varepsilon(k,j)$$

\begin{equation}
\label{eqn:crl__calib__prf}
\Abs{\E[P^{kj}-f \mid A^{kj} \leq P^{kj} \leq B^{kj}]} = \sqrt{\frac{\varepsilon(k,j)}{\alpha(k,j)}}
\end{equation}

On the other hand

$$\E[f \mid A^{kj} \leq P^{kj} \leq B^{kj}] = \E[P^{kj}-P^{kj}+f \mid A^{kj} \leq P^{kj} \leq B^{kj}]$$

$$\E[f \mid A^{kj} \leq P^{kj} \leq B^{kj}] = \E[P^{kj} \mid A^{kj} \leq P^{kj} \leq B^{kj}]-\E[P^{kj}-f \mid A^{kj} \leq P^{kj} \leq B^{kj}]$$

Applying \ref{eqn:crl__calib__prf}

$$\E[f \mid A^{kj} \leq P^{kj} \leq B^{kj}] \leq \E[P^{kj} \mid A^{kj} \leq P^{kj} \leq B^{kj}]+\sqrt{\frac{\varepsilon(k,j)}{\alpha(k,j)}}$$


$$\E[f \mid A^{kj} \leq P^{kj} \leq B^{kj}] \leq B^{kj} + \sqrt{\frac{\varepsilon(k,j)}{\alpha(k,j)}}$$

In the same manner, we can show that

$$\E[f \mid A^{kj} \leq P^{kj} \leq B^{kj}] \geq A^{kj} - \sqrt{\frac{\varepsilon(k,j)}{\alpha(k,j)}}$$

\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:calib}]

Consider $\zeta: \Nats^2 \rightarrow (0,\frac{1}{2}]$ s.t.  $\zeta \in \Fall$ and $\Floor{\log \frac{1}{\zeta}} \in \GrowA$. Define $I:=\{(k,j) \in \Nats^2 \mid \frac{\Abs{\delta(k,j)}}{\alpha(k,j)} \geq \zeta(k,j)\}$, $D^{kj}:=\Rats \cap [\frac{\Abs{\delta(k,j)}}{2\alpha(k,j)},\frac{\Abs{\delta(k,j)}}{\alpha(k,j)}]$ and choose ${\epsilon(k,j) \in (\Sgn \delta(k,j)) \cdot \Argmin{t \in D^{kj}} \Abs{\En_\Rats(t)}}$. It is easy to see that ${\Abs{\En_\Rats(\epsilon)} = O(\log \frac{\alpha}{\Abs{\delta}})}$, hence we can construct $Q: \Words \Scheme \Rats$ s.t. $\R_Q=\R_P$ and for any $(k,j) \in I$, and $x,y \in \Words$, $Q^{kj}(x,y)=P^{kj}(x,y)-\epsilon(k,j)$ (we supply $\epsilon$ as advice for $Q$). Applying Proposition~\ref{prp:weight} to $P$, $Q$ and $W$, we conclude there is $\varepsilon \in \Fall$ s.t.

$$\E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}(Q^{kj}-f)^2] + \varepsilon(k,j)$$

$$\E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}(P^{kj}-f-\epsilon(k,j))^2] + \varepsilon(k,j)$$

$$\E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}((P^{kj} - f)^2 - (P^{kj}-f-\epsilon(k,j))^2] \leq \varepsilon(k,j)$$

$$ \epsilon(k,j) \E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}(2(P^{kj} - f) - \epsilon(k,j))] \leq \varepsilon(k,j)$$

$$ \epsilon(k,j) (2 \E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}(P^{kj} - f)]-\E_{\mu^k \times U^{\R_W(k,j)}}[W^{kj}]\epsilon(k,j)) \leq \varepsilon(k,j)$$

$$ \epsilon(k,j) (2 \delta(k,j) - \alpha(k,j)\epsilon(k,j)) \leq \varepsilon(k,j)$$

Dividing both sides by $ \alpha(k,j)$ we get

$$\epsilon(k,j) (\frac{2\delta(k,j)}{\alpha(k,j)} - \epsilon(k,j)) \leq \frac{\varepsilon(k,j)}{\alpha(k,j)}$$

$$\frac{\delta(k,j)^2}{\alpha(k,j)^2}-(\epsilon(k,j) - \frac{\delta(k,j)}{\alpha(k,j)})^2 \leq \frac{\varepsilon(k,j)}{\alpha(k,j)}$$

$\epsilon$ is between $\frac{\delta}{2\alpha}$ and $\frac{\delta}{\alpha}$ therefore $(\epsilon-\frac{\delta}{\alpha})^2 \leq (\frac{\delta}{2\alpha} - \frac{\delta}{\alpha})^2$  which yields

$$\frac{\delta(k,j)^2}{\alpha(k,j)^2}-(\frac{\delta(k,j)}{2\alpha(k,j)} - \frac{\delta(k,j)}{\alpha(k,j)})^2 \leq \frac{\varepsilon(k,j)}{\alpha(k,j)}$$

$$\frac{3}{4} \cdot \frac{\delta(k,j)^2}{\alpha(k,j)^2} \leq \frac{\varepsilon(k,j)}{\alpha(k,j)}$$

$$\frac{\delta(k,j)^2}{\alpha(k,j)} \leq \frac{4}{3}\varepsilon(k,j)$$

\end{proof}

\subsection{Algebraic Properties}

In this subsection we show that several algebraic identities satisfied by expected values have analogues for optimal predictors.

Given $F_1,F_2$ random variables and $t_1,t_2 \in \Reals$, we have 

\begin{equation}
\E[t_1 F_1 + t_2 F_2] = t_1 \E[F_1] + t_2 \E[F_2]
\end{equation}

Optimal predictors have an analogous property:

\begin{proposition}
\label{prp:linearity}

Fix $\Gamma=(\GrowR,\GrowA)$ a pair of growth spaces of rank 2 and $\Fall$ a fall space of rank 2. Consider $\mu$ a word ensemble, $f_1,f_2: \Supp \mu \rightarrow \Reals$ bounded and $t_1,t_2 \in \Rats$. Denote $f: = t_1 f_1 + t_2 f_2$. Suppose $P_1$ is an $\Fall^\sharp(\Gamma)$-optimal predictor for $(\mu,f_1)$ and $P_2$ is an $\Fall^\sharp(\Gamma)$-optimal predictor for $(\mu,f_2)$. Construct $P: \Words \Scheme \Rats$ s.t. $\R_P(k,j) = \R_{P_1}(k,j) + \R_{P_2}(k,j)$ and for any $x \in \Supp \mu^k$, $y_1 \in \WordsLen{\R_{P_1}(k,j)}$, $y_2 \in \WordsLen{\R_{P_1}(k,j)}$, $P^{kj}(x,y_1 y_2)=t_1 P_1^{kj}(x,y_1) + t_2 P_2^{kj}(x, y_2)$. Then, $P$ is an $\Fall^\sharp(\Gamma)$-optimal predictor for $(\mu, f)$.

\end{proposition}

\begin{proof}

Consider any $S: \Words \Scheme \Rats$ with $\R_S \geq \R_P$. We have

$$\E[(P^{kj} - f)S^{kj}] = \E[(t_1 P_1^{kj} + t_2 P_2^{kj} - (t_1 f_1 + t_2 f_2))S^{kj}]$$

$$\E[(P^{kj} - f)S^{kj}] = t_1 \E[(P_1^{kj} - f_1)S^{kj}] + t_2 \E[(P_2^{kj} - f_2)S^{kj}]$$

$$\Abs{\E[(P^{kj} - f)S^{kj}]} \leq \Abs{t_1} \cdot \Abs{\E[(P_1^{kj} - f_1)S^{kj}]} + \Abs{t_2} \cdot \Abs{\E[(P_2^{kj} - f_2)S^{kj}]}$$

Using \ref{eqn:op_sharp} for $P_1$ and $P_2$ we see that the right hand side is in $\Fall$.

\end{proof}

Independent random variables $F_1, F_2$ satisfy 

\begin{equation}
\label{eqn:ev_mult}
\E[F_1 F_2] = \E[F_1] \E[F_2]
\end{equation}

To formulate an analogous property for optimal predictors, we need a notion of independence for distributional decision problems which doesn't make the identity tautologous. Consider distributional decision problems $(\mu, f_1)$, $(\mu, f_2)$. Informally, $f_2$ is "independent" of $f_1$ when learning the value of $f_1(x)$ provides no efficiently accessible information about $f_2(x)$. In the present work, we won't try to formalise this in full generality. Instead, we will construct a specific scenario in which the independence assumption is justifiable.

We start with an informal description. Suppose that $f_2(x)$ depends only on part $\pi(x)$ of the information in $x$ i.e. $f_2(x) = g(\pi(x))$. Suppose further that given $y=\pi(x)$ it is possible to efficiently produce samples $x'$ of $\mu \mid \pi^{-1}(y)$ for which $f_1(x')$ is known\footnote{This is substantially weaker than saying $f_1$ can be efficiently computed even in the uniform case (assuming standard complexity theoretic conjectures) and even more so in the non-uniform case, as we shall see when the relevant notion of "efficient sampling" is formalised.}. Then, the knowledge of $f_1(x)$ doesn't provide new information about $g(\pi(x))$ since equivalent information can be efficiently produced without this knowledge.

In order to formalise the above, we introduce several new definitions.

\begin{definition}

Fix $n \in \Nats$ and $\Grow$ a pair of growth spaces of rank $n$. Given encoded sets $X$ and $Y$, an \emph{$\MGrow$-scheme of signature $X \rightarrow Y$} is a triple $(S,\R_S,\M_S)$ where $S: \Nats^n \times X \times \Words^2 \Alg Y$, $\R_S: \Nats^n \times \Words \Alg \Nats$ and a family of probability distributions $\{\M_S^K: \Words \rightarrow [0,1]\}_{K \in \Nats^n}$ are s.t.

\begin{enumerate}[(i)]

\item There is a polynomial $p: \Nats^n \rightarrow \Nats$ s.t. for any $K \in \Nats^n$, $x \in X$, ${y \in \WordsLen{\R_S(K)}}$ and $z \in \Supp \M_S^K$, $\T_S(K,x,y,z) \leq p(K)$.

\item There is a polynomial $q: \Nats^n \rightarrow \Nats$ s.t. for any $K \in \Nats^n$ and $z \in \Supp \M_S^K$, ${\T_{\R_S}(K,z) \leq q(K)}$.

\item There is $r \in \GrowR$ s.t. for any $K \in \Nats^n$ and $z \in \Supp \M_S^K$, $\R_S(K,z) \leq r(K)$.

\item There is $l \in \GrowA$ s.t. for any $K \in \Nats^n$, $\Supp \M_S^K \subseteq \WordsLen{l(K)}$.

\end{enumerate}

Abusing notation, we denote the $\MGrow$-scheme $(S,\R_S,\M_S)$ by $S$.

$\R_S^K(z)$ will denote $\R_S(K,z)$. $\UM_S^K$ will denote the probability distribution on ${\Words \times \Words}$ given by $\UM_S^K(y,z):= \M_S^K(z) \delta_{\Abs{y},\R_S^K(z)} 2^{-\R_S^K(z)}$.

$S^K(x,y,z)$ will denote $S(K,x,y,z)$. Given $w=(y,z)$, $S^K(x,w)$ will denote $S(K,x,y,z)$. $S^K(x)$ will denote the $Y$-valued random variable which equals $S(K,x,y,z)$ for $(y,z)$ sampled from $\UM_S^K$. $S_x^K$ will denote the probability distribution of this random variable i.e. $S_x^K$ is the push-forward of $\UM_S^K$ by the mapping $(y,z) \mapsto S(K,x,y,z)$.

We think of $S$ as a randomized algorithm with advice which is random in itself. In particular any $\Gamma$-scheme can $S$ can be regarded as an $\MGrow$-scheme with $\M_S^K(z):=\delta_{z\A_S^K}$.

We will use the notation $S: X \MScheme Y$ to signify $S$ is an $\MGrow$-scheme of signature $X \rightarrow Y$.

\end{definition}

\begin{definition}

Fix $n \in \Nats$, $\Grow$ a pair of growth spaces of rank $n$ and $\Fall$ a fall space of rank $n$. A word ensemble $\mu$ is called \emph{$\Fall(\MGrow)$-samplable} (resp. \emph{$\Fall(\Gamma)$-samplable}) when there is an $\MGrow$-scheme (resp. $\Gamma$-scheme) $L$ of signature $\bm{1} \rightarrow \Words$  s.t. the function $\varepsilon(K):=\Dtv(\mu^{K_1},L_\bullet^K)$ is in $\Fall$.

In this case, $L$ is called an \emph{$\Fall(\MGrow)$-sampler (resp. $\Fall(\Gamma)$-sampler)} of $\mu$.

\end{definition}

\begin{samepage}
\begin{definition}

Fix $n \in \Nats$, $\Grow$ a pair of growth spaces of rank $n$ and $\Fall$ a fall space of rank $n$. A distributional estimation problem $(\mu,f)$ is called \emph{$\Fall(\MGrow)$-generatable (resp. $\Fall(\Gamma)$-generatable)} when there is an $\MGrow$-scheme (resp. $\Gamma$-scheme) $G$ of signature $\bm{1} \rightarrow \Words \times \Rats$ s.t. 

\begin{enumerate}[(i)]

\item $G_1$ is an $\Fall(\MGrow)$-sampler (resp. $\Fall(\Gamma)$-sampler) of $\mu$.

\item For any $K \in \Nats^n$, denote $X_{G}^K:=\Supp \, (G_1)_\bullet^K$ and $\chi_G^K:=\chi_{X_{G}^K}$. For any $x \in X_G^K$, denote ${f_G^K(x):=\E_{z \sim\UM_G^K}[G_2^K(z) \mid G_1^K(z) = x]}$. We require that the function $\varepsilon(K):=\E_{x \sim \mu^{K_1}}[(\chi_G^K(x) f_G^K(x)-f(x))^2]$ is in $\Fall$.

\end{enumerate}

In this case, $G$ is called an \emph{$\Fall(\MGrow)$-generator (resp. $\Fall(\Gamma)$-generator)} of $(\mu,f)$.

\end{definition}
\end{samepage}

\begin{definition}

Fix $n \in \Nats$, $\Grow$ a pair of growth spaces of rank $n$ and $\Fall$ a fall space of rank $n$. Consider a word ensemble $\mu$, an encoded set $Y$ and a family ${\{\pi^K: \Supp \mu^{K_1} \Markov Y\}_{K \in \Nats^n}}$. $\mu$ is called \emph{$\Fall(\MGrow)$-samplable (resp. $\Fall(\Gamma)$-samplable) relative to $\pi$} when there is an $\MGrow$-scheme (resp. $\Gamma$-scheme) $L$ of signature $Y \rightarrow \Words$ s.t. the function ${\varepsilon(K):=\E_{(x,y) \sim \mu^{K_1} \ltimes \pi^K}[\Dtv(\mu \mid (\pi^K)^{-1}(y),L_y^K)]}$ is in $\Fall$.

In this case, $L$ is called an \emph{$\Fall(\MGrow)$-sampler (resp. $\Fall(\Gamma)$-sampler)} of $(\mu,\pi)$.

\end{definition}

\begin{definition}

Fix $n \in \Nats$, $\Grow$ a pair of growth spaces of rank $n$ and $\Fall$ a fall space of rank $n$. Consider a distributional estimation problem $(\mu,f)$, an encoded set $Y$ and a family $\{\pi^K: \Supp \mu^{K_1} \Markov Y\}_{K \in \Nats^n}$. $(\mu,f)$ is called \emph{$\Fall(\MGrow)$-generatable (resp. $\Fall(\Gamma)$-generatable) relative to $\pi$} when there is an $\MGrow$-scheme (resp. $\Gamma$-scheme) $G$ of signature $Y \rightarrow \Words \times \Rats$ s.t.

\begin{enumerate}[(i)]

\item $G_1$ is an $\Fall(\MGrow)$-sampler (resp. $\Fall(\Gamma)$-sampler) of $(\mu,\pi)$.

\item For any $K \in \Nats^n$, $y \in Y$, Denote $X_{G,y}^K:=\Supp \, (G_1)_y^K$ and $\chi_{G,y}^X:=\chi_{X_y^K}$. For any ${x \in X_{G,y}^K}$, denote ${f_G^K(x,y):=\E_{z \sim\UM_G^K}[G_2^K(y,z) \mid G_1^K(y,z) = x]}$. We require that the function ${\varepsilon(K):=\E_{(x,y) \sim \mu^{K_1} \ltimes \pi^K}[(\chi_{G,y}^K(x) f_G^K(x,y)-f(x))^2]}$ is in $\Fall$.

\end{enumerate}

\end{definition}

The following is an analogue of \ref{eqn:ev_mult} for optimal predictors.

\begin{samepage}
\begin{theorem}

Fix $\Grow$ a pair of growth spaces of rank 2 and $\Fall$ a fall space of rank 2. Consider $\mu$ a word ensemble, $f_1, f_2: \Supp \mu \rightarrow \Reals$ bounded, $(\nu,g)$ a distributional estimation problem and $\pi: \Words \Scheme \Words$. Assume the following conditions:

\begin{enumerate}[(i)]

\item $\Dtv(\nu^k,\mu^k \ltimes \pi^{kj}) \in \Fall$

\item $\E_{(x,z) \sim \mu^k \times UM_\pi^{kj}}[(f_2(x)-g(\pi^{kj}(x,z)))^2] \in \Fall$

\item $\nu$ is $\Fall(\MGrow)$-samplable.

\item $(\mu, f_1)$ is $\Fall(\MGrow)$-generatable relative to $\pi$.

\end{enumerate}

Suppose $P_1$ is an $\Fall^\sharp(\Gamma)$-optimal predictor for $(\mu,f_1)$ and $P_2$ is an $\Fall^\sharp(\Gamma)$-optimal predictor for $(g,\nu)$. Construct $P: \Words \Scheme \Rats$ s.t. $\R_P=\R_{P_1}+\R_{P_2}+\R_{\pi}$ and ${P^{kj}(x,y_1 y_2 y_3)=P_1^{kj}(x,y_1) P_2^{kj}(\pi^{kj}(x,y_3),y_2)}$. Then, $P$ is an $\Fall^\sharp(\Gamma)$-optimal predictor for $(\mu,f_1 f_2)$.

\end{theorem}
\end{samepage}

\begin{proof}

Foo

\end{proof}

TBD

\section{Reductions and Completeness}
\label{sec:reductions}

TBD

\section{Existence and Uniqueness}
\label{sec:e_and_u}

TBD

\section{Reflective Systems and Game Theory}
\label{sec:reflective}

TBD

\section{Discussion}
\label{sec:discussion}

TBD

\appendix

\section{Appendix}

We review the definitions of hard-core predicate and one-way function and state the Goldreich-Levin theorem.

We will use the notation $\Gamma_{\text{det}}:=(\Gamma_0^1,\Gamma_0^1)$, $\Gamma_{\text{rand}}:=(\Gamma_{\text{poly}}^1,\Gamma_0^1)$, ${\Gamma_{\text{circ}}:=(\Gamma_0^1,\Gamma_{\text{poly}}^1)}$.

\begin{samepage}
\begin{definition}

Given $\mu$ a word ensemble\footnote{The standard definition of a hard-core predicate corresponds to the case $\mu^k=U^k$. Here we allow for slightly greater generality.}, $f: \Supp \mu \rightarrow \Words$ and ${B: \Words \xrightarrow{\Gamma_{\text{det}}} \Bool}$, $B$ is a called a \emph{hard-core predicate} of $(\mu,f)$ when for any $S: \Words \xrightarrow{\Gamma_{\textnormal{rand}}} \Bool$ there is $\varepsilon \in \Fall_{\text{neg}}^1$ s.t. 

\begin{equation}
\Prb_{(x,y) \sim \mu^k \times U^{\R_S(k)}}[S^k(f(x),y)=B^k(x)] \leq \frac{1}{2} + \varepsilon(k)
\end{equation}

\end{definition}
\end{samepage}

\begin{samepage}
\begin{definition}

Given $\mu$ a word ensemble, $f: \Supp \mu \rightarrow \Words$ and ${B: \Words \xrightarrow{\Gamma_{\text{det}}} \Bool}$, $B$ is a called a \emph{non-uniformly hard-core predicate} of $(\mu,f)$ when for any ${S: \Words \xrightarrow{\Gamma_{\textnormal{circ}}} \Bool}$ there is $\varepsilon \in \Fall_{\text{neg}}^1$ s.t. 

\begin{equation}
\Prb_{x \sim \mu^k}[S^k(f(x),y)=B^k(x)] \leq \frac{1}{2} + \varepsilon(k)
\end{equation}

\end{definition}
\end{samepage}

\begin{samepage}
\begin{definition}

$f: \Words \Alg \Words$ is called an \emph{one-way function}
when

\begin{enumerate}[(i)]

\item There is $p: \Nats \rightarrow \Nats$ polynomial s.t. $\forall x \in \Words: \T_f(x) \leq p(\Abs{x})$.

\item For any $S: \Words \xrightarrow{\Gamma_{\text{rand}}} \Words$

\begin{equation}
\Prb_{(x,y) \sim U^k \times U^{\R_S(k)}}[f(S^k(f(x),y))=x] \in \Fall_{\text{neg}}^1
\end{equation}

\end{enumerate}

\end{definition}
\end{samepage}

\begin{samepage}
\begin{definition}

$f: \Words \Alg \Words$ is called a \emph{non-uniformly hard to invert} one-way function
when

\begin{enumerate}[(i)]

\item There is $p: \Nats \rightarrow \Nats$ polynomial s.t. $\forall x \in \Words: \T_f(x) \leq p(\Abs{x})$.

\item For any $S: \Words \xrightarrow{\Gamma_{\text{circ}}} \Words$

\begin{equation}
\Prb_{x \sim U^k}[f(S^k(f(x)))=x] \in \Fall_{\text{neg}}^1
\end{equation}

\end{enumerate}

\end{definition}
\end{samepage}

It is easy to see that any non-uniformly hard-core predicate is in particular a hard-core predicate and any non-uniformly hard to invert one-way function is in particular a one-way function.

The following appears in \cite{Goldreich_2008} as Theorem 7.7. Here we state it in the notation of the present work.

\begin{theorem}[Goldreich-Levin]
\label{thm:goldreich_levin}

Consider a one-way function ${f: \Words \Alg \Words}$. Let $\mu^k:=U^{2k}$, $f_{\textnormal{GL}}: \Supp \mu \rightarrow \Words$ and ${B: \Words \xrightarrow{\Gamma_{\textnormal{det}}} \Bool}$ be s.t. for any $x,y \in \WordsLen{k}$, $f_{\textnormal{GL}}(xy)=\Chev{f(x),y}$ and ${B^k(xy)=x \cdot y}$. Then, $B$ is a hard-core predicate of $(\mu, f_{\textnormal{GL}})$.

\end{theorem}

There is also a non-uniform version of the theorem which is not stated in \cite{Goldreich_2008}, but its proof is a straightforward adaptation.

\begin{theorem}
\label{thm:goldreich_levin_circ}

In the setting of Theorem~\ref{thm:goldreich_levin}, assume $f$ is non-uniformly hard to invert. Then $B$ is a non-uniformly hard-core predicate of $(\mu, f_{\textnormal{GL}})$.
\end{theorem}

\section*{Acknowledgments}

TBD

\bibliographystyle{unsrt}
\bibliography{Optimal_Predictors}

\end{document}

