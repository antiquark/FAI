%
\documentclass{article}

\usepackage[affil-it]{authblk}
\usepackage{cite}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{commath}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
%\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[section]
%\newtheorem{conjecture}{Conjecture}[section]

%\theoremstyle{remark}
%\newtheorem{note}{Note}[section]

\newcommand{\Words}{{\{ 0, 1 \}^*}}
\newcommand{\WordsLen}[1]{{\{ 0, 1 \}^{#1}}}
\newcommand{\Bool}{\{0,1\}}

\DeclareMathOperator{\Sgn}{sgn}
\DeclareMathOperator{\Supp}{supp}
\DeclareMathOperator{\Stab}{stab}
\DeclareMathOperator{\Img}{Im}
\DeclareMathOperator{\Prb}{Pr}
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Ent}{H}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Sym}{Sym}
\DeclareMathOperator{\T}{T}
\DeclareMathOperator{\R}{r}
\DeclareMathOperator{\A}{a}

\newcommand{\KL}[2]{\operatorname{D}_{\mathrm{KL}}(#1 \| #2)}

\newcommand{\Argmin}[1]{\underset{#1}{\operatorname{arg\,min}}\,}
\newcommand{\Argmax}[1]{\underset{#1}{\operatorname{arg\,max}}\,}

\newcommand{\Nats}{\mathbb{N}}
\newcommand{\Ints}{\mathbb{Z}}
\newcommand{\Rats}{\mathbb{Q}}
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\Coms}{\mathbb{C}}

\newcommand{\Lim}[1]{\lim_{#1 \rightarrow \infty}}
\newcommand{\LimInf}[1]{\liminf_{#1 \rightarrow \infty}}
\newcommand{\LimSup}[1]{\limsup_{#1 \rightarrow \infty}}

\newcommand{\Abs}[1]{\lvert #1 \rvert}
\newcommand{\Norm}[1]{\lVert #1 \rVert}
\newcommand{\Floor}[1]{\lfloor #1 \rfloor}
\newcommand{\Ceil}[1]{\lceil #1 \rceil}
\newcommand{\Chev}[1]{\langle #1 \rangle}
\newcommand{\Quote}[1]{\ulcorner #1 \urcorner}

\begin{document}

\title{Optimal Predictors: A Bayesian Notion of Approximation Algorithm (Draft)}


\author{Vadim Kosoy}
\affil{Affiliation TBD}

\date{\today}

\maketitle

\begin{abstract}
The concept of an "approximation algorithm" is usually only applied to optimization problems since in optimization problems the performance of the algorithm on any given input is a continuous parameter. We introduce a new concept of approximation applicable to decision problems and functions, inspired by Bayesian probability. From the perspective of a Bayesian reasoner with limited computational resources, the answer to a problem that cannot be solved exactly is uncertain and therefore should be described by a random variable. It thus should make sense to talk about the expected value of this random variable, an idea we formalize in the language of average-case complexity theory by introducing the concept of "optimal predictor." We show that optimal predictors exhibit many parallels with "classical" probability theory, prove some existence theorems and demonstrate some applications to artificial general intelligence.%
\end{abstract}%



\section*{Introduction}
%
Imagine you are strolling in the city with a friend when a car passes by with the license plate number "7614829". Your friend proposes a wager, claiming that the number is composite and offering 10 : 1 odds in your favor. Knowing that your friend has no exceptional ability in mental arithmetic and that it's highly unlikely they saw this car before, you realize they are just guessing. Your mental arithmetic is also insufficient to test the number for primality, but is sufficient to check that $7614829 \equiv 1 \pmod{3}$ and $\frac{1}{\ln 7614829} \approx 0.06$. Arguing from the prime number theorem and observing that 7614829 is odd and is divisible neither by 3 nor by 5, you conclude that the probability 7614829 is prime is $\frac{1}{\ln 7614829} \times 2 \times \frac{3}{2} \times \frac{5}{4} \approx 22\%$. Convinced that the odds are in your favor you accept the bet\footnote{Alas, $7614829 = 271 \times 28099$.}.


From the perspective of frequentist probability the question "what is the probability 7614829 is prime?" seems meaningless, since it is either prime or not so there is no frequency to observe (unless the frequency is 0 or 1). From a Bayesian perspective, probability represents a degree of confidence, however in classical Bayesian probability theory it is assumed the only source of uncertainty is lack of information. The number 7614829 already contains all information needed to determine whether it's prime so the probability again has to be 0 or 1. However, real life uncertainty is not only information-theoretic but also complexity-theoretic. Even when we have all information to obtain the answer, out computational resources are limited so we remain uncertain. The rigorous formalization of this idea is the main goal of the present work.

The idea of assigning probabilities to purely mathematical questions was studied by several authors\cite{Gaifman_2004,Hutter_2013,Demski_2012,Christiano_2014,Garrabrant_2015}, mainly in the setting of formal logic. That is, their approach was looking for functions from the set of sentences in some formal logical language to $[0,1]$. However, although there is a strong intuitive case for assigning probabilities to sentences like $\varphi_1:=\text{"7614829 is prime"}$ it is much less clear there is a meaningful assignment of probabilities to sentences like $\varphi_2 := \text{"there are no odd perfect numbers"}$ or (even worse) $\varphi_3 := \text{"there is no cardinality } \kappa \text{ s.t. } \aleph_0 < \kappa < 2^{\aleph_0} \text{."}$.

A wager on $\varphi_1$ can be resolved in a predetermined finite amount of time (the amount of time it takes to test it directly). On the other hand, it is unknown how long the resolution of $\varphi_2$ will take. It is possible that there is an odd perfect number but finding it (or otherwise becoming certain of its existence) will take a very long time. It is also possible there is no odd perfect number, a fact that cannot be directly verified because of its infinite nature. It is possible that there a proof of $\varphi_1$ within some formal theory, but accepting such a proof as resolution requires us to be completely certain of the consistency of the theory (whereas it is arguable that the consistency of formal mathematical theories, especially more abstract theories like ZFC, is itself only known empirically and in particular with less than absolute certainty). Moreover, there is no knowing a priori whether a proof exists or how long it will take to find it. For $\varphi_3$ there is no way to "directly" verify neither the sentence nor its negation, and it is actually known to be independent of ZFC.

In the present work we avoid choosing a specific category of mathematical questions. Instead, we consider the abstract setting of arbitrary distributional decision problems. This leads to the perspective that an assignment of probabilities is a form of \emph{approximate} solution to a problem. This is not the same sense of approximation as used in optimization problems, where the approximation error is the difference between the ideal solution and the actual solution. Instead, the approximation error is the prediction accuracy of our probability assignment. This is also different from average-complexity theory where the solution is required to be exact on most input instances. However the language of average-complexity theory (in particular the concept of a distributional decision problem) turns out to be well-suited to our purpose.
The concept of "optimal predictor" that arises from the approach turns out to behave much like probabilities, or more generally expected values, in "classical" probability theory. They display an appropriate form of calibration. The "expected values" are linear in general and multiplicative for functions that are independent in an appropriate sense. There is a natural parallel of conditional probabilities. For simple examples constructed from one-way functions we get the probability values we expect. Also they are well behaved in the complexity-theoretic sense that a natural class of reductions transforms optimal predictors into optimal predictors, and complete problems for these reductions exist for important complexity classes.

Optimal predictors turn out to be unique up to a certain equivalence relation. The existence of optimal predictors depends on the specific variety you consider. We show that in the non-uniform case (allowing advice) there is a variety of optimal predictors that exist for completely arbitrary problems. Uniform optimal predictors of this kind exist for a certain class of problems we call "samplable" which can be very roughly regarded as an average-case analogue of $\textsc{NP} \cap \textsc{coNP}$. More generally mapping the class of problems which admit optimal predictors allows for much further research.

Assignment of probabilities to mathematical questions is interesting in the context of artificial general intelligence\cite{Hutter_2013,Christiano_2014}. In this context is useful to consider situations in which an agent reasons about itself or several agents reason about each other \cite{Fallenstein_2015}. We give a formal model of such situations in our setting and use the Kakutani-Glicksberg-Fan theorem to prove they still admit existence of optimal predictors. We then use this to model agents playing a game in normal form and show that such agents converge to the analogue of Nash equilibrium (or even a proper equilibrium, depending on the precise implementation) in the time bounded case. That is, each agent plays a near-optimal response among those it can find within the allotted time. We suggest more potential applications for optimal predictors to decision theory and the theory of self-modifying agents.

The structure of the paper is as follows. Section~\ref{sec:fundamentals} introduces the main definitions and gives a simple example using one-way functions. Section~\ref{sec:probability} shows the parallel between properties of optimal predictors and classical probability theory. Section~\ref{sec:reductions} discusses behavior of optimal predictors and reductions and shows $\textsc{SampNP}$ has a complete problem under appropriate reductions. Section~\ref{sec:e_and_u} discusses existence and uniqueness of optimal predictors. Section~\ref{sec:reflective} discusses applications to AGI. Section~\ref{sec:discussion} discusses possible avenues for further research. The Appendix reviews relevant theorems about one-way functions.

\setcounter{section}{-1}

\section{Notation}
%
\subsection{Numbers and Functions}

$\Nats$ is the set of natural numbers. We will use the convention in which natural numbers start from 0, so $\Nats = \{0, 1, 2 \ldots \}$. 

$\Ints$ is the ring of integers, $\Rats$ is the field of rational numbers, $\Reals$ is the field of real numbers.

For $F \in \{\Rats,\Reals\}$, $F^{>0} := \{x \in F \mid x > 0\}$, $F^{\geq 0} := \{x \in F \mid x \geq 0\}$.

For any $t \in \Reals$, $\Floor{t} := \max \{n \in \Ints \mid n \leq t\}$, $\Ceil{t} := \min \{n \in \Ints \mid n \geq t\}$.

$\log: \Reals^{\geq 0} \rightarrow \Reals \sqcup \{-\infty\}$ will denote the logarithm in base 2.

Given a set $X$ and a subset $Y$, $\chi_Y: X \rightarrow \Bool$ will denote the characteristic function of $Y$ (when $X$ is assumed to be known from the context)

$$\chi_Y(x):=\begin{cases}1 & \text{if } x \in Y \\ 0 & \text{if } x \not\in Y \end{cases}$$

$\theta: \Reals \rightarrow \Bool$ will denote the Heaviside step function $\theta:=\chi_{[0,\infty)}$ i.e.

$$\theta(t):=\begin{cases}1 & \text{if } t \geq 0 \\ 0 & \text{if } t < 0 \end{cases}$$

\subsection{Measures and Probabilities}

For $X$ a measurable space, $\mu$ a probability measure on $X$, $V$ a finite dimensional vector space over $\Reals$ and $f: X \rightarrow V$, $\E_{x \sim \mu}[f(x)]$ will denote the expected value of $f$ with respect to $\mu$, i.e. $\E_{x \sim \mu}[f(x)] := \int_X f(x) d\mu(x)$. We will the abbreviated notations $\E_\mu[f(x)]$, $\E[f(x)]$, $\E_\mu[f]$, $\E[f]$ when no confusion is likely to occur.

Given a topological space $X$ and a Borel probability measure $\mu$ on $X$, $\Supp \mu$ will denote the support of $\mu$. In particular when $X$ is discrete, ${\Supp \mu = \{x \in X \mid \mu(x) > 0\}}$.

Given $X,Y$ measurable spaces, $\mu$ a measure on $X$ and $f: X \rightarrow Y$ a measurable mapping, $f_*(\mu)$ will denote the corresponding pushforward measure on $Y$.

\subsection{Algorithms}

$\Words$ is the set of all finite binary strings (words). For any $x \in \Words$, $\Abs{x}$ is the length of $x$ i.e. $x \in \WordsLen{\Abs{x}}$. For any $x \in \Words$ and $n \in \Nats$, $x_{\leq n}$ stands for the prefix of $x$ of length $n$ if $\Abs{x} \geq n$ and $x$ otherwise. Given $x,y \in \Words$, $xy$ stands for the concatenation of $x$ and $y$ (in particular $\Abs{xy}=\Abs{x}+\Abs{y}$). Given $n \in \Nats$ and $x,y \in \WordsLen{n}$, $x \cdot y$ stands for $\bigoplus_{i=1}^n x_i y_i$. For any $n \in \Nats$, $U^n$ is the uniform probability distribution on $\WordsLen{n}$.

Given $n \in \Nats$ and ${x_1, x_2 \ldots x_n \in \Words}$, $\Chev{x_1,x_2 \ldots x_n} \in \Words$ denotes the encoding of $(x_1,x_2 \ldots x_n)$ obtained by repeating each bit of $x_1, x_2 \ldots x_n$ twice and inserting the separators 01.
\begin{definition}

An \emph{encoded set} is a set $X$ together with an injection ${e_X: X \rightarrow \Words}$ (the encoding) s.t. $\Img e_X$ is decidable in polynomial time.

\end{definition}

There are standard encodings we implicitly use throughout. $\Words$ is an encoded set with the trivial encoding ${e_\Words(x):=x}$. $\Nats$ is an encoded set where $e_\Nats(n)$ is the binary representation of $n$. $\Rats$ is an encoded set where ${e_\Rats(\frac{n}{m}):=\Chev{n,m}}$ for an irreducible fraction $\frac{n}{m}$. For any encoded set $X$ and $L \in \textsc{P}$, $\{x \in X \mid e_X(x) \in L\}$ is an encoded set whose encoding is the restriction of $e_X$. For $X,Y$ encoded sets, $X \times Y$ is an encoded set with encoding $e_{X \times Y}(x,y):=\Chev{e_X(x),e_Y(y)}$.

Given $n \in \Nats$, encoded sets $X_1, X_2 \ldots X_n$ and encoded set $Y$ we use the notation $A: \prod_{i=1}^n X_i \xrightarrow{alg} Y$ to mean a Turing machine with $n$ input tapes that halts on every input for which the $i$-th tape is initialized to a value in $\Img e_X$ and produces an output in $\Img e_Y$. Given $\{x_i \in X_i\}_{i=1}^n$ the notation $A(x_1, x_2 \ldots x_n)$ stands for the unique $y \in Y$ s.t. applying $A$ to the input composed of $e_{X_i}(x_i)$ results in output $e_Y(y)$. We use different input tapes for different components of the input instead of encoding the $n$-tuple as a single word in order to allow $A$ to process some components of the input in time smaller than the length of other components. This involves abuse of notation since a Cartesian product of encoded sets is naturally an encoded set, but hopefully this won't cause much confusion.

Given $A: X \xrightarrow{alg} Y$ and $x \in X$, $\T_A(x)$ stands for the number of time steps in the computation of $A(x)$.

For any $n \in \Nats$, we fix $\mathcal{U}_n$, a prefix free universal Turing machine with $n+1$ input tapes: 1 program tape and $n$ tapes that serve as input to the program. Given $A: \prod_{i=1}^n X_i \xrightarrow{alg}\ Y$, $\Quote{A} \in \Words$ denotes the corresponding program for $\mathcal{U}_n$.

\section{Fundamentals}
\label{sec:fundamentals}

\subsection{Optimal Predictors}

We start with a simple model to help build intuition and motivate the following definitions.

Consider finite sets $X$ and $Y$, a probability distribution $\mu: X \rightarrow [0,1]$, a mapping $m: X \rightarrow Y$ and a function $f: X \rightarrow \Reals$. Suppose $x$ was sampled from $\mu$ and we were told $y := m(x)$ (but not told $x$ itself). Our expected value of $f(x)$ in these conditions is $\E[f(x)] = \E_{x' \sim \mu}[f(x') \mid m(x') = y]$.

Let $P: X \rightarrow \Reals$ be the function $P(x) := \E_{x' \sim \mu}[f(x') \mid m(x) = m(x)]$. How can we characterize $P$ without referring to the concept of a conditional expected value? For any $Q: X \rightarrow \Reals$ we can consider the "error" $\E_\mu[(Q - f)^2]$. $Q$ is called "efficient" when it factors as $Q = q \circ m$ for some $q: Y \rightarrow \Reals$. It is easy to see that $P$ has the least error among all efficient functions.

Note that the characterization of $P$ depends not only on $f$ but also on $\mu$. That is, the accuracy of an estimator depends on the prior probabilities to encounter different questions. In general, we assume that the possible questions are indexed by elements of $\Words$. Thus we need to consider a probability distribution on $\Words$. However, in the spirit of average-complexity theory we will only require our estimators to be \emph{asymptotically} optimal. Therefore instead of considering a single probability distribution we consider a family of probability distribution indexed by an integer parameter, where the role of the parameter is defining the relevant limit. We thereby arrive at the following:

\begin{definition}

A \emph{word ensemble} $\mu$ is a family of probability distributions $\{\mu^k: \Words \rightarrow [0,1]\}_{k \in \Nats}$.

\end{definition}

We now introduce our abstraction for a "class of mathematical questions" (with quantitative real-valued answers). This abstraction is a trivial generalization of the concept of a distributional decision problem from average-case complexity theory (see e.g. \cite{Bogdanov_2006}).

\begin{definition}

A \emph{distributional estimation problem} is a pair $(\mu,f)$ where $\mu$ is a word ensemble and $f: \Supp \mu \rightarrow \Reals$ is bounded.

\end{definition}

In the motivational model, the estimator was restricted to lie in a class of functions that factor through a fixed mapping. Of course we are interested in more realistic notions of efficiency. In the present work we consider restrictions on time complexity, access to random bits and size of advice strings. Spatial complexity is also of interest but treating it is out of our current scope. It is possible to consider weaker or stronger restrictions which we represent using the following abstraction:

\begin{definition}

Fix $n$. A \emph{growth space} $\Gamma$ of rank $n$ is a set of functions ${\gamma: \Nats^n \rightarrow \Nats}$ s.t.

\begin{enumerate}[(i)]

\item If $\gamma_1, \gamma_2 \in \Gamma$ then $\gamma_1 + \gamma_2 \in \Gamma$.

\item If $\gamma_1 \in \Gamma$, $\gamma_2: \Nats^n \rightarrow \Nats$ and $\forall K \in \Nats^n: \gamma_2(K) \leq \gamma_1(K)$ then $\gamma_2 \in \Gamma$.

\item $0 \in \Gamma$

\end{enumerate}

\begin{example}

For any $n \in \Nats$, $\Gamma_0^n$ is a growth space of rank $n$. $\gamma \in \Gamma_0^n$ iff $\gamma \equiv 0$.

\end{example}

\end{definition}

\begin{example}

For any $n \in \Nats$, $\Gamma_{\text{poly}}^n$ is a growth space of rank $n$. $\gamma \in \Gamma_{\text{poly}}^n$ iff there is a polynomial $p: \Nats^n \rightarrow \Nats$ s.t. $\gamma(K) \leq p(K)$.

\end{example}

\begin{example}

For any $n \in \Nats$, $\Gamma_{\text{log}}^n$ is a growth space of rank $n$. $\gamma \in \Gamma_{\text{log}}^n$ iff there is $c \in \Nats$ s.t. $\gamma(K_1, K_2 \ldots K_n) \leq c \sum_{i=1}^n \log(K_i+1)$.

\end{example}

We now introduce our notion of an "efficient" algorithm.

\begin{definition}

Fix $n \in \Nats$ and $\Gamma=(\Gamma_{\mathfrak{R}}$, $\Gamma_{\mathfrak{A}})$ a pair of growth spaces of rank $n$. Given encoded sets $X$ and $Y$, a \emph{$\Gamma$-scheme of signature $X \rightarrow Y$} is a triple $(S,\R_S,\A_S)$ where $S: \Nats^n \times X \times \Words^2 \xrightarrow{alg} Y$, $\R_S: \Nats^n \times \Words \xrightarrow{alg} \Nats$ and $\A_S: \Nats^n \rightarrow \Words$ are s.t.

\begin{enumerate}[(i)]

\item There is a polynomial $p: \Nats^n \rightarrow \Nats$ s.t. for any $K \in \Nats^n$, $x \in X$ and $y \in \WordsLen{\R_S(K)}$, $\T_S(K,x,y,\A_S(K)) \leq p(K)$.

\item There is a polynomial $q: \Nats^n \rightarrow \Nats$ s.t. for any $K \in \Nats^n$, ${\T_{\R_S}(K,\A_S(K)) \leq q(K)}$.

\item The function $r: \Nats^n \rightarrow n$ defined by $r(K):=\R_S(K,\A_S(K))$ lies in $\Gamma_{\mathfrak{R}}$.

\item $\Abs{\A_S} \in \Gamma_{\mathfrak{A}}$

\end{enumerate}

Abusing notation, we denote the $\Gamma$-scheme $(S,\R_S,\A_S)$ by $S$. $S^K(x,y,z)$ will denote $S(K,x,y,z)$, $S^K(x,y)$ will denote $S(K,x,y,\A_S(K))$ and $S^K(x)$ will denote a random variable which equals $S(K,x,y,a(K))$ for $y$ sampled from $U^{\R_S(K)}$. We think of $S$ as a randomized algorithm with advice where $y$ are the internal coin tosses and $\A_S$ is the advice\footnote{Note that the number of random bits $\R_S(k,j)$ has to be efficiently computable modulo the advice $\A_S(k,j)$ rather than being an arbitrary function. This requirement is needed to prevent using the function $\R_S$ as advice in itself. In particular, when $\Gamma_{\mathfrak{A}}=\Gamma_0^2$, $S$ represents a uniform randomized algorithm.}. Similarly, $\R_S(K)$ will denote $\R_S(K,\A_S(K))$.

We will use the notation $S: X \xrightarrow{\Gamma} Y$ to signify $S$ is a $\Gamma$-scheme of signature $X \rightarrow Y$.

\end{definition}

Instead of requiring the time complexity to be polynomial in $K$, we could have used a third growth space which determines the allowed time complexity. However, we make do without this generalization in the current work.

It will also be useful to consider families of $\Gamma$-schemes satisfying uniform resource bounds.

\begin{definition}

Fix $n \in \Nats$, $\Gamma=(\Gamma_{\mathfrak{R}}$, $\Gamma_{\mathfrak{A}})$ a pair of growth spaces of rank $n$ and encoded sets $X$, $Y$. A set $F$ of $\Gamma$-schemes of signature $X \rightarrow Y$ is called a \emph{uniform family} when

\begin{enumerate}[(i)]

\item There is a polynomial $p_1: \Nats^n \rightarrow \Nats$ s.t. for any $S \in F$, $K \in \Nats^n$, $x \in X$ and $y \in \WordsLen{\R_S(K)}$, $\T_S(K,x,y,\A_S(K)) \leq p_1(K)$.

\item There is a polynomial $p_2: \Nats^n \rightarrow \Nats$ s.t. for any $S \in F$ and $K \in \Nats^n$, $\T_{\R_S}(K,\A_S(K)) \leq p_2(K)$.

\item $\max_{S \in F} \R_S \in \Gamma_{\mathfrak{R}}$

\item There is $l \in \Gamma_{\mathfrak{A}}$ s.t. for any $S \in F$ and $K \in \Nats^n$, ${\Abs{\Quote{S}} + \Abs{\Quote{\R_S}} + \Abs{\A_S(K)} \leq l(K)}$.

\end{enumerate}

\end{definition}

The details of this definition are motivated by the following proposition.

\begin{proposition}
\label{prp:fam_diag}

Fix $n \in \Nats$, $\Gamma=(\Gamma_{\mathfrak{R}}$, $\Gamma_{\mathfrak{A}})$ a pair of growth spaces of rank $n$ and encoded sets $X$, $Y$. Consider $F$ a uniform family of $\Gamma$-schemes of signature $X \rightarrow Y$ and a collection $\{\mathcal{S}_K \in F\}_{K \in \Nats^n}$. Then, there is $\Delta_\mathcal{S}: X \xrightarrow{
\Gamma} Y$ s.t. for any $K \in \Nats^n$, $x \in X$ and $y \in Y$, $\Pr[\Delta_\mathcal{S}^K(x)=y] = \Pr[\mathcal{S}_K^K(x)=y]$.

\end{proposition}

\begin{proof}

We take $\A_{\Delta_{\mathcal{S}}}(k,j):=\Chev{\Quote{\mathcal{S}_K},\Quote{\R_{\mathcal{S}_K}},\A_{\mathcal{S}_K}(K)}$. $\R_{\Delta_{\mathcal{S}}}$ is constructed so that $\R_{\Delta_{\mathcal{S}}}(K)=\R_{\mathcal{S}_K}(K)$. $\Delta_{\mathcal{S}}$ is constructed so that $\Delta_{\mathcal{S}}^K(x,z)=\mathcal{S}_K^K(x,z)$.

\end{proof}

Note that the concept of a uniform family is non-trivial only when $1 \in \Gamma_{\mathfrak{A}}$, otherwise condition (iv) allows only families of at most one member.

Fix $\Gamma$ a pair of growth spaces of rank 2. The first parameter serves to define asymptotic behavior and can be roughly thought of as determining the size of the input. The second parameter serves to control the resources available to the predictor. To illustrate the significance of the second parameter using the informal\footnote{This example cannot be formalized in the framework as presented here since the set of prime numbers is in $\textsc{P}$. We can probably tackle it by introducing restrictions on spatial resources, but this out of the current scope.} example from Section 1, the question "what is the probability 7614829 is prime?" depends on the amount of available resources. For example, we can use additional resources to test for divisibility by additional smaller primes (or in some more clever way) until eventually we are able to test primality and assign a probability in $\{0,1\}$.

Given a distributional estimation problem $(\mu,f)$ and $Q: \Words \xrightarrow{\Gamma} \Rats$, we can consider the estimation error $\E_{(x,y) \sim \mu^k \times U^{\R_Q(k,j)}}[(Q^{kj}(x,y) - f(x))^2]$. It makes little sense to require this error to be minimal for every $(k,j) \in \Nats^2$, since we can always hard-code a finite number of answers into $Q$ without violating the resource restrictions. Instead we require minimization up to an asymptotically small error. Since it makes sense to consider different kind of asymptotic requirements, we introduce an abstraction that corresponds to this choice.

\begin{definition}

Given $n \in \Nats$, a \emph{fall space of rank $n$} is a set $\mathcal{E}$ of bounded functions $\varepsilon: \Nats^n \rightarrow \Reals^{\geq 0}$ s.t.

\begin{enumerate}[(i)]

\item If $\varepsilon_1, \varepsilon_2 \in \mathcal{E}$ then $\varepsilon_1 + \varepsilon_2 \in \mathcal{E}$.

\item If $\varepsilon_1 \in \mathcal{E}$, $\varepsilon_2: \Nats^n \rightarrow \Reals^{\geq 0}$ and $\forall K \in \Nats^n: \varepsilon_2(K) \leq \varepsilon_1(K)$ then $\varepsilon_2 \in \mathcal{E}$.

\item There is a polynomial $h: \Nats^n \rightarrow \Nats$ s.t. $2^{-h} \in \mathcal{E}$.

\end{enumerate}

\end{definition}

\begin{example}

Given $n \in \Nats$, we define $\mathcal{E}_{\text{neg}}^n$, a fall space of rank $n$. For any $\varepsilon: \Nats^n \rightarrow \Reals^{\geq 0}$ bounded, $\varepsilon \in \mathcal{E}_{\text{neg}}^n$ iff for any $d \in \Nats$ and polynomials ${p_1,p_2 \ldots p_{n-1}: \Nats \rightarrow \Nats}$

$$\Lim{k} k^d \max_{j_1 \leq p_1(k)} \max_{j_2 \leq p_2(k)} \ldots \max_{j_{n-1} \leq p_{n-1}(k)} \varepsilon(k,j_1,j_2 \ldots j_{n-1}) = 0$$

\end{example}

\begin{example}

Given $n \in \Nats$, we define $\mathcal{E}_{\text{uneg}}^n$, a fall space of rank $n$. For any ${\varepsilon: \Nats^n \rightarrow \Reals^{\geq 0}}$ bounded, $\varepsilon \in \mathcal{E}_{\text{uneg}}^n$ iff for any $d \in \Nats$, ${J_1,J_2 \ldots J_{n-1}: \Nats \xrightarrow{alg} \Nats}$, and polynomials ${p_1,p_2 \ldots p_{n-1}: \Nats \rightarrow \Nats}$, ${q_1,q_2 \ldots q_{n-1}: \Nats \rightarrow \Nats}$, if $J_i \leq p_i$ and $\T_{J_i} \leq q_i$ then

$$\Lim{k} k^d \varepsilon(k,J_1(k),J_2(k) \ldots J_{n-1}(k)) = 0$$

\end{example}

We note a few simple properties of fall spaces which will be useful in the following.

\begin{proposition}
\label{prp:err_spc_zero}

For any fall space $\mathcal{E}$, $0 \in \mathcal{E}$.

\end{proposition}

\begin{proof}

Follows from conditions (ii) and (iii), since $0 \leq 2^{-h}$.

\end{proof}

\begin{proposition}

For any fall space $\mathcal{E}$, $\varepsilon \in \mathcal{E}$ and $c \in \Reals^{\geq 0}$, $c \varepsilon \in \mathcal{E}$.

\end{proposition}

\begin{proof}

By induction, condition (i) implies that for any $m \in \Nats$, $m\varepsilon \in \mathcal{E}$. It follows that $c\varepsilon \in \mathcal{E}$ since $c\varepsilon \leq \Ceil{c}\varepsilon$.

\end{proof}

\begin{proposition}

For any fall space $\mathcal{E}$ and $\varepsilon_1, \varepsilon_2 \in \mathcal{E}$, $\max(\varepsilon_1,\varepsilon_2) \in \mathcal{E}$

\end{proposition}

\proof{$$\max(\varepsilon_1,\varepsilon_2) \leq \varepsilon_1+\varepsilon_2$$}

\begin{proposition}
\label{prp:fall_space_closed_wrt_power}

For any fall space $\mathcal{E}$, $\varepsilon \in \mathcal{E}$ and $\alpha \in \Reals$, if $\alpha \geq 1$ then $\varepsilon^\alpha \in \mathcal{E}$.

\end{proposition}

\begin{proof}

$$\varepsilon^\alpha = (\sup \varepsilon)^\alpha (\frac{\varepsilon}{\sup \varepsilon})^\alpha \leq  (\sup \varepsilon)^\alpha \frac{\varepsilon}{\sup \varepsilon} \in \mathcal{E}$$

\end{proof}

\begin{proposition}

Consider $\mathcal{E}$ a fall space and $\alpha \in \Reals^{>0}$. Define ${\mathcal{E}^\alpha := \{\varepsilon^\alpha \mid \varepsilon \in \mathcal{E}\}}$. Then, $\mathcal{E}^\alpha$ is a fall space.

\end{proposition}

\begin{proof}

To check condition (i), consider $\varepsilon_1, \varepsilon_2 \in \mathcal{E}$. 

If $\alpha > 1$, $(\varepsilon_1^\alpha + \varepsilon_2^\alpha)^\frac{1}{\alpha} \leq \varepsilon_1 + \varepsilon_2 \in \mathcal{E}$ hence $(\varepsilon_1^\alpha + \varepsilon_2^\alpha)^\frac{1}{\alpha} \in \mathcal{E}$ and $\varepsilon_1^\alpha + \varepsilon_2^\alpha \in \mathcal{E}^\alpha$.

If $\alpha \leq 1$, $(\varepsilon_1^\alpha + \varepsilon_2^\alpha)^\frac{1}{\alpha} = 2^\frac{1}{\alpha}(\frac{\varepsilon_1^\alpha + \varepsilon_2^\alpha}{2})^\frac{1}{\alpha} \leq 2^\frac{1}{\alpha} \frac{\varepsilon_1+\varepsilon_2}{2} \in \mathcal{E}$ hence $(\varepsilon_1^\alpha + \varepsilon_2^\alpha)^\frac{1}{\alpha} \in \mathcal{E}$ and $\varepsilon_1^\alpha + \varepsilon_2^\alpha \in \mathcal{E}^\alpha$.

Conditions (ii) and (iii) are obvious.

\end{proof}

\begin{proposition}

Consider $\mathcal{E}$ a fall space and $\alpha_1,\alpha_2 \in \Reals^{>0}$ with $\alpha_1 \leq \alpha_2$. Then, ${\mathcal{E}^{\alpha_2} \subseteq \mathcal{E}^{\alpha_1}}$.

\end{proposition}

\begin{proof}

Follows from Proposition~\ref{prp:fall_space_closed_wrt_power}.

\end{proof}

We are now ready to give our central definition, which corresponds to a notion of "expected value" for distributional estimation problems.

\begin{definition}
\label{def:op}

Fix $\Gamma$ a pair of growth spaces of rank 2 and $\mathcal{E}$ a fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem and $P: \Words \xrightarrow{\Gamma} \Rats$ with bounded range. $P$ is called an \emph{$\mathcal{E}(\Gamma)$-optimal predictor for $(\mu,f)$} when for any $Q: \Words \xrightarrow{\Gamma} \Rats$ there is $\varepsilon \in \mathcal{E}$ s.t.

\begin{equation}
\label{eqn:op}
\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2] + \varepsilon(k,j)
\end{equation}

\end{definition}

Distributional \emph{decision} problems are the special case when the range of $f$ is $\Bool$. In this special case, the outputs of an optimal predictors can be thought of as probabilities\footnote{With some caveats. First, $P$ can take values outside $[0,1]$ but it's easy to see that clipping all values to $[0,1]$ preserves optimality. Second, $P^{kj}(x,y)=1$ doesn't imply $f(x) = 1$ and $P^{kj}(x,y)=0$ doesn't imply $f(x)=0$. We can try to fix this using a logarithmic error function instead of the squared norm, however this creates other difficulties and is outside the scope of the present work.}.

Note that $\varepsilon$ in (\ref{eqn:op}) depends on $Q$. However in some sense the optimality condition can be amplified to uniformity w.r.t. the resources required by $Q$.

\begin{proposition}
\label{prp:unif}

Fix $\Gamma=(\Gamma_{\mathfrak{R}},\Gamma_{\mathfrak{A}})$ a pair of growth spaces of rank 2 and $\mathcal{E}$ a fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem, $P$ an $\mathcal{E}(\Gamma)$-optimal predictor for $(\mu,f)$ and $F$ a uniform family of $\Gamma$-schemes of signature $\Words \rightarrow \Rats$. Then there is $\varepsilon \in \mathcal{E}$ s.t. for any $Q \in F$, equation~\ref{eqn:op} holds.

\end{proposition}

\begin{proof}

For any $k,j \in \Nats$, $\{\E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2] \mid Q \in F\}$ is a finite set because $F$ is a uniform family so the runtime of $Q^{kj}$ is bounded by a polynomial in $k,j$ that doesn't depend on $Q$. Therefore we can choose ${Q_{kj} \in \Argmin{Q \in F} \E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2]}$. By Proposition~\ref{prp:fam_diag}, there is $\bar{Q}: \Words \xrightarrow{\Gamma} \Rats$ s.t. $\bar{Q}^{kj}(x)$ is distributed the same as $Q_{kj}^{kj}(x)$.

Since $P$ is an $\mathcal{E}(\Gamma)$-optimal predictor, there is $\varepsilon \in \mathcal{E}$ s.t.

\begin{equation}
\label{eqn:prp__unif__prf1}
\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_{\bar{Q}}(k,j)}}[(\bar{Q}^{kj} - f)^2] + \varepsilon(k,j)
\end{equation}

For any $Q \in F$, we have 

$$\E_{\mu^k \times U^{\R_{\bar{Q}}(k,j)}}[(\bar{Q}^{kj} - f)^2]=\E_{\mu^k \times U^{\R_{Q_{kj}}(k,j)}}[(Q_{kj}^{kj} - f)^2]$$

\begin{equation}
\label{eqn:prp__unif__prf2}
\E_{\mu^k \times U^{\R_{\bar{Q}}(k,j)}}[(\bar{Q}^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2]
\end{equation}

Combining \ref{eqn:prp__unif__prf1} and \ref{eqn:prp__unif__prf2} we get the desired result.

\end{proof}

As usual, random is no more powerful than advice. This is demonstrated by the following two propositions.

\begin{proposition}

Fix $\Gamma=(\Gamma_{\mathfrak{R}},\Gamma_{\mathfrak{A}})$ a pair of growth spaces of rank 2 and $\mathcal{E}$ a fall space of rank 2. Observe that $\bar{\Gamma}_{\mathfrak{R}}:=\Gamma_{\mathfrak{R}}+\Gamma_{\mathfrak{A}}$ is a growth space and denote $\bar{\Gamma}:=(\bar{\Gamma}_{\mathfrak{R}},\Gamma_{\mathfrak{A}})$. Consider $(\mu,f)$ a distributional estimation problem and $P$ an $\mathcal{E}(\Gamma)$-optimal predictor for $(\mu,f)$. Then, $P$ is also an $\mathcal{E}(\bar{\Gamma})$-optimal predictor for $(\mu,f)$.

\end{proposition}

\begin{proof}

Consider any $Q: \Words \xrightarrow{\bar{\Gamma}} \Rats$. Suppose $\R_Q=r_{\mathfrak{R}}+r_{\mathfrak{A}}$ where $r_{\mathfrak{R}} \in \Gamma_{\mathfrak{R}}$ and $r_{\mathfrak{A}} \in \Gamma_{\mathfrak{A}}$. For any $k,j \in \Nats$, choose ${\bar{\A}_Q(k,j) \in \Argmin{y \in \WordsLen{r_{\mathfrak{A}}(k,j)}} \E_{(x,z) \sim \mu^k \times U^{r_{\mathfrak{R}}(k,j)}}[(Q^{kj}(x,yz) - f(x))^2]}$. As easy to see, there is $\bar{Q}: \Words \xrightarrow{\Gamma} \Rats$ s.t. for all $k,j \in \Nats$, $\R_{\bar{Q}}(k,j) = r_{\mathfrak{R}}(k,j)$, $\A_{\bar{Q}}(k,j):=\Chev{\A_Q(k,j),\bar{\A}_Q(k,j)}$ and for any $x \in \Supp \mu^k$ and $z \in \WordsLen{r_{\mathfrak{R}}(k,j)}$, ${\bar{Q}^{kj}(x,z)=Q^{kj}(x,\bar{\A}_Q(k,j)z)}$.

It follows that there is $\varepsilon \in \mathcal{E}$ s.t.

$$\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{r_{\mathfrak{R}}(k,j)}}[(\bar{Q}^{kj} - f)^2] + \varepsilon(k,j)$$

Obviously $\E_{\mu^k \times U^{r_{\mathfrak{R}}(k,j)}}[(\bar{Q}^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2]$ therefore

$$\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj} - f)^2] + \varepsilon(k,j)$$

\end{proof}

\begin{proposition}

Fix $\Gamma=(\Gamma_{\mathfrak{R}},\Gamma_{\mathfrak{A}})$ a pair of growth spaces of rank 2 and $\mathcal{E}$ a fall space of rank 2. Denote $\bar{\Gamma}_{\mathfrak{R}}:=\Gamma_{\mathfrak{R}}+\Gamma_{\mathfrak{A}}$ and $\bar{\Gamma}:=(\bar{\Gamma}_{\mathfrak{R}},\Gamma_{\mathfrak{A}})$. Consider $(\mu,f)$ a distributional estimation problem and $\bar{P}$ an $\mathcal{E}(\bar{\Gamma})$-optimal predictor for $(\mu,f)$. Then, there exists an $\mathcal{E}(\Gamma)$-optimal predictor for $(\mu,f)$.

\end{proposition}

\begin{proof}

Suppose $\R_{\bar{P}}=r_{\mathfrak{R}}+r_{\mathfrak{A}}$ where $r_{\mathfrak{R}} \in \Gamma_{\mathfrak{R}}$ and $r_{\mathfrak{A}} \in \Gamma_{\mathfrak{A}}$. For any ${k,j \in \Nats}$, choose ${\bar{\A}_P(k,j) \in \Argmin{y \in \WordsLen{r_{\mathfrak{A}}(k,j)}} \E_{(x,z) \sim \mu^k \times U^{r_{\mathfrak{R}}(k,j)}}[(\bar{P}^{kj}(x,yz) - f(x))^2]}$. We can construct $P: \Words \xrightarrow{\Gamma} \Rats$ so that for all $k,j \in \Nats$, $\R_P(k,j) = r_{\mathfrak{R}}(k,j)$, $\A_P(k,j):=\Chev{\A_{\bar{P}}(k,j),\bar{\A}_P(k,j)}$ and for any $x \in \Supp \mu^k$ and $z \in \WordsLen{r_{\mathfrak{R}}(k,j)}$, ${P^{kj}(x,z)=\bar{P}^{kj}(x,\bar{\A}_P(k,j)z)}$. Clearly ${\E_{\mu^k \times U^{r_{\mathfrak{R}}(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_{\bar{P}}(k,j)}}[(\bar{P}^{kj} - f)^2]}$ and therefore $P$ is an $\mathcal{E}(\Gamma)$-optimal predictor for $(\mu,f)$.

\end{proof}

\subsection{Orthogonality Theorems}

There is a variant of Definition~\ref{def:op} which is nearly equivalent in many cases and often useful. 

We can think of functions $f: \Supp \mu \rightarrow \Reals$ as vectors in a real inner product space with inner product $\Chev{f,g}:=\E_\mu[fg]$. Informally, we can think of $\Gamma$-schemes as a subspace (although a $\Gamma$-scheme is not even a function) and an $\mathcal{E}(\Gamma)$-optimal predictor for $(\mu,f)$ as the nearest point to $f$ in this subspace. Now, given an inner product space $V$, a vector $f \in V$, an actual subspace $W \subseteq V$ and $p = \Argmin{q \in W} \Norm{q - f}^2$, we have $\forall v \in W: \Chev{p-f,v}=0$. This motivates the following:

\begin {definition}

Fix $\Gamma$ a pair of growth spaces of rank 2 and $\mathcal{E}$ a fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem and $P: \Words \xrightarrow{\Gamma} \Rats$ with bounded range. $P$ is called an \emph{$\mathcal{E}^\sharp(\Gamma)$-optimal predictor for $(\mu,f)$} when for any $S: \Words \xrightarrow{\Gamma} \Rats$ with $\R_S \geq \R_P$

\begin{equation}
\label{eqn:op_sharp}
\Abs{\E_{(x,y,z) \sim \mu^k \times U^{\R_P(k,j)} \times U^{\R_S(k,j)-\R_P(k,j)}}[(P^{kj}(x,y) - f(x))S^{kj}(x,yz)]} \in \mathcal{E}
\end{equation}

\end {definition}

The following theorem is the analogue in our language of the previous fact about inner product spaces.

\begin{theorem}
\label{thm:ort}

Fix $\Gamma=(\Gamma_{\mathfrak{R}}$, $\Gamma_{\mathfrak{A}})$ a pair of growth spaces of rank 2 and $\mathcal{E}$ a fall space of rank 2. Assume there is $\zeta: \Nats^2 \rightarrow (0,\frac{1}{4}]$ s.t. $\zeta \in \mathcal{E}^{\frac{1}{2}}$ and ${\Floor{\log \log \frac{1}{\zeta}} \in \Gamma_{\mathfrak{A}}}$\footnote{If $\Floor{\log(k+2)}, \Floor{\log(j+2)} \in \Gamma_{\mathfrak{A}}$ (equivalently $\Gamma_{\text{log}}^2 \subseteq \Gamma_{\mathfrak{A}}$) then this condition holds for any $\mathcal{E}$ since we can take $\zeta = 2^{-h}$ for $h$ polynomial.}. Consider $(\mu,f)$ a distributional estimation problem and $P$ an $\mathcal{E}(\Gamma)$-optimal predictor for $(\mu,f)$. Then, $P$ is also an $\mathcal{E}^{\frac{1}{2}\sharp}(\Gamma)$-optimal predictor for $(\mu,f)$.

\end{theorem}

\begin{proof}

Assume without loss of generality that there is a polynomial ${h: \Nats^2 \rightarrow \Nats}$ s.t. $\zeta \geq 2^{-h}$ (otherwise we can take any polynomial $h$ s.t. $2^{-h} \in \mathcal{E}$ and consider $\zeta':=\zeta+2^{-h}$). Fix $S: \Words \xrightarrow{\Gamma} \Rats$ with $\R_S \geq \R_P$. Consider any ${\sigma: \Nats^2 \rightarrow \{ \pm 1 \}}$ and $n: \Nats^2 \rightarrow \Nats$ s.t. $n \leq \log \frac{1}{\zeta}$ (in particular $n \leq h$). Define ${t(k,j) := \sigma(k,j) 2^{-n(k,j)}}$. It is easy to see there is $Q_t: \Words \xrightarrow{\Gamma} \Rats$ s.t. given $k,j \in \Nats$, $x \in \Supp \mu^k$, ${y \in \WordsLen{\R_P(k,j)}}$ and $z \in \WordsLen{\R_P(k,j) - \R_S(k,j)}$, $Q_t^{kj}(x,yz) = P^{kj}(x,y) + t(k,j) S^{kj}(x,yz)$. Moreover, we can construct $Q_t$ for all admissible choices of $t$ (but fixed $S$) to get a uniform family.

Applying Proposition~\ref{prp:unif}, we conclude that there is $\varepsilon \in \mathcal{E}$ which doesn't depend on $t$ s.t.

$$\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_S(k,j)}}[(Q_t^{kj} - f)^2] + \varepsilon(k,j)$$

$$\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj} - f)^2] \leq \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} + t(k,j)S^{kj}  - f)^2] + \varepsilon(k,j)$$

$$\E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f)^2 - (P^{kj} + t(k,j)S^{kj} - f)^2] \leq \varepsilon(k,j)$$

$$-\E_{\mu^k \times U^{\R_S(k,j)}}[(t(k,j)S^{kj} + 2 (P^{kj} - f)) S^{kj}] t(k,j) \leq \varepsilon(k,j)$$

$$-\E_{\mu^k \times U^{\R_S(k,j)}}[(S^{kj})^2] t(k,j)^2 + 2 \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}] t(k,j) \leq \varepsilon(k,j)$$

$$2 \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}] t(k,j) \leq \E_{\mu^k \times U^{\R_S(k,j)}}[(S^{kj})^2] t(k,j)^2 + \varepsilon(k,j)$$

$$2 \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}] t(k,j) \leq (\sup \Abs{S^{kj}})^2 t(k,j)^2 + \varepsilon(k,j)$$

$$2 \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}] \sigma(k,j) 2^{-n(k,j)} \leq (\sup \Abs{S^{kj}})^2 4^{-n(k,j)} + \varepsilon(k,j)$$

Multiplying both sides by $2^{n(k,j)-1}$ we get

$$\E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}] \sigma(k,j) \leq \frac{1}{2}((\sup \Abs{S^{kj}})^2 2^{-n(k,j)} + \varepsilon(k,j) 2^{n(k,j)})$$

Let $\sigma(k,j):=\Sgn \E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}]$.

$$\Abs{\E_{\mu^k \times U^{\R_S(k,j)}}[(P^{kj} - f) S^{kj}]} \leq \frac{1}{2}((\sup \Abs{S^{kj}})^2 2^{-n(k,j)} + \varepsilon(k,j) 2^{n(k,j)})$$

Let $n(k,j):=\min(\Floor{\frac{1}{2}\log \max(\frac{1}{\varepsilon(k,j)},1)},\Floor{\log \frac{1}{\zeta(k,j)}})$.

$$\Abs{\E[(P^{kj} - f) S^{kj}]} \leq (\sup \Abs{S^{kj}})^2 \max(\min(\varepsilon(k,j)^{\frac{1}{2}},1),\zeta(k,j)) + \frac{1}{2}\varepsilon(k,j) \min(\max(\varepsilon(k,j)^{-\frac{1}{2}},1),\zeta(k,j)^{-1})$$

$$\Abs{\E[(P^{kj} - f) S^{kj}]} \leq (\sup \Abs{S^{kj}})^2 \max(\varepsilon(k,j)^{\frac{1}{2}},\zeta(k,j)) + \frac{1}{2} \max(\varepsilon(k,j)^{\frac{1}{2}},\varepsilon(k,j))$$

The right hand side is obviously in $\mathcal{E}^{\frac{1}{2}}$.

\end{proof}

Conversely, we have the following:

\begin{theorem}

Fix $\Gamma=(\Gamma_{\mathfrak{R}}$, $\Gamma_{\mathfrak{A}})$ a pair of growth spaces of rank 2 and $\mathcal{E}$ a fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem and $P$ an $\mathcal{E}^\sharp(\Gamma)$-optimal predictor for $(\mu,f)$. Then, $P$ is also an $\mathcal{E}(\Gamma)$-optimal predictor for $(\mu,f)$.

\end{theorem}

\begin{proof}

Consider any $Q: \Words \xrightarrow{\Gamma} \Rats$. We have

$$\E_{\mu^k \times U^{\R_Q(k,j)}}[(Q^{kj}-f)^2]=\E_{\mu^k \times U^{\R_Q(k,j)} \times U^{\R_P(k,j)}}[(Q^{kj}-P^{kj}+P^{kj}-f)^2]$$

$$\E[(Q^{kj}-f)^2]=\E[(Q^{kj}-P^{kj})^2]+2\E[(Q^{kj}-P^{kj})(P^{kj}-f)]+\E[(P^{kj}-f)^2]$$

$$\E[(P^{kj}-f)^2]+\E[(Q^{kj}-P^{kj})^2]=\E[(Q^{kj}-f)^2]+2\E[(P^{kj}-Q^{kj})(P^{kj}-f)]$$

$$\E[(P^{kj}-f)^2] \leq \E[(Q^{kj}-f)^2] + 2\E[(P^{kj}-Q^{kj})(P^{kj}-f)]$$

Applying \ref{eqn:op_sharp}, we conclude that there is $\varepsilon \in \mathcal{E}$ s.t. \ref{eqn:op} holds.

\end{proof}

\subsection{Simple Example}
\label{sec:fundamentals__one_way}

The concept of an optimal predictor is in some sense complementary to the concept of pseudorandom: a pseudorandom process deterministically produces output that appears random to bounded algorithms whereas optimal predictors compute the moments of the perceived random distributions of the outputs of deterministic processes. To demonstrate this complementarity and give an elementary example of an optimal predictor, we use the concept of a one-way function (which may be regarded as a function with pseudorandom inverse).

\begin{theorem}
\label{thm:one_way}

Consider $f: \Words \xrightarrow{alg} \Words$ a one-to-one one-way function. For every $k \in \Nats$, define $f^{(k)}: \WordsLen{k} \times \WordsLen{k} \rightarrow \Words$ by ${f^{(k)}(x,y):=\Chev{f(x),y}}$. Define $\mu_f^k:=f_*^{(k)}(U^k \times U^k).$ Finally, define $\chi_f: \Supp \mu \rightarrow \Bool$ by ${\chi_f(\Chev{f(x),y}):=x \cdot y}$.

Denote $\Gamma:=(\Gamma_{\textnormal{poly}}^2,\Gamma_0^2)$. Let $P: \Words \xrightarrow{\Gamma} \Rats$ satisfy $P \equiv \frac{1}{2}$. Then, $P$ is an $\mathcal{E}_{\textnormal{uneg}}^2(\Gamma)$-optimal predictor\footnote{Because of the way $\mathcal{E}_{\text{uneg}}^2$ is defined, we can also think of $P$ as a $(\Gamma_{\text{poly}}^1,\Gamma_0^1)$-scheme which is optimal among such schemes up to an error in $\mathcal{E}_{\text{neg}}^1$.} for $(\mu_f, \chi_f)$.

\end{theorem}

\begin{proof}

Assume to the contrary that $P$ is not optimal. Then there is ${Q: \Words \xrightarrow{\Gamma} \Rats}$, $d \in \Nats$, $J: \Nats \xrightarrow{alg} \Nats$, polynomials $p,q: \Nats \rightarrow \Nats$, an infinite set ${I \subseteq \Nats}$ and $\epsilon \in \Reals^{>0}$ s.t. $J \leq p$, $\T_J \leq q$ and

$$ \forall k \in I: \E_{\mu_f^k}[(\frac{1}{2}-\chi_f)^2] \geq \E_{\mu_f^k \times U^{\R_Q(k,J(k))}}[(Q^{k,J(k)}-\chi_f)^2] +\frac{\epsilon}{k^d}$$

$$ \forall k \in I: \E_{\mu_f^k \times U^{\R_Q(k,J(k))}}[(Q^{k,J(k)}-\chi_f)^2] \leq \frac{1}{4} - \frac{\epsilon}{k^d} $$

$$ \forall k \in I: \E_{\mu_f^k}[(\E_{U^{\R_Q(k,J(k))}}[Q^{k,J(k)}]-\chi_f)^2] \leq \frac{1}{4} - \frac{\epsilon}{k^d} $$

Denoting $\Gamma^1:=(\Gamma_{\text{poly}}^1,\Gamma_0^1)$, there is $G: \Words \xrightarrow{\Gamma^1} \Bool$ s.t. for all ${x \in \Words}$, ${\Abs{\E[Q^{k,J(k)}(x)]-\Pr[G^k(x)=1]}\leq 2^{-k}}$ ($G^k$ works by evaluating ${\alpha \leftarrow Q^{k,J(k)}}$ and then returning 1 with probability $\alpha \pm 2^{-k}$ and 0 with probability $1-\alpha \pm 2^{-k}$, where the $2^{-k}$ error comes from rounding a rational number to a binary fraction). Denoting $\delta(x):=\E[Q^{k,J(k)}(x)]-\Pr[G^k(x)=1]$

$$ \forall k \in I: \E_{\mu_f^k}[(\Prb_{U^{\R_G(k)}}[G^k=1]+\delta-\chi_f)^2] \leq \frac{1}{4} - \frac{\epsilon}{k^d} $$

$$ \forall k \in I: \E_{\mu_f^k}[(\Prb_{U^{\R_G(k)}}[G^k=1]-\chi_f)^2]+2 \E_{\mu_f^k}[(\Prb_{U^{\R_G(k)}}[G^k=1]-\chi_f)\delta]+\E_{\mu_f^k}[\delta^2] \leq \frac{1}{4} - \frac{\epsilon}{k^d}$$

$$ \forall k \in I: \E_{\mu_f^k}[(\Prb_{U^{\R_G(k)}}[G^k=1]-\chi_f)^2]-2 \cdot 2^{-k}- 4^{-k} \leq \frac{1}{4} - \frac{\epsilon}{k^d}$$

Since $2^{-k}$ falls faster than $k^{-d}$, there is $I_1 \subseteq \Nats$ infinite and $\epsilon_1 \in \Reals^{>0}$ s.t.

$$ \forall k \in I_1: \E_{\mu_f^k}[(\Prb_{U^{\R_G(k)}}[G^k=1]-\chi_f)^2] \leq \frac{1}{4} - \frac{\epsilon_1}{k^d}$$

$$ \forall k \in I_1: \E_{\mu_f^k}[\Abs{\Prb_{U^{\R_G(k)}}[G^k=1]-\chi_f}] \leq \sqrt{\frac{1}{4} - \frac{\epsilon_1}{k^d}} $$

$$ \forall k \in I_1: \E_{\mu_f^k}[\Prb_{U^{\R_G(k)}}[G^k \ne \chi_f]] \leq \sqrt{\frac{1}{4} - \frac{\epsilon_1}{k^d}} $$

$$ \forall k \in I_1: \E_{(x,y) \sim U^k \times U^k}[\Prb_{U^{\R_G(k)}}[G^k(\Chev{f(x),y}) \ne x \cdot y]] \leq \sqrt{\frac{1}{4} - \frac{\epsilon_1}{k^d}} $$

$$ \forall k \in I_1: \Prb_{U^k \times U^k \times U^{\R_G(k)}}[G^k(\Chev{f(x),y}) \ne x \cdot y] \leq \sqrt{\frac{1}{4} - \frac{\epsilon_1}{k^d}} $$

Since $\sqrt{t}$ is a concave function and the derivative of $\sqrt{t}$ is $\frac{1}{2\sqrt{t}}$, we have $\sqrt{t} \leq \sqrt{t_0} + \frac{t-t_0}{2\sqrt{t_0}}$. We get

$$ \forall k \in I_1: \Prb_{U^k \times U^k \times U^{\R_G(k)}}[G^k(\Chev{f(x),y}) \ne x \cdot y] \leq \frac{1}{2}-\frac{\epsilon_1}{k^d}$$

$$ \forall k \in I_1: \Prb_{U^k \times U^k \times U^{\R_G(k)}}[G^k(\Chev{f(x),y}) = x \cdot y] \geq \frac{1}{2}+\frac{\epsilon_1}{k^d}$$

This contradicts Theorem~\ref{thm:hard_core}.

\end{proof}

The following is the non-uniform version of Theorem~\ref{thm:one_way} which we state without proof since the proof is a straightforward adaptation of the above (using Theorem~\ref{thm:hard_core_circ} in place of Theorem~\ref{thm:hard_core}).

\begin{theorem}

Consider $f: \Words \xrightarrow{alg} \Words$ a one-to-one non-uniformly hard to invert one-way function.

Denote $\Gamma:=(\Gamma_{\textnormal{poly}}^2,\Gamma_{\textnormal{poly}}^2)$. Let $P: \Words \xrightarrow{\Gamma} \Rats$ satisfy $P \equiv \frac{1}{2}$. Then, $P$ is an $\mathcal{E}_{\textnormal{neg}}^2(\Gamma)$-optimal predictor for $(\mu_f, \chi_f)$.

\end{theorem}

\section{Optimal Predictors and Probability Theory}
\label{sec:probability}

\subsection{Calibration}

From a Bayesian perspective, a good probability assignment should be calibrated. For example, suppose there 100 people in a room and you assign each person a probability they are married. If there are 60 people you assigned probabilities in the range 70\%-80\%, the number of married people among these 60 should be close to the interval $60 \times [0.7, 0.8] = [42,48]$. The same requirement can be made for expected value assignments. For example, if you now need to assign an expected value to the age of each person and you assigned an expected age in the range 30-40 to some sufficiently large group of people, the mean age in the group should be close to the interval $[30,40]$. 

We will now show that optimal predictors satisfy an analogous property.

\begin{definition}

Given $n \in \Nats$, a growth space $\Gamma$ of rank $n$ and a fall space $\mathcal{E}$ of rank $n$, $\mathcal{E}$ is called \emph{$\Gamma$-ample} when there is $\zeta: \Nats^n \rightarrow (0,\frac{1}{2}]$ s.t.  $\zeta \in \mathcal{E}$ and $\Floor{\log \frac{1}{\zeta}} \in \Gamma$.

\end{definition}

\begin{theorem}
\label{thm:calib}

Fix $\Gamma:=(\Gamma_{\mathfrak{R}},\Gamma_{\mathfrak{A}})$ a pair of growth spaces of rank 2 and $\mathcal{E}$ a $\Gamma_{\mathfrak{A}}$-ample fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem, $P$ an $\mathcal{E}(\Gamma)$-optimal predictor for $(\mu,f)$, $s,t: \Nats^2 \rightarrow \Reals$. denote ${\alpha(k,j):=\Prb_{\mu^k \times U^{\R_P(k,j)}}[s(k,j) \leq P^{kj} \leq t(k,j)]}$ and ${\delta(k,j):=\E_{\mu^k \times U^{\R_P(k,j)}}[P^{kj}-f \mid s(k,j) \leq P^{kj} \leq t(k,j)]}$. Then, $\alpha \delta^2 \in \mathcal{E}$.

\end{theorem}

To see the relationship between Theorem~\ref{thm:calib} and calibration, consider the following corollary.

\begin{corollary}

In the setting of Theorem~\ref{thm:calib}, there is $\varepsilon \in \mathcal{E}$ s.t. 

\begin{equation}
s(k,j) - \sqrt{\frac{\varepsilon(k,j)}{\alpha(k,j)}} \leq \E[f \mid s(k,j) \leq P^{kj} \leq t(k,j)] \leq t(k,j) + \sqrt{\frac{\varepsilon(k,j)}{\alpha(k,j)}}
\end{equation}

\end{corollary}

\begin{proof}

$$\E[f \mid s(k,j) \leq P^{kj} \leq t(k,j)] = \E[P^{kj}-P^{kj}+f \mid s(k,j) \leq P^{kj} \leq t(k,j)]$$

$$\E[f \mid s(k,j) \leq P^{kj} \leq t(k,j)] = \E[P^{kj} \mid s(k,j) \leq P^{kj} \leq t(k,j)]-\E[P^{kj}-f \mid s(k,j) \leq P^{kj} \leq t(k,j)]$$

$$\E[f \mid s(k,j) \leq P^{kj} \leq t(k,j)] \leq t(k,j)+\Abs{\delta(k,j)}$$

Denoting $\varepsilon := \alpha \delta^2$, we conclude that

$$\E[f \mid s(k,j) \leq P^{kj} \leq t(k,j)] \leq t(k,j) + \sqrt{\frac{\varepsilon(k,j)}{\alpha(k,j)}}$$

In the same manner, we can show that

$$\E[f \mid s(k,j) \leq P^{kj} \leq t(k,j)] \geq s(k,j) - \sqrt{\frac{\varepsilon(k,j)}{\alpha(k,j)}}$$

\end{proof}

To prove Theorem~\ref{thm:calib}, we need the following proposition.

\begin{proposition}
\label{prp:weight}

Fix $\Gamma:=(\Gamma_{\mathfrak{R}},\Gamma_{\mathfrak{A}})$ a pair of growth spaces of rank 2 and $\mathcal{E}$ a $\Gamma_{\mathfrak{A}}$-ample fall space of rank 2. Consider $(\mu,f)$ a distributional estimation problem, $P$ an $\mathcal{E}(\Gamma)$-optimal predictor for $(\mu,f)$, $Q: \Words \xrightarrow{\Gamma} \Rats$ and ${W: \Words \xrightarrow{\Gamma} \Rats^{\geq 0}}$ bounded s.t. $\R_W \geq \max(\R_P, \R_Q)$. Denote ${\mu^{kj}_{P,W}:=\mu^k \times U^{\R_P(k,j)} \times U^{\R_W(k,j)-\R_P(k,j)}}$, ${\mu^{kj}_{Q,W}:=\mu^k \times U^{\R_Q(k,j)} \times U^{\R_W(k,j)-\R_Q(k,j)}}$. Then, there is $\varepsilon \in \mathcal{E}$ s.t.

\begin{equation}
\E_{\mu^{kj}_{P,W}}[W^{kj}(P^{kj} - f)^2] \leq \\ \E_{\mu^{kj}_{Q,W}}[W^{kj}(Q^{kj} - f)^2] + \varepsilon(k,j)
\end{equation}

\end{proposition}

\begin{proof}

Consider $\zeta: \Nats^2 \rightarrow (0,\frac{1}{2}]$ s.t.  $\zeta \in \mathcal{E}$ and $\Floor{\log \frac{1}{\zeta}} \in \Gamma_{\mathfrak{A}}$. For any $k,j \in \Nats$ and $t \in \Reals$, let $\rho_\zeta^{kj}(t) \in \Argmin{s \in \Rats \cap [t-\zeta(k,j),t+\zeta(k,j)]} e_\Rats(s)$. Denote $M:= \sup W$. It is easy to see that there is $\gamma \in \Gamma_{\mathfrak{A}}$ s.t. for any $t \in [0, M]$, $\Abs{e_\Rats(\rho_\zeta^{kj}(t))} \leq \gamma(k,j)$.

For any $t \in \Reals$ there is $Q_t: \Words \xrightarrow{\Gamma} \Rats$ s.t. for any $x \in \Supp \mu^k$ and ${y \in \WordsLen{\R_W(k,j)}}$

$$Q_t^{kj}(x,y)=\begin{cases}Q^{kj}(x,y_{\leq \R_Q(k,j)}) \text{ if } W^{kj}(x,y) \geq \rho^{kj}_\zeta(t) \\ P^{kj}(x,y_{\leq \R_P(k,j)}) \text{ if } W^{kj}(x,y) < \rho^{kj}_\zeta(t)\end{cases}$$

Moreover we can construct the $Q_t$ for all $t \in [0, M]$ s.t. they form a uniform family. By Proposition~\ref{prp:unif} there is $\varepsilon \in \mathcal{E}$ s.t. for all $t \in [0, M]$

$$\E_{\mu^k \times U^{\R_P(k,j)}}[(P^{kj}-f)^2] \leq \E_{\mu^k \times U^{\R_W(k,j)}}[(Q_t^{kj}-f)^2] + \varepsilon(k,j)$$

$$\E_{(x,y) \sim \mu^k \times U^{\R_W(k,j)}}[(P^{kj}(x,y_{\leq \R_P(k,j)})-f(x))^2-(Q_t^{kj}(x,y)-f(x))^2] \leq \varepsilon(k,j)$$

The expression inside the expected values vanishes when $W^{kj}(x,y) < \rho^{kj}_\zeta(t)$. In other cases, $Q_t^{kj}(x,y) = Q^{kj}(x,y_{\leq \R_Q(k,j)})$. We get

$$\E_{(x,y) \sim \mu^k \times U^{\R_W(k,j)}}[\theta(W^{kj}(x,y)-\rho_\zeta^{kj}(t)) \cdot ((P^{kj}(x,y_{\leq \R_P(k,j)})-f(x))^2-(Q^{kj}(x,y_{\leq \R_Q(k,j)})-f(x))^2)] \leq \varepsilon(k,j)$$

We integrate both sides of the inequality over $t$ from 0 to $M$.

\begin{equation}
\label{eqn:prp__weight__prf1}
\E[\int_0^M\theta(W^{kj}-\rho_\zeta^{kj}(t)) \dif t \cdot ((P^{kj}-f)^2-(Q^{kj}-f)^2)] \leq M \varepsilon(k,j)
\end{equation}

For any $s \in \Reals$

$$\int_0^M \theta(s-\rho_\zeta^{kj}(t)) \dif t = \int_0^{s-\zeta(k,j)} \theta(s-\rho_\zeta^{kj}(t)) \dif t + \int_{s-\zeta(k,j)}^{s+\zeta(k,j)} \theta(s-\rho_\zeta^{kj}(t)) \dif t + \int_{s+\zeta(k,j)}^M \theta(s-\rho_\zeta^{kj}(t)) \dif t$$

$\Abs{\rho_\zeta^{kj}(t)-t} \leq \zeta(k,j)$ therefore the integrand in the first term is 1 and in the last term 0:

$$\int_0^M \theta(s-\rho_\zeta^{kj}(t)) \dif t = \int_0^{s-\zeta(k,j)} \dif t + \int_{s-\zeta(k,j)}^{s+\zeta(k,j)} \theta(s-\rho_\zeta^{kj}(t)) \dif t$$

$$\int_0^M \theta(s-\rho_\zeta^{kj}(t)) \dif t = s-\zeta(k,j) + \int_{s-\zeta(k,j)}^{s+\zeta(k,j)} \theta(s-\rho_\zeta^{kj}(t)) \dif t$$

$$\int_0^M \theta(s-\rho_\zeta^{kj}(t)) \dif t - s = \zeta(k,j) + \int_{s-\zeta(k,j)}^{s+\zeta(k,j)} \theta(s-\rho_\zeta^{kj}(t)) \dif t$$

\begin{equation}
\label{eqn:prp__weight__prf2}
\int_0^M \theta(s-\rho_\zeta^{kj}(t)) \dif t - s \in [0,3\zeta(k,j)]
\end{equation}

Combining \ref{eqn:prp__weight__prf1} and \ref{eqn:prp__weight__prf2} we conclude that for some $M' \in \Reals^{\geq 0}$

$$\E[W^{kj} \cdot ((P^{kj}-f)^2-(Q^{kj}-f)^2)] \leq M \varepsilon(k,j) + M'\zeta(k,j)$$

\end{proof}

Proposition~\ref{prp:weight} shows that...

We are now ready to prove Theorem~\ref{thm:calib}.

\begin{proof}[Proof of Theorem \ref{thm:calib}]

Haha!

\end{proof}

TBD

\subsection{Algebraic Properties}

TBD

\section{Reductions and Completeness}
\label{sec:reductions}

TBD

\section{Existence and Uniqueness}
\label{sec:e_and_u}

TBD

\section{Reflective Systems and Game Theory}
\label{sec:reflective}

TBD

\section{Discussion}
\label{sec:discussion}

TBD

\appendix

\section{Appendix: One-Way Functions}

We review the definition of a one-way function and a non-uniformly hard one-way function and state a theorem by Goldreich and Levin which is used in Section~\ref{sec:fundamentals__one_way}.

We will use the notation $\Gamma_{\text{rand}}:=(\Gamma_{\text{poly}}^1,\Gamma_0^1)$, $\Gamma_{\text{circ}}:=(\Gamma_0^1,\Gamma_{\text{poly}}^1)$.

\begin{samepage}
\begin{definition}

$f: \Words \xrightarrow{alg} \Words$ is called an \emph{one-way function}
when

\begin{enumerate}[(i)]

\item There is $p: \Nats \rightarrow \Nats$ polynomial s.t. $\forall x \in \Words: \T_f(x) \leq p(\Abs{x})$.

\item For any $S: \Words \xrightarrow{\Gamma_{\text{rand}}} \Words$, ${\Prb_{U^k \times U^{\R_S(k)}}[f(S^k(f(x)))=x] \in \mathcal{E}_{\text{neg}}^1}$.

\end{enumerate}

\end{definition}
\end{samepage}

\begin{samepage}
\begin{definition}

$f: \Words \xrightarrow{alg} \Words$ is called a \emph{non-uniformly hard to invert} one-way function
when

\begin{enumerate}[(i)]

\item There is $p: \Nats \rightarrow \Nats$ polynomial s.t. $\forall x \in \Words: \T_f(x) \leq p(\Abs{x})$.

\item For any $S: \Words \xrightarrow{\Gamma_{\text{circ}}} \Words$, ${\Prb_{U^k \times U^{\R_S(k)}}[f(S^k(f(x)))=x] \in \mathcal{E}_{\text{neg}}^1}$.

\end{enumerate}

\end{definition}
\end{samepage}

It is easy to see that any non-uniformly hard to invert one-way function is in particular a one-way function.

The following appears in \cite{Goldreich_2008} as Theorem 7.7. Here we state it in the notation of the present work.

\begin{theorem}[Goldreich-Levin]
\label{thm:hard_core}

Consider a one-way function ${f: \Words \xrightarrow{alg} \Words}$ and $G: \Words \times \Words \xrightarrow{\Gamma_{\textnormal{rand}}} \Bool$. Then there is $\varepsilon \in \mathcal{E}_{\textnormal{neg}}^1$ s.t. 

\begin{equation}
\Prb_{(x,y,z) \sim U^k \times U^k \times U^{\R_G(k)}}[G^k(f(x),y,z)=x \cdot y] \leq \frac{1}{2} + \varepsilon(k)
\end{equation}

\end{theorem}

There is also a non-uniform version of the theorem which is not stated in \cite{Goldreich_2008}, but its proof is a straightforward adaptation.

\begin{theorem}
\label{thm:hard_core_circ}

Consider a non-uniformly hard one-way function ${f: \Words \xrightarrow{alg} \Words}$ and $G: \Words \times \Words \xrightarrow{\Gamma_{\textnormal{circ}}} \Bool$. Then there is $\varepsilon \in \mathcal{E}_{\textnormal{neg}}^1$ s.t. 

\begin{equation}
\Prb_{(x,y) \sim U^k \times U^k}[G^k(f(x),y)=x \cdot y] \leq \frac{1}{2} + \varepsilon(k)
\end{equation}

\end{theorem}

\section*{Acknowledgments}

TBD

\bibliographystyle{unsrt}
\bibliography{Optimal_Predictors}

\end{document}

