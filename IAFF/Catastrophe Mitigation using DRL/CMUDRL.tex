%&latex
\documentclass[a4paper]{article}

\usepackage[a4paper,margin=1in]{geometry}
\usepackage[affil-it]{authblk}
\usepackage{cite}
\usepackage[unicode]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{commath}

\newcommand{\Comment}[1]{}

\newcommand{\Bool}{\{0,1\}}
\newcommand{\Words}{{\Bool^*}}

% operators that are separated from the operand by a space
\DeclareMathOperator{\Sgn}{sgn}
\DeclareMathOperator{\Supp}{supp}
\DeclareMathOperator{\Stab}{stab}
\DeclareMathOperator{\Img}{Im}
\DeclareMathOperator{\Dom}{dom}

% autosize deliminaters
\newcommand{\AP}[1]{\left(#1\right)}
\newcommand{\AB}[1]{\left[#1\right]}
\newcommand{\AC}[1]{\left\{#1\right\}}

% operators that require brackets
\newcommand{\Pa}[2]{\underset{#1}{\operatorname{Pr}}\AB{#2}}
\newcommand{\PP}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{Pr}}}
\newcommand{\PPP}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{Pr}}}
\newcommand{\E}[1]{\underset{#1}{\operatorname{E}}}
\newcommand{\Ea}[2]{\underset{#1}{\operatorname{E}}\AB{#2}}
\newcommand{\EE}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{E}}}
\newcommand{\EEE}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{E}}}
\newcommand{\I}[1]{\underset{#1}{\operatorname{I}}}
\newcommand{\Ia}[2]{\underset{#1}{\operatorname{I}}\AB{#2}}
\newcommand{\II}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{I}}}
\newcommand{\III}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{I}}}
\newcommand{\Var}{\operatorname{Var}}

% operators that require parentheses
\newcommand{\En}{\operatorname{H}}
\newcommand{\Ena}[1]{\operatorname{H}\AP{#1}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\End}{\operatorname{End}}
\newcommand{\Sym}{\operatorname{Sym}}

\newcommand{\Prj}{\operatorname{pr}}

\newcommand{\D}{\mathrm{d}}
\newcommand{\KL}[2]{\operatorname{D}_{\mathrm{KL}}(#1 \| #2)}
\newcommand{\Dtv}{\operatorname{d}_{\text{tv}}}
\newcommand{\Dtva}[1]{\operatorname{d}_{\text{tv}}\AP{#1}}

\newcommand{\Argmin}[1]{\underset{#1}{\operatorname{arg\,min}}\,}
\newcommand{\Argmax}[1]{\underset{#1}{\operatorname{arg\,max}}\,}

\newcommand{\Nats}{\mathbb{N}}
\newcommand{\Ints}{\mathbb{Z}}
\newcommand{\Rats}{\mathbb{Q}}
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\Coms}{\mathbb{C}}

\newcommand{\Sq}[2]{\{#1\}_{#2 \in \Nats}}
\newcommand{\Sqn}[1]{\Sq{#1}{n}}

\newcommand{\Estr}{\boldsymbol{\lambda}}

\newcommand{\Lim}[1]{\lim_{#1 \rightarrow \infty}}
\newcommand{\LimInf}[1]{\liminf_{#1 \rightarrow \infty}}
\newcommand{\LimSup}[1]{\limsup_{#1 \rightarrow \infty}}

\newcommand{\Abs}[1]{\left\vert #1 \right\vert}
\newcommand{\Norm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\Floor}[1]{\lfloor #1 \rfloor}
\newcommand{\Ceil}[1]{\lceil #1 \rceil}
\newcommand{\Chev}[1]{\langle #1 \rangle}
\newcommand{\Quote}[1]{\ulcorner #1 \urcorner}

\newcommand{\Alg}{\xrightarrow{\textnormal{alg}}}
\newcommand{\M}{\xrightarrow{\textnormal{k}}}
\newcommand{\PF}{\xrightarrow{\circ}}

% Paper specific

\newcommand{\Ob}{\mathcal{O}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\St}{\mathcal{S}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\In}{\mathcal{I}}
\newcommand{\FH}{(\A \times \Ob)^*}
\newcommand{\IH}{(\A \times \Ob)^\omega}
\newcommand{\Ado}{\bar{\Ob}}
\newcommand{\Ada}{\bar{\A}}
\newcommand{\Adi}{{\bar{\In}}}
\newcommand{\Adao}{\overline{\A \times \Ob}}
\newcommand{\Adfh}{\Adao^*}
\newcommand{\Adih}{\Adao^\omega}
\DeclareMathOperator{\HD}{hdom}
\newcommand{\Hy}{\mathcal{H}}
\newcommand{\UC}{\mathcal{U}}

\newcommand{\RMC}{\mathrm{C}}
\newcommand{\RMD}{\mathrm{D}}
\newcommand{\RME}{\mathrm{E}}
\newcommand{\RMF}{\mathrm{F}}

\newcommand{\SF}{\St^{\RMF}}
\newcommand{\SD}{\St^{\RMD}}
\newcommand{\SC}{\St^{\RMC}}
\newcommand{\MF}{M^{\RMF}}
\newcommand{\MD}{M^{\RMD}}
\newcommand{\ME}{M^{\RME}}
\newcommand{\TF}{\bar{\tau}^{\RMF}}
\newcommand{\PD}{\pi^{\RMD}}
\newcommand{\UD}{\upsilon^{\RMD}}

\newcommand{\Ut}{\operatorname{U}}
\newcommand{\V}{\operatorname{V}}
\newcommand{\Q}{\operatorname{Q}}
\newcommand{\EU}{\operatorname{EU}}

\newcommand{\Dl}{\mathcal{D}}
\newcommand{\Do}{\mathfrak{D}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\Z}{Z}
\newcommand{\J}{J}

\begin{document}

[Previously](https://agentfoundations.org/item?id=1656) we derived a regret bound for DRL which assumed the advisor is "locally sane." Such an advisor can only take actions that don't lose any value in the long term. In particular, if the environment contains a latent *catastrophe* that manifests with a certain rate (such as the possibility of an UFAI), a locally sane advisor has to take the optimal course of action to mitigate it, since every delay yields a positive probability of the catastrophe manifesting and leading to permanent loss of value. This state of affairs is unsatisfactory, since we would like to have performance guarantees for an AI that can mitigate catastrophes that the human operator cannot mitigate on their own. To address this problem, we introduce a new form of DRL where in every hypothetical environment the set of uncorrupted states is divided into "dangerous" (impending catastrophe) and "safe" (catastrophe was mitigated). The advisor is then only required to be locally sane in safe states, whereas in dangerous states certain "leaking" of long-term value is allowed. We derive a regret bound in this setting as a function of the time discount factor, the expected value and standard deviation of the catastrophe mitigation time for the optimal policy, and the "value leak" rate (i.e. essentially the rate of catastrophe occurrence). The form of this regret bound implies that in certain asymptotic regimes, the agent attains near-optimal expected utility (and in particular mitigates the catastrophe with probability close to 1), whereas the advisor on its own *fails* to mitigate the catastrophe with probability close to 1. %Thus, this formalism can be regarded as a simple model of aligned superintelligence: the agent is *aligned* since near-optimal utility is achieved despite the presence of corrupted states (which are treated more or less the same as before) and it is *super*intelligent since its performance is vastly better than the performance of the advisor.

***

Appendix A proves the main theorem. Appendix B contains the proof of an important lemma which is however almost identical to what appeared in the previous essay. Appendix C contains several propositions from the previous essay which we are used in the proof.

\section{Notation}

Whatever...

\section{Results}

We start by formalising the concepts of a "catastrophe" and "catastrophe mitigation" in the language of MDPs.

\#Definition N1

A *catastrophe MDP* is an MDP $M$ together with a partition of $\St_M$ into subsets $\St_M:=\SF_M \sqcup \SD_M \sqcup \SC_M$ (safe, dangerous and corrupt states respectively).

\#Definition N7

Fix a catastrophe MDP $M$. Define $\A_M^\sharp: \St_M \rightarrow 2^{\A_M}$ by

$$\A_M^\sharp(s):=\begin{cases} \{a \in \A_M \mid \Supp{\T(s,a)} \subseteq \SF_M\} \text{ if } s \in \SF_M \\ \{a \in \A_M \mid \Supp{\T(s,a)} \cap \SC_M = \varnothing\} \text{ if } s \in \SD_M \\ \A_M \text{ if } s \in \SC_M \end{cases}$$

$\pi: \St_M \M \A_M$ is called a *mitigation policy for $M$* when 

i. For any $s \in \St_M$, $\Supp{\pi(s)} \subseteq \A_M^\sharp(s)$. 

$\pi$ is called a *proper mitigation policy for $M$* when condition i holds and

ii. For any $s \in \SD_M$, $\lim_{n \rightarrow \infty} \T_{M\pi}^n\AP{\SF_M \mid s} = 1$. 

\Comment{Given $k \in \Nats$, $\pi$ is called a *proper k-mitigation policy for $M$* when conditions i+ii hold and

iii. For any $s \in \St_D$, $\Supp{\pi(s)} \subseteq \A_M^k(s)$.

iv. For any $s \in \St_F$, $\Supp{\pi(s)} \subseteq \A_M^{k+1}(s)$.}

\#Definition N2

Fix $\bar{\tau}_1,\bar{\tau}_2 \in (0,\infty)$, a catastrophe MDP $M$ and a proper mitigation policy $\pi$. $\pi$ is said to have *mitigation time moments $\bar{\tau}_1,\bar{\tau}_2$* when for any $s \in \SD_M$

i. $$\sum_{n=0}^\infty (n+1) \AP{\T_{M\pi}^{n+1}\AP{\SF_M \mid s}-\T_{M\pi}^{n}\AP{\SF_M \mid s}} = \bar{\tau}_1$$

ii. $$\sum_{n=0}^\infty (n+1)^2 \AP{\T_{M\pi}^{n+1}\AP{\SF_M \mid s}-\T_{M\pi}^{n}\AP{\SF_M \mid s}} = \bar{\tau}_2$$

***

Next, we introduce the notion of an MDP perturbation. We will use it by considering perturbations of a catastrophe MDP which "eliminate the catastrophe."

\#Definition N3

Fix $\delta\in(0,1)$ and consider a catastrophe MDP $M$. An MDP $\tilde{M}$ is said to be a *$\delta$-perturbation of $M$* when

i. $\St_{\tilde{M}} = \St_M$

ii. $\A_{\tilde{M}} = \A_M$

iii. $\R_{\tilde{M}}=\R_M$

iv. For any $s \in \SF_M$ and $a \in \A_M$, $\T_{\tilde{M}}\AP{s,a}=\T_{M}\AP{s,a}$

v. For any $s \in \SD_M$ and $a \in \A_M$, there exists $\zeta \in \Delta\St_M$ s.t. $\T_{M}\AP{s,a}=(1-\delta)\T_{\tilde{M}}\AP{s,a}+\delta\zeta$.

***

Similarly, we can consider perturbations of a policy.

\#Definition N4

Fix $\delta\in(0,1)$ and consider a catastrophe MDP $M$. Given $\pi: \St_M \M \A_M$ and $\tilde{\pi}: \St_M \M \A_M$, $\tilde{\pi}$ is said to be a *$\delta$-perturbation of $\pi$* when

i. For any $s \in \SF_M$, $\tilde{\pi}(s) = \pi(s)$.

ii. For any $s \in \SD_M$, there exists $\alpha\in\Delta\A$ s.t. $\pi(s)=(1-\delta)\tilde{\pi}(s)+\delta\alpha$.

***

We will also need to introduce policy-specific value functions, Q-functions and relatively $k$-optimal actions.

\#Definition N5

Fix an MDP $M$ and $\pi: \St_M \M \A_M$. We define $\V_{M\pi}: \St_M \times (0,1) \rightarrow [0,1]$ and $\Q_{M\pi}: \St_M \times \A_M \times (0,1) \rightarrow [0,1]$ by

$$\V_{M\pi}(s,\gamma) := (1-\gamma) \sum_{n=0}^\infty \gamma^n \Ea{\T_{M\pi}^n(s)}{\R_M}$$

$$\Q_{M\pi}(s,a,\gamma) := (1-\gamma) \R_M(s) + \gamma \Ea{t \sim \T_{M}(s,a)}{\V_{M\pi}(t,\gamma)}$$

For each $k \in \Nats$, we define $\V_{M\pi}^k: \St_M \rightarrow \Reals$, $\Q_{M\pi}^k: \St_M \times \A_M \rightarrow \Reals$ and $\A_{M\pi}^k: \St_M \rightarrow 2^{\A_M}$ by

$$\V_{M\pi}^k(s) := (-1)^k \frac{\D^k \V_{M\pi}(s,\gamma)}{\D\gamma^k}\bigg\vert_{\gamma=1}$$

$$\Q_{M\pi}^k(s,a) := (-1)^k \frac{\D^k \Q_{M\pi}(s,a,\gamma)}{\D\gamma^k}\bigg\vert_{\gamma=1}$$

$$\A_{M\pi}^0(s) := \{a \in \A_M \mid \Q_{M\pi}^0(s,a) \geq \V_{M\pi}^0(s)\}$$

$$\A_{M\pi}^{k+1}(s) := \{a \in \A_{M\pi}^k(s) \mid \Q_{M\pi}^{k+1}(s,a) \geq \V_{M\pi}^{k+1}(s) \text{ or } \exists j \leq k: \Q_{M\pi}^{j}(s,a) > \V_{M\pi}^{j}(s)\}$$

***

Now we give the new (weaker) condition on the advisor policy. For notational simplicity, we assume the policy is stationary. It is easy to generalize these results to non-stationary advisor policies and to policies that depend on irrelevant additional information (i.e. policies for universes that are *realizations* of the MDP).

\#Definition N8

Given a catastrophe MDP $M$, we denote $M^\flat$ the MDP defined by

* $\St_{M^\flat} = \St_M$

* $\A_{M^\flat} = \A_M$

* $\T_{M^\flat} = \T_M$

* For any $s\not\in\SF_M$, $\R_{M^\flat}(s) = 0$.

* For any $s \in \SF_M$, $\R_{M^\flat}(s) = \frac{1}{2} + \frac{1}{2}\R_M(s)$.

\#Definition N6

Fix $\epsilon,\delta,\gamma \in (0,1)$. Consider a catastrophe MDP $M$. A policy $\pi: \St_M \M \A_M$ is said to be *locally $(\epsilon,\delta)$-sane* for $(M,\gamma)$ when there exists a $\delta$-perturbation $\tilde{M}$ of $M$ with a *deterministic* proper mitigation policy $\pi^*: \St_M \rightarrow \A_M$ and a $\delta$-perturbation $\tilde{\pi}$ of $\pi$ s.t.

i. For all $s \in \St_M$, $\V_{M\pi^*}(s,\gamma) = \V_M(s,\gamma)$.

ii. $\tilde{\pi}$ is a mitigation policy for $\tilde{M}$.

iii. For any $s \in \St_M \setminus \SC_M$: $$\Supp{\tilde{\pi}(s)} \subseteq \A_{\tilde{M}^\flat\pi^*}^0(s)$$

iv. For any $s \in \St_M \setminus \SC_M$: $$\tilde{\pi}\AP{\pi^*(s) \mid s} > \epsilon$$

% Alternatively we could allow \pi^* to be stochastic...
% and require \tilde{\pi} to be of the form \epsilon \pi^* + (1 - \epsilon) \pi'

Given $\bar{\tau}_{1,2} \in (0,\infty)$, $\pi$ is said to *have moments $\bar{\tau}_{1,2}$* when $\pi^*$ has them as mitigation time moments.

***

Note that a locally $(\epsilon,\delta)$-sane policy still has to be $0$-optimal in $\SF_M$. This requirement seems reasonably realistic, since, roughly speaking, it only means that there is *some* way to "rearrange the universe" that the agent can achieve, and that would be "endorsed" by the advisor, s.t this rearrangement doesn't destroy substantially much value and s.t. after this rearrangement, there is no "impending catastrophe" that the agent has to prevent and the advisor wouldn't be able to prevent in its place. In particular, this rearrangement may involve creating some subagents inside the environment and *destroying the original agent*, in which case any policy on $\SF_M$ is "vacuously" optimal (since all actions have no effect).

We can now formulate the main result.

\#Theorem 1

Fix an interface $\In=(\A,\Ob)$, $N \in \Nats$, $\epsilon \in (0,1)$ and for each $k \in [N]$, an MDP $\MF_k$ s.t. $\A_{\MF_k} = \A$. Now, consider for each $k \in [N]$, an $\In$-universe $\upsilon^k=(\mu^k,r^k)$ which is an $\Ob$-realization of a catastrophe MDP $M^k$ with state function $S^k$ s.t.

i. $\SF_{M^k} = \St_{\MF_k}$

ii. For each $s \in \St_{\MF_k}$ and $a \in \A$, $\T_{M^k}(s,a) \mid \St_{\MF_k} = \T_{\MF_k}(s,a)$.

iii. For each $s \in \St_{\MF_k}$, $\R_{M^k}(s)=\R_{\MF_k}(s)$.

iv. Given $k,j \in [N]$ and $h \in \HD{\mu^k} \cap \HD{\mu^j}$, if $S^k(h) \in \St_{M^k} \setminus \SC_{M^k}$ and $S^j(h) \in \St_{M^j} \setminus \SC_{M^j}$, then $r^k(h)=r^j(h)$ (this condition means that in uncorrupted states, the reward is observable).

Consider also $\alpha,\delta\in(0,1)$, $\bar{\tau}_{1,2} \in (0,\infty)$ and $\sigma^k$ a locally $(\epsilon,\delta)$-sane policy for $(M^k,1-\alpha)$. Assume $\sigma^k$ has moments $\bar{\tau}_{1,2}$. Then, there exists an $\Adi$-policy $\pi^*$ s.t. for any $k \in [N]$

$$\EU_{\upsilon^k}^*(1-\alpha) - \EU_{\bar{\upsilon}^k\AB{\sigma^kS^k}}^{\pi^*}(1-\alpha) = O\AP{\max\AP{\frac{\delta}{\alpha},1}\cdot\AP{(\bar{\tau}_1 \alpha)^{1/4} + \bar{\tau}_2 \alpha}+\bar{\tau}_1\delta}$$

Here, $\sigma^k S^k$ is the $\In$-policy defined by $\sigma^k S^k(h):=\sigma^k\AP{S^k(h)}$. $\epsilon$ and the $\MF_k$ are regarded as *fixed* and we don't explicitly examine their effect on regret, whereas $\alpha$, $\delta$, $\bar{\tau}_{1,2}$ and the $M^k$ are regarded as variable with the asymptotics $\alpha,\delta \rightarrow 0$, $\bar{\tau}_{1,2} \rightarrow \infty$.

***

To clarify the behavior of the regret bound, we give a simple example.

\#Example 1

Let $\A = \{0,1,*\}$, $\Ob=\Bool$. For any $n \in \Nats$ and $k \in [N]$, we fix some $w_n^k \in \Bool^n$ and define the catastrophe MDP $M_n^k$ by

* $\SD_{M_n^k} = \Bool^{\leq n}$, $\SF_{M_n^k} = \{\bot,\top\}$, $\SC_{M_n^k} = \varnothing$ (adding corrupted states is an easy exercise).

* If $s \in \Bool^{< n}$ and $a \in \Bool$ then 

$$\T_{M_n^k}(sa \mid s,a) = 1 - \delta$$

$$\T_{M_n^k}(\bot \mid s,a) = \delta$$

$$\T_{M_n^k}(s \mid sa,*) = 1 - \delta$$

$$\T_{M_n^k}(\bot \mid sa,*) = \delta$$

* If $a \in {0,1}$ then

$$\T_{M_n^k}(\top \mid w_n^k,a) = 1$$

* If $s \in \Bool^n \setminus w_n^k$ and $a \in {0,1}$ then

$$\T_{M_n^k}(\bot \mid s,a) = 1$$

* If $s \in \{\bot,\top\}$ and $a \in \A$ then

$$\T_{M_n^k}(s \mid s,a) = 1$$

* $\R_{M_n^k}(\bot)=0$, if $s \in \St_{M_n^k} \setminus \bot$ then $\R_{M_n^k}(s)=1$.

* $S_n^k(\Estr_{\A \times \Ob})=\Estr_{\Bool}$ and $S_n^k(hao)=\bot$ iff $o = 0$ (this defines a unique $S_n^k$).

* If $s \in \Bool^{<n} \cup \{\bot,\top\}$ then $\sigma_n^k(a \mid s) = \frac{1}{3}$ for any $a \in \A$.

* $\sigma_n^k(0 \mid w_n^k) = \epsilon$, $\sigma_n^k(* \mid w_n^k) = 1 - \epsilon$.

* If $s \in \Bool^n \setminus w_n^k$ then $\sigma_n^k(0 \mid s) = \delta$, $\sigma_n^k(* \mid s) = 1 - \delta$.

We can take $\bar{\tau}_1 = n$, $\bar{\tau}_2 = n^2$. Fix $\lambda \in (0,1/3]$ and consider the asymptotic regime $n \rightarrow \infty$, $\alpha_n = \Theta\Big(n^{-7/3}\Big)$, $\delta_n = O\AP{n^{-2-\lambda}}$. According to Theorem 1, we get

$$\EU_{\upsilon_n^k}^*(1-\alpha_n) - \EU_{\bar{\upsilon}_n^k\AB{\sigma_n^k}}^{\pi_n^*}(1-\alpha_n) = \AP{\frac{n^{-2-\lambda}}{n^{-7/3}}\AP{\AP{n \cdot n^{-7/3}}^{1/4}+n^2 \cdot n^{-7/3}}+n \cdot n^{-2-\lambda}}$$

$$\EU_{\upsilon_n^k}^*(1-\alpha_n) - \EU_{\bar{\upsilon}_n^k\AB{\sigma_n^k}}^{\pi_n^*}(1-\alpha_n) = O\AP{n^{-\lambda}}=O\AP{\alpha_n^{3\lambda/7}}$$

The probability of a catastrophe (i.e. ending up in state $\bot$) for the optimal policy for a given $k$ is $O\AP{n\delta}=O\AP{n^{-1-\lambda}}$. Therefore, the probability of a catastrophe for policy $\pi_n^*$ is $O\AP{n^{-1-\lambda}+n^{-\lambda}}=O\AP{n^{-\lambda}}$. On the other hand, it is easy to see that for $\delta_n = \omega\AP{2^{-n}}$, the policy $\sigma_n^k$ has a probability of catastrophe $1-o(1)$ (and in particular  regret $\Omega(1)$): it spends $\Omega(2^n)$ time "exploring" $\Bool^{\leq n}$ with a probability $\delta$ of a catastrophe on every step.

Note that this example can be interpreted as a version of Christiano's [approval-directed agent](https://ai-alignment.com/model-free-decisions-6e6609f5d99e), if we regard the state $s \in \Bool^{i}$ as a "plan of action" that the advisor may either approve or not. But in this formalism, it is a special case of consequentialist reasoning.

***

Theorem 1 speaks of a finite set of environments, but as before (see Proposition 1 [here](https://agentfoundations.org/item?id=1550) and Corollary 3 [here](https://agentfoundations.org/item?id=1656)), there is a "structural" equivalent, n.e. we can use it to produce corollaries about Bayesian agents with priors over a countable set of environments. The difference is, in this case we consider asymptotic regimes in which the environment is also variable, so the probability weight of the environment in the prior will affect the regret bound. We leave out the details for now.

\section{Discussion}

TBD

\section{Appendix A}

We start by deriving a more general and more precise version of the non-catastrophic regret bound, in which the optimal policy is replaced by an arbitrary "reference policy" (later it will be related to the mitigation policy) and the dependence on the MDPs is expressed via a bound on their $\V^1$ and $\V^2$ functions.

\#Definition A.N1

Fix $\epsilon\in(0,1)$. Consider an MDP $M$ and policies $\pi: \St_M \rightarrow \A_M$, $\sigma: \St_M \M \A_M$. $\sigma$ is called *$\epsilon$-sane relatively to $\pi$* when for any $s \in \St_M$

i. $\Supp{\sigma(s)} \subseteq \A_{M\pi}^0$

ii. $\sigma\AP{\pi(s) \mid s} > \epsilon$

\#Lemma A.N1

Fix an interface $\In=(\A,\Ob)$, $N \in \Nats$ and $\epsilon \in (0,1)$. Now, consider for each $k \in [N]$, an $\In$-universe $\upsilon^k=(\mu^k,r)$ which is an $\Ob$-realization of an MDP $M_k$ with state function $S^k$ and policies $\pi^k,\sigma^k: \St_{M^k} \M \A$. Consider also $\alpha\in(0,1)$, $\bar{\tau}_{1,2} \in (0,\infty)$ and assume that 

i. $\sigma^k$ is $\epsilon$-sane relatively to $\pi^k$.

ii. For any $s \in \St_{M^k}$ and $\gamma\in(0,1)$ $$\Abs{\frac{\D\V_{M^k\pi^k}(s,\gamma)}{\D\gamma}} \leq \bar{\tau}_1$$

iii. For any $s \in \St_{M^k}$ and $\gamma\in(0,1)$ $$\Abs{\frac{\D^2\V_{M^k\pi^k}(s,\gamma)}{\D\gamma^2}} \leq \bar{\tau}_2$$

Then, there exists an $\Adi$-policy $\pi^*$ s.t. for any $k \in [N]$

$$\EU_{\upsilon^k}^{\pi^k S^k}(1-\alpha) - \EU_{\bar{\upsilon}^k\AB{\sigma^k S^k}}^{\pi^*}(1-\alpha) \leq O\AP{\bar{\tau}_2 \alpha + (\bar{\tau}_1 \alpha)^{1/4}}$$

The $O$-notation refers to the asymptotics where $\epsilon$ is *fixed* (so we don't explicitly examine its effect on regret) whereas $\alpha$, $\bar{\tau}_{1,2}$ and the $M_k$ are variable and $\alpha \rightarrow 0$, $\bar{\tau}_{1,2} \rightarrow \infty$.

***

The proof of Lemma A.N1 is almost identical to the proof the main theorem for ["non-catastrophic" DRL](https://agentfoundations.org/item?id=1656) up to minor modifications needed to pass from absolute to relative regret, and tracking the contribution of the derivatives of $\V_{M^k\pi^k}$. We give it in Appendix B.

We will not apply Lemma A.N1 directly the the universes of Theorem 1. Instead, we will define new universes using the following constructions.

\#Definition A.N2

Consider $M$ a catastrophe MDP. We define the catastrophe MDP $\MD$ as follows.

* $\SF_{\MD}:=\SF_M \sqcup \{\bot\}$, $\SD_{\MD}:=\SD_M$, $\SC_{\MD}:=\varnothing$.

* $\A_{\MD} = \A_M$

* For any $s,t \in \SD_M$:

$$\T_{\MD}(t \mid s) = \T_M(t \mid s)$$

$$\T_{\MD}(\bot \mid s) = \T_M(\SC_M \mid s)$$

$$\T_{\MD}(\bot \mid \bot) = 1$$

* For any $s \in \SD_M \cup \SF_M$, $t \in \SF_M$:

$$\T_{\MD}(t \mid s) = \T_M(t \mid s)$$

* For any $s \in \SF_M$:

$$\T_{\MD}(\bot \mid s) = \T_M(\SC_M \cup \SD_M \mid s)$$

* For any $s \in \SD_M$, $\R_{\MD}(s) = \frac{1}{2}\R_M(s)$.

* For any $s \in \SF_M$, $\R_{\MD}(s) = 1$.

* $\R_{\MD}(\bot) = 0$

Now, consider an interface $\In=(\A,\Ob)$ and a $\upsilon=(\mu,r)$ which is an $\Ob$-realization of a catastrophe MDP $M$ with state function $S$. Denote $\Ob':=\Ob\times\{\Re,\Im\}$, $\Ob^\star:=\Ob' \sqcup \{\bot\}$ and $\In^\star:=(\A,\Ob^\star)$. Denote $\beta: \Ob' \rightarrow \Ob$ the projection mapping and $\beta^*: \AP{\A \times \Ob'}^* \rightarrow \AP{\A \times \Ob}^*$ corresponding. We define the $\In^\star$-universe $\UD=(\mu^\RMD,r^\star)$ and the function $S^\star: \AP{\A \times \Ob^\star}^* \rightarrow \St_{\MD}$ as follows

$$\mu^\RMD(o\Re \mid ha) := \begin{cases} \mu\AP{o \mid \beta^*(h)a} \text{ if } h\in\AP{\A \times \Ob'}^* \text{ and } S\AP{\beta^*(h)},S\AP{\beta^*(h)ao}\in\SD_M \\ 0 \text{ otherwise} \end{cases}$$

$$\mu^\RMD(o\Im \mid ha) := \begin{cases} \mu\AP{o \mid \beta^*(h)a} \text{ if } h\in\AP{\A \times \Ob'}^* \text{ and } S\AP{\beta^*(h)ao}\in\SF_M \\ 0 \text{ otherwise} \end{cases}$$

$$\mu^\RMD(\bot \mid ha) := 1 - \sum_{o \in O} \AP{\mu^\RMD(o\Re \mid ha) + \mu^\RMD(o\Im \mid ha)}$$

$$r^\star(h):=\begin{cases} \frac{1}{2}r(\Estr) \text{ if } h = \Estr \\ \frac{1}{2}r\AP{\beta^*(h)} \text{ if } h\in\AP{\A \times \Ob'}^*,\ \Abs{h}>0 \text{ and } h_{:\Abs{h}-1}\in\A\Ob\Re \\ 1 \text{ if } h\in\AP{\A \times \Ob'}^*,\ \Abs{h}>0 \text{ and } h_{:\Abs{h}-1}\in\A\Ob\Im \\ 0 \text{ if } h\not\in\AP{\A \times \Ob'}^* \end{cases}$$

$$S^\star(h):=\begin{cases} S\AP{\beta^*(h)} \text{ if } h\in\AP{\A \times \Ob'}^* \\ \bot \text{ otherwise} \end{cases}$$

It is easy to see that $\UD$ is an $\Ob^\star$-realization of $\MD$ with state function $S^\star$.

\#Definition A.N3

Consider $M$ a catastrophe MDP. We define the catastrophe MDP $\ME$ as follows.

* $\SF_{\ME}:=\SF_M \sqcup \{\bot\}$, $\SD_{\ME}:=\SD_M$, $\SC_{\ME}:=\varnothing$.

* $\A_{\ME} = \A_M$

* $\T_{\ME} = \T_{\MD}$

* For any $s \in \SD_M \cup \SF_M$, $\R_{\ME}(s) = \frac{1}{2}\R_M(s)$.

* $\R_{\ME}(\bot) = 0$

Now, consider an interface $\In=(\A,\Ob)$ and a $\upsilon=(\mu,r)$ which is an $\Ob$-realization of a catastrophe MDP $M$ with state function $S$. We define the $\In^\star$-universe $\upsilon^\RME=(\mu^\RME,r^\star)$ as follows

$$\mu^\RME(o\Re \mid ha) := \begin{cases} \mu\AP{o \mid \beta^*(h)a} \text{ if } h\in\AP{\A \times \Ob'}^* \text{ and } S\AP{\beta^*(h)},S\AP{\beta^*(h)ao}\in\SD_M \\ \mu\AP{o \mid \beta^*(h)a} \text{ if } h\in\AP{\A \times \Ob'}^* \text{ and } S\AP{\beta^*(h)ao}\in\SF_M \\ 0 \text{ otherwise} \end{cases}$$

$$\mu^\RME(o\Im \mid ha) := 0$$

$$\mu^\RME(\bot \mid ha) := 1 - \sum_{o \in O} \mu^\RME(o\Re \mid ha)$$

It is easy to see that $\upsilon^\RME$ is an $\Ob^\star$-realization of $\ME$ with state function $S^\star$.

Given $h = a_0 o_0 a_1 o_1 \ldots a_{n-1} o_{n-1} \in \AP{\A \times \Ob}^n$, we will use the notation

$$\Re^*h := a_0 o_0 \Re a_1 o_1 \Re \ldots a_{n-1} o_{n-1} \Re \in \AP{\A \times \Ob'}^n$$ 

Given an $\In^\star$-policy $\pi$, the $\In$-policy $\pi\Re^*$ is defined by $\pi\Re^*(h) := \pi\AP{\Re^*h}$.

***

In order to utilize condition iii of Definition N6, we need to establish the following relation between $M^\flat$ and $\MD$, $\ME$.

\#Proposition A.N6

Consider $M$ a catastrophe MDP, some $s \in \St_M \setminus \SC_M$ and $\pi^*$ a proper mitigation policy. Then

$$\A_{M^\flat\pi^*}^0\AP{s} \cap \A_M^\sharp(s) \subseteq \A_{\MD\pi^*}^0\AP{s}$$

$$\A_{M^\flat\pi^*}^0\AP{s} \cap \A_M^\sharp(s) \subseteq \A_{\ME\pi^*}^0\AP{s}$$

***

For the purpose of the proof, the following notation will be convenient

\#Definition A.N6

Consider $\St$ a finite set and some $\T: \St \M \St$. We define $\T^\infty: \St \M \St$ by

$$\T^\infty := \lim_{n \rightarrow \infty} \frac{1}{n} \sum_{m = 0}^{n-1} \T^m$$

As well known, the limit above always exists.

\#Proof of Proposition A.N6

Consider any $s \in \St \setminus \SC_M$ and $a \in \A_{M^\flat\pi^*}^0\AP{s} \cap \A_M^\sharp(s)$. Since $a \in \A_{M^\flat\pi^*}^0\AP{s}$, we have

$$\Ea{\AP{\T_{M^\flat\pi^*}^\infty \circ \T_{M^\flat}}(s,a)}{\R_{M^\flat}} = \Ea{\T_{M^\flat}(s,a)}{\V^0_{M^\flat\pi^*}} = \Q_{M^\flat\pi^*}^0(s,a) \geq \V_{M^\flat\pi^*}^0(s) = \Ea{\T_{M^\flat\pi^*}^\infty(s)}{\R_{M^\flat}}$$

Let $N$ be either of $\MD$ and $\ME$. Since $a \in \A_M^\sharp(s)$, we get

$$\Ea{\AP{\T_{M^\flat\pi^*}^\infty \circ \T_{N}}(s,a)}{\R_{M^\flat}} \geq \Ea{\T_{M^\flat\pi^*}^\infty(s)}{\R_{M^\flat}}$$

Since $\pi^*$ is a mitigation policy, we get

$$\Ea{\AP{\T_{N\pi^*}^\infty \circ \T_{N}}(s,a)}{\R_{M^\flat}} \geq \Ea{\T_{N\pi^*}^\infty(s)}{\R_{M^\flat}}$$

Finally, since $\pi^*$ is proper, $\Supp{\T_{N\pi^*}^\infty(s)} \subseteq \SF_M$ and $\Supp{\AP{\T_{N\pi^*}^\infty \circ \T_{N}}(s,a)} \subseteq \SF_M$. We conclude

$$\Q_{N\pi^*}^0(s,a) = \Ea{\AP{\T_{N\pi^*}^\infty \circ \T_{N}}(s,a)}{\R_{N}} \geq \Ea{\T_{N\pi^*}^\infty(s)}{\R_{N}} = \V_{N\pi^*}^0(s)$$

***

Now we will establish a bound on $\V^1$ and $\V^2$ in terms of mitigation time moments, in order to demonstrate conditions ii and iii of Lemma A.N1.

\#Proposition A.N2

Fix $\bar{\tau}_1, \bar{\tau}_2, \TF_1, \TF_2 \in (0,\infty)$. Consider a catastrophe MDP $M$ and a proper mitigation policy $\pi: \St_M \M \A_M$ with mitigation time moments $\bar{\tau}_1, \bar{\tau}_2$. Assume than for any $s \in \SF_M$ and $\gamma\in(0,1)$

i. $$\Abs{\frac{\D\V_{M\pi}(s,\gamma)}{\D\gamma}} \leq \TF_1$$

ii. $$\Abs{\frac{\D^2\V_{M\pi}(s,\gamma)}{\D\gamma^2}} \leq \TF_2$$

Then, for any $s \in \St_M \setminus \SC_M$ and $\gamma\in[0,1]$

a. $$\Abs{\frac{\D\V_{M\pi}(s,\gamma)}{\D\gamma}} \leq 3 \bar{\tau}_1 + \TF_1$$

b. $$\Abs{\frac{\D^2\V_{M\pi}(s,\gamma)}{\D\gamma^2}} \leq 3 \bar{\tau}_2 + 2 \bar{\tau}_1 \TF_1 + \TF_2$$

***

Note that, since $\V_{M\pi}(s,\gamma)$ is a rational function of $\gamma$ with no poles on the interval $[0,1]$, some finite bounds of the form i and ii always exist. Note also that Proposition A.N2 is really about Markov chains rather than MDPs, but we don't make it explicit to avoid introducing more notation.

\#Proof of Proposition A.N2

Let $\mu_{M\pi s}\in\Delta\St_M^\omega$ be the Markov chain with transition matrix $\T_{M\pi}$ and initial state $s$. For any $\gamma\in(0,1$), we have

$$\V_{M\pi}(s,\gamma) = \Ea{x\sim\mu_{M\pi s}}{(1-\gamma)\sum_{n=0}^\infty \gamma^n \R_M\AP{x_n}}$$

Given $x\in\St_M^\omega$, we define $\tau(x) \in \Nats \sqcup \{\infty\}$ by 

$$\tau(x)=\min\{n \in \Nats \mid x_n \in \SF_M\}$$

It is easy to see that $\V_{M\pi}(s,\gamma)$ can be rewritten as

$$\V_{M\pi}(s,\gamma) = \Ea{x\sim\mu_{M\pi s}}{(1-\gamma)\AP{\sum_{n=0}^{\tau(x)-1} \gamma^n \R_M\Big(x_n\Big) + \frac{\gamma^{\tau(x)}}{1-\gamma}\V_{M\pi}\AP{x_{\tau(x)},\gamma}}}$$

The expression above is well defined because $\pi$ is a proper mitigation policy and therefore $\tau(x)$ is finite with probability 1.

$$\V_{M\pi}(s,\gamma) = \Ea{x\sim\mu_{M\pi s}}{(1-\gamma)\sum_{n=0}^{\tau(x)-1} \gamma^n \R_M\Big(x_n\Big) + \gamma^{\tau(x)}\V_{M\pi}\AP{x_{\tau(x)},\gamma}}$$

Let us decompose $\V_{M\pi}(s,\gamma)$ as $\V_{M\pi}^\RMD(s,\gamma)+\V_{M\pi}^\RMF(s,\gamma)$ defined as follows

$$\V_{M\pi}^\RMD(s,\gamma) := \Ea{x\sim\mu_{M\pi s}}{(1-\gamma)\sum_{n=0}^{\tau(x)-1} \gamma^n \R_M\Big(x_n\Big) }$$

$$\V_{M\pi}^\RMF(s,\gamma) := \Ea{x\sim\mu_{M\pi s}}{\gamma^{\tau(x)}\V_{M\pi}\AP{x_{\tau(x)},\gamma}}$$

We have

$$\frac{\D\V_{M\pi}^\RMD(s,\gamma)}{\D\gamma} = \Ea{x\sim\mu_{M\pi s}}{\sum_{n=0}^{\tau(x)-1} \AP{-\gamma^n+(1-\gamma)\cdot n\gamma^{n-1}} \R_M\Big(x_n\Big)}$$

$$\Abs{\frac{\D\V_{M\pi}^\RMD(s,\gamma)}{\D\gamma}} \leq \Ea{x\sim\mu_{M\pi s}}{\tau(x)+(1-\gamma)\sum_{n=0}^{\tau(x)-1} n\gamma^{n-1} \R_M\Big(x_n\Big) }$$

The second term can be regarded as a weighted average (since $1-\gamma=\sum_{n=0}^\infty \gamma^n$), where the maximal term in the average is at most $\tau(x)-1$, hence

$$\Abs{\frac{\D\V_{M\pi}^\RMD(s,\gamma)}{\D\gamma}} \leq 2 \bar{\tau}_1$$

Also, we have

$$\frac{\D\V_{M\pi}^\RMF(s,\gamma)}{\D\gamma} = \Ea{x\sim\mu_{M\pi s}}{\tau(x)\gamma^{\tau(x)-1}\V_{M\pi}\AP{x_{\tau(x)},\gamma}+\gamma^{\tau(x)}\frac{\D\V_{M\pi}\AP{x_{\tau(x)},\gamma}}{\D\gamma}}$$

$$\Abs{\frac{\D\V_{M\pi}^\RMF(s,\gamma)}{\D\gamma}} \leq \Ea{x\sim\mu_{M\pi s}}{ \tau(x)+\Abs{\frac{\D\V_{M\pi}\AP{x_{\tau(x)},\gamma}}{\D\gamma}}} = \bar{\tau}_1 + \Ea{x\sim\mu_{M\pi s}}{\Abs{\frac{\D\V_{M\pi}\AP{x_{\tau(x)},\gamma}}{\D\gamma}}} \leq \bar{\tau}_1 + \TF_1$$

$$\Abs{\frac{\D\V_{M\pi}(s,\gamma)}{\D\gamma}} \leq \Abs{\frac{\D\V_{M\pi}^\RMD(s,\gamma)}{\D\gamma}}+\Abs{\frac{\D\V_{M\pi}^\RMF(s,\gamma)}{\D\gamma}} \leq 3 \bar{\tau}_1 + \bar{\tau}_1^\RMF$$

\Comment{$$\Abs{\frac{\D\V_{M\pi}^\RMF(s,\gamma)}{\D\gamma}\bigg\vert_{\gamma=1}} \leq \bar{\tau}_1 + \Ea{x\sim\mu_{M\pi s}}{\Abs{\V_{M\pi}^1\AP{x_{\tau(x)}}}} \leq \bar{\tau}_1 + \bar{\tau}_1^\RMF$$

We conclude

$$\Abs{\V_{M\pi}^1(s)} \leq \Abs{\frac{\D\V_{M\pi}^\RMD(s,\gamma)}{\D\gamma}\bigg\vert_{\gamma=1}}+\Abs{\frac{\D\V_{M\pi}^\RMF(s,\gamma)}{\D\gamma}\bigg\vert_{\gamma=1}} \leq 3 \bar{\tau}_1 + \bar{\tau}_1^\RMF$$}

Now we analyze the second derivatives.

$$\frac{\D^2\V_{M\pi}^\RMD(s,\gamma)}{\D\gamma^2} = \Ea{x\sim\mu_{M\pi s}}{\sum_{n=0}^{\tau(x)-1} \AP{-2n\gamma^{n-1}+(1-\gamma)\cdot n(n-1)\gamma^{n-2}} \R_M\Big(x_n\Big)}$$

$$\Abs{\frac{\D^2\V_{M\pi}^\RMD(s,\gamma)}{\D\gamma^2}} \leq \Ea{x\sim\mu_{M\pi s}}{2\frac{\AP{\tau(x)-1}\tau(x)}{2} + \max\AP{\AP{\tau(x)-1}\AP{\tau(x)-2},0}} \leq 2\bar{\tau}_2$$

Denote $\V_{M\pi}'\AP{x_{\tau(x)},\gamma}:=\frac{\D\V_{M\pi}\AP{x_{\tau(x)},\gamma}}{\D\gamma}$, $\V_{M\pi}''\AP{x_{\tau(x)},\gamma}:=\frac{\D^2\V_{M\pi}\AP{x_{\tau(x)},\gamma}}{\D\gamma^2}$.

$$\frac{\D^2\V_{M\pi}^\RMF(s,\gamma)}{\D\gamma^2} = \Ea{x\sim\mu_{M\pi s}}{\tau(x)\AP{\tau(x)-1}\gamma^{\tau(x)-2}\V_{M\pi}\AP{x_{\tau(x)},\gamma}+2\tau(x)\gamma^{\tau(x)-1}\V_{M\pi}'\AP{x_{\tau(x)},\gamma}+\gamma^{\tau(x)}\V_{M\pi}''\AP{x_{\tau(x)},\gamma}}$$

$$\Abs{\frac{\D^2\V_{M\pi}^\RMF(s,\gamma)}{\D\gamma^2}} \leq \Ea{x\sim\mu_{M\pi s}}{\tau(x)\AP{\tau(x)-1}+2\tau(x)\Abs{\V_{M\pi}'\AP{x_{\tau(x)},\gamma}}+\Abs{\V_{M\pi}''\AP{x_{\tau(x)},\gamma}}}$$

$$\Abs{\frac{\D^2\V_{M\pi}^\RMF(s,\gamma)}{\D\gamma^2}} \leq \bar{\tau}_2 + 2 \bar{\tau}_1 \Ea{x\sim\mu_{M\pi s}}{\Abs{\V_{M\pi}'\AP{x_{\tau(x)},\gamma}}}+\Ea{x\sim\mu_{M\pi s}}{\Abs{\V_{M\pi}''\AP{x_{\tau(x)},\gamma}}} \leq \bar{\tau}_2 + 2\bar{\tau}_1\TF_1+\TF_2$$

$$\Abs{\frac{\D^2\V_{M\pi}(s,\gamma)}{\D\gamma^2}} \leq \Abs{\frac{\D^2\V_{M\pi}^\RMD(s,\gamma)}{\D\gamma^2}}+\Abs{\frac{\D^2\V_{M\pi}^\RMF(s,\gamma)}{\D\gamma^2}} \leq 3 \bar{\tau}_2 + 2 \bar{\tau}_1 \bar{\tau}_1^\RMF +\bar{\tau}_2^\RMF$$

\Comment{$$\Abs{\frac{\D^2\V_{M\pi}^\RMF(s,\gamma)}{\D\gamma^2}\bigg\vert_{\gamma=1}} \leq \bar{\tau}_2 + 2 \bar{\tau}_1 \Ea{x\sim\mu_{M\pi s}}{\Abs{\V_{M\pi}^1\AP{x_{\tau(x)}}}}+\Ea{x\sim\mu_{M\pi s}}{\Abs{\V_{M\pi}^2\AP{x_{\tau(x)}}}} \leq \bar{\tau}_2 + 2 \bar{\tau}_1 \bar{\tau}_1^\RMF +\bar{\tau}_2^\RMF$$

$$\Abs{\V_{M\pi}^2(s)} \leq \Abs{\frac{\D^2\V_{M\pi}^\RMD(s,\gamma)}{\D\gamma^2}\bigg\vert_{\gamma=1}}+\Abs{\frac{\D^2\V_{M\pi}^\RMF(s,\gamma)}{\D\gamma^2}\bigg\vert_{\gamma=1}} \leq 3 \bar{\tau}_2 + 2 \bar{\tau}_1 \bar{\tau}_1^\RMF +\bar{\tau}_2^\RMF$$}

***

To transform the relative regret bounds for "auxiliary" universes obtained from Lemma A.N1 to regret bounds for the original universes, we will need the following.

\#Definition A.N4

Consider $\delta\in(0,1)$, a universe $\upsilon=(\mu,r)$, a catastrophe MDP $M$ and some $S: \FH \rightarrow \St_M \sqcup \{\bot\}$. Let $\pi: \FH \M \A$ be any policy. A policy $\tilde{\pi}: \FH \M \A$ is said to be a *$\delta$-perturbation of $\pi$ over $S$* when

i. For any $h \in \HD{\mu}$ s.t. $S(h)\in\SF_M$, $\tilde{\pi}(h)=\pi(h)$.

ii. For any $h \in \HD{\mu}$ s.t. $S(h)\in\SD_M$, there exists $\alpha\in\Delta\A$ s.t $\pi(h)=(1-\delta)\tilde{\pi}(h)+\delta\alpha$.

\#Definition A.N5

Fix $\delta\in(0,1)$ and a universe $\upsilon=(\mu,r)$ which is an $\Ob$-realization of a catastrophe MDP $M$ with state function $S$. Let $\tilde{M}$ be a $\delta$-perturbation of $M$. Then, we define the environment $\mu^{\tilde{M}}$ by

$$\mu^{\tilde{M}}(o \mid ha) := \frac{\T_{\tilde{M}}\AP{S(hao) \mid S(h),a}}{\T_{M}\AP{S(hao) \mid S(h),a}}\mu(o \mid ha)$$

We also denote $\upsilon^{\tilde{M}}:=\AP{\mu^{\tilde{M}},r}$. It is easy to see that $\upsilon^{\tilde{M}}$ is an $\Ob$-realization of $\tilde{M}$ with state function $S$.

\#Proposition A.N5

Consider $\gamma,\delta\in(0,1)$ s.t $\delta \geq 1 - \gamma$ and $\bar{\tau}\in(0,\infty)$. Let $\upsilon=(\mu,r)$ be a universe which is an $\Ob$-realization of a catastrophe MDP $M$ with state function $S$. Suppose that $\pi^*$ is a mitigation policy for $M$ that has the 1st moment $\bar{\tau}$. Consider some $\In^\star$-policy $\pi$. Suppose that $\tilde{M}$ is a $\delta$-perturbation of $M$ and $\tilde{\pi}$ is a $\delta$-perturbation of $\pi$ over $S^\star$. Then, there is some $C\in(0,\infty)$ that depends on nothing s.t

$$\frac{1}{2}\AP{\EU_{\upsilon}^{\pi^* S}(\gamma)-\EU_{\upsilon}^{\pi\Re^*}(\gamma)} \leq \EU_{\upsilon^{\tilde{M}\RME}}^{\pi^* S^\star}(\gamma)-\EU_{\upsilon^{\tilde{M}\RME}}^{\tilde{\pi}}(\gamma) + C\delta\AP{\bar{\tau}+\frac{\max\AP{\EU_{\upsilon^{\tilde{M}\RMD}}^{\pi^* S^\star}(\gamma)-\EU_{\upsilon^{\tilde{M}\RMD}}^{\tilde{\pi}}(\gamma),0}}{1-\gamma}}$$

***

In order to prove Proposition A.N5, we need a relative regret bound for $M$ derived from a relative regret bound for $\ME$.

\#Proposition A.N4

Fix an interface $\In$ and an $\In$-universe $\upsilon=(\mu,r)$ which is an $\Ob$-realization of a catastrophe MDP $M$ with state function $S$ s.t. $S(\Estr)\not\in\SC_M$. Suppose that $\pi^*$ is a mitigation policy for $M$. Let $\pi$ be any $\In^\star$-policy. Then, for any $\gamma\in(0,1)$

$$\frac{1}{2}\AP{\EU_{\upsilon}^{\pi^* S}(\gamma)-\EU_{\upsilon}^{\pi\Re^*}(\gamma)} \leq \EU_{\upsilon^\RME}^{\pi^* S^\star}(\gamma)-\EU_{\upsilon^\RME}^{\pi}(\gamma)$$

\#Proof of Proposition A.N4

$\pi^*$ is a mitigation policy, therefore for any $s \in \St_M \setminus \SC_M$, $\T_{\ME\pi^*}(s)=\T_{M\pi^*}(s)$. It follows that 

$$\EU_{\upsilon^\RME}^{\pi^* S^\star}(\gamma) = \frac{1}{2}\EU_{\upsilon}^{\pi^* S}(\gamma)$$

Also, it is easy to see from the definition of $\T_{\ME}$ and $r^\star$ that

$$\EU_{\upsilon^\RME}^{\pi}(\gamma) \leq \frac{1}{2}\EU_{\upsilon}^{\pi\Re^*}(\gamma)$$

Indeed, any discrepancy between the behavior of $\ME$ and $M$ involves transition to the state $\bot$ which yields 0 reward forever. Subtracting these inequalities, we get the desired result.

***

Another observation we need to prove Proposition A.N5 is a bound on the effect of $\delta$-perturbations in terms of mitigation time.

\#Proposition A.N7

Consider $\gamma,\delta\in(0,1)$, a universe $\upsilon=(\mu,r)$ which is an $\Ob$-realization of a catastrophe MDP $M$ with state function $S$, and some $\pi: \FH \M \A$. Assume that 

i. $S(\Estr) \not\in \SC_M$

ii. For any $h \in S^{-1}\AP{\SD_M}$ and $a \in \Supp{\pi(h)}$, $\T_M\AP{\SC_M \mid s,a} = 0$.

iii. For any $h \in S^{-1}\AP{\SF_M}$ and $a \in \Supp{\pi(h)}$, $\T_M\AP{\SF_M \mid s,a} = 1$. 

Let $\tilde{M}$ be a $\delta$-perturbation of $M$ and $\tilde{\pi}$ be a $\delta$-perturbation of $\pi$ over $S$. Then,

$$\Dtva{\mu\bowtie\pi,\ \mu^{\tilde{M}}\bowtie\tilde{\pi}} \leq 2\AP{1-\Ea{x\sim\mu^{\tilde{M}}\bowtie\tilde{\pi}}{\AP{1-2\delta}^{\tau_S(x)}}}$$

\#Proof of Proposition A.N7

It is straightforward to construct a probability space $(\Omega,P)$, $X: \Omega \rightarrow (A \times \Ob)^\omega$ measurable and $\Sqn{C_n \subseteq \Omega}$ measurable s.t.

i. $h_*(P) = \mu\bowtie\pi$

ii. For any $n \in \Nats$ and $h \in (A \times \Ob)^n$ s.t. $S(h) \in \SD_M$: 

$$\Pa{}{C_n \mid X_{:n} = h} = 2\delta$$

iii. For any $n \in \Nats$ and $h \in (A \times \Ob)^n$ s.t. $S(h) \in \SF_M$: 

$$\Pa{}{C_n \mid X_{:n} = h} = 0$$

iv. For any $n \in \Nats$, $h \in (A \times \Ob)^n$ and $h' \in (A \times \Ob)^{n+1}$:

$$\Pa{}{X_{:n+1}=h' \mid X_{:n} = h \text{ and not } C_n} = \Pa{x \sim \mu^{\tilde{M}}\bowtie\tilde{\pi}}{x_{:n+1}=h' \mid x_{:n} = h}$$

Denote $D:=\cap_{n=0}^\infty \Omega \setminus C_n$. We have

$$P(D) = \Ea{x\sim\mu^{\tilde{M}}\bowtie\tilde{\pi}}{\AP{1-2\delta}^{\tau_S(x)}}$$

$$\Dtva{P,\ P \mid D} \leq 1 - P(D)$$

$$\Dtva{\mu\bowtie\pi,\ h_*\AP{P \mid D}} \leq 1 - P(D)$$

Also, it is easy to see that for any $A \subseteq (\A \times \Ob)^\omega$ measurable

$$h_*\AP{P \mid D}(A)=\frac{\Ea{x\sim\mu^{\tilde{M}}\bowtie\tilde{\pi}}{\AP{1-2\delta}^{\tau_S(x)}\chi_A}}{P(D)}$$

It follows that

$$\Dtva{h_*\AP{P \mid D},\mu^{\tilde{M}}\bowtie\tilde{\pi}} = \frac{1}{2}\Ea{x\sim\mu^{\tilde{M}}\bowtie\tilde{\pi}}{\Abs{\frac{\AP{1-2\delta}^{\tau_S(x)}}{P(D)}-1}}$$

$$\Dtva{h_*\AP{P \mid D},\mu^{\tilde{M}}\bowtie\tilde{\pi}} = \frac{1}{2P(D)}\Ea{x\sim\mu^{\tilde{M}}\bowtie\tilde{\pi}}{\Abs{\AP{1-2\delta}^{\tau_S(x)}-P(D)}}$$

Using the fact that $\AP{1-2\delta}^{\tau_S(x)}\in[0,1]$ and the convexity of the function $\Abs{t-P(D)}$

$$\Dtva{h_*\AP{P \mid D},\mu^{\tilde{M}}\bowtie\tilde{\pi}} \leq \frac{1}{2P(D)}\Ea{x\sim\mu^{\tilde{M}}\bowtie\tilde{\pi}}{\AP{1-2\delta}^{\tau_S(x)}\AP{1-P(D)}+\AP{1-\AP{1-2\delta}^{\tau_S(x)}}P(D)}$$

$$\Dtva{h_*\AP{P \mid D},\mu^{\tilde{M}}\bowtie\tilde{\pi}} \leq \frac{1}{2P(D)}\AP{P(D)\AP{1-P(D)} + \AP{1-P(D)}P(D)}=1-P(D)$$

Using the triangle inequality, we conclude

$$\Dtva{\mu\bowtie\pi,\ \mu^{\tilde{M}}\bowtie\tilde{\pi}}\leq\Dtva{\mu\bowtie\pi,\ h_*\AP{P \mid D}}+\Dtva{h_*\AP{P \mid D},\mu^{\tilde{M}}\bowtie\tilde{\pi}}=2\AP{1-\Ea{x\sim\mu^{\tilde{M}}\bowtie\tilde{\pi}}{\AP{1-2\delta}^{\tau_S(x)}}}$$

***

As a final ingredient towards the proof of Proposition A.N5, we will need to use the relative regret bound for $\MD$ to get a certain statistical bound on mitigation time.

\#Definition A.N7

Let $\mu$ be any environment. We define the closed set $\HD^\omega\mu \subseteq (\A \times \Ob)^\omega$ by

$$\HD^\omega\mu := \AC{x \in (\A \times \Ob)^\omega \mid \forall n \in \Nats: x_{:n} \in \HD{\mu}}$$

Consider a universe $\upsilon=(\mu,r)$ which is an $\Ob$-realization of a catastrophe MDP $M$ with state function $S$. We define the measurable function $\tau_S: \HD^\omega{\mu} \rightarrow \Nats \sqcup \{\infty\}$ as follows

$$\tau_S(x) := \min\AC{n \in \Nats \mid S\AP{x_{:n}} \in \SF_M}$$

\#Proposition A.N3

Fix an interface $\In$ and an $\In$-universe $\upsilon=(\mu,r)$ which is an $\Ob$-realization of a catastrophe MDP $M$ with state function $S$ s.t. $S(\Estr)\in\SD_M$. Suppose that $\pi^*$ is a mitigation policy for $M$ that has the 1st moment $\bar{\tau}\in(0,\infty)$. Let $\pi$ be any $\In^\star$-policy. Then, there is $C\in(0,\infty)$ that depends on nothing s.t. for any $\gamma,\delta\in(0,1)$, if $\delta \geq 1-\gamma$ then

$$\Ea{\mu^\RMD\bowtie\pi}{(1-\delta)^{\tau_{S^\star}}} \geq 1 - C\delta\AP{\bar{\tau}+\frac{\max\AP{\EU_{\upsilon^{\RMD}}^{\pi^* S^\star}(\gamma)-\EU_{\upsilon^{\RMD}}^{\pi}(\gamma),0}}{1-\gamma}}$$

\#Proof of Proposition A.N3

For any $x \in \HD{\mu^\RMD}$, we have

$$\Ut^{r^\star}_\gamma(x) \leq (1-\gamma)\AP{\frac{1}{2}\sum_{n=0}^{\tau_{S^\star}(x)-1}{\gamma^n} + \sum_{n=\tau_{S^\star}(x)}^\infty \gamma^n} = (1-\gamma)\AP{\frac{1}{2} \cdot \frac{1 - \gamma^{\tau_{S^\star}(x)}}{1-\gamma}+\frac{\gamma^{\tau_{S^\star}(x)}}{1-\gamma}}=\frac{1}{2}+\frac{1}{2}\gamma^{\tau_{S^\star}(x)}$$

It follows that

$$\EU_{\UD}^\pi(\gamma) \leq \frac{1}{2}+\frac{1}{2}\Ea{=\mu^\RMD\bowtie\pi}{\gamma^{\tau_{S^\star}}}$$

If $x \in \HD^\omega{\mu^\RMD}$ is s.t. for all $n\in\Nats$, $S^\star\AP{x_{:n}}\ne\bot$, then

$$\Ut^{r^\star}_\gamma(x) \geq (1-\gamma)\sum_{n=\tau_{S^\star}(x)}^\infty \gamma^n = \gamma^{\tau_{S^\star}(x)}$$

Since $\pi^*$ is a mitigation policy, it follows that

$$\EU_{\UD}^{\pi^*S^\star}(\gamma) \geq \Ea{\mu^\RMD\bowtie\pi^*S^\star}{\gamma^{\tau_{S^\star}}} \geq \gamma^{\bar{\tau}}$$

Subtracting the two inequalities, we get

$$\EU_{\UD}^{\pi^*S^\star}(\gamma) - \EU_{\UD}^\pi(\gamma) \geq \gamma^{\bar{\tau}} - \frac{1}{2} - \frac{1}{2}\Ea{\mu^\RMD\bowtie\pi}{\gamma^{\tau_{S^\star}}}$$

$$\Ea{\mu^\RMD\bowtie\pi}{\gamma^{\tau_{S^\star}}} \geq 2\gamma^{\bar{\tau}} - 2\AP{\EU_{\UD}^{\pi^*S^\star}(\gamma) - \EU_{\UD}^\pi(\gamma)}-1$$

Denote $\rho := \max\AP{\EU_{\UD}^{\pi^*S^\star}(\gamma) - \EU_{\UD}^\pi(\gamma),0}$.  By choosing $C$ sufficiently large, we can assume without loss of generality that the right hand side is positive since, unless $\gamma^{\bar{\tau}} \approx 1$, we would have $C\delta\bar{\tau} \geq C(1-\gamma)\bar{\tau} > 1$, and unless $\rho \ll 1$, we would have $C\delta\frac{\rho}{1-\gamma} \geq C\rho > 1$. In either case, the inequality we are trying to prove would hold. Also, note that $\frac{\ln{(1-\delta)}}{\ln{\gamma}} \geq 1$. We get

$$\Ea{\mu^\RMD\bowtie\pi}{(1-\delta)^{\tau_{S^\star}}}=\Ea{\mu^\RMD\bowtie\pi}{\gamma^{\tau_{S^\star}\frac{\ln{(1-\delta)}}{\ln{\gamma}}}} \geq \Ea{\mu^\RMD\bowtie\pi}{\gamma^{\tau_{S^\star}}}^{\frac{\ln{(1-\delta)}}{\ln{\gamma}}} \geq \AP{2\gamma^{\bar{\tau}}-2\rho-1}^{\frac{\ln{(1-\delta)}}{\ln{\gamma}}}=(1-\delta)^{\frac{\ln{\AP{2\gamma^{\bar{\tau}}-2\rho-1}}}{\ln{\gamma}}}$$

By the same reasoning as before, we can assume without loss of generality that e.g. $\gamma^{\bar{\tau}} \leq 1 - \frac{1}{2}(1-\gamma)\bar{\tau}$. It follows that

$$2\gamma^{\bar{\tau}}-2\rho-1 \leq 2 - (1 - \gamma)\bar{\tau} - 2\rho - 1 = 1 - (1 - \gamma)\bar{\tau} - 2\rho \leq 1 - (1-\gamma) = \gamma$$

$$\frac{\ln{\AP{2\gamma^{\bar{\tau}}-2\rho-1}}}{\ln{\gamma}} \geq 1$$

Combining this with the previous inequality implies

$$\Ea{\mu^\RMD\bowtie\pi}{(1-\delta)^{\tau_{S^\star}}} \geq 1 - \delta \frac{\ln{\AP{2\gamma^{\bar{\tau}}-2\rho-1}}}{\ln{\gamma}}$$

It is easy to see that there is $x_0 \in (0,1)$ s.t. for any $x \in [x_0,1]$, $2x -1 \geq x^3$ and therefore $\frac{2x-1}{x^3} \geq 1$. Therefore, for any such $x$ and $\rho \ll 1$, $e^{-C\rho}\leq\frac{2x - 1}{x^3} - \frac{2\rho}{x_0^3}\leq\frac{2x - 2\rho - 1}{x^3}$, where it is sufficient to assume that $C > \frac{2}{x_0^3}$. Taking $x=\gamma^{\bar{\tau}}$, we conclude (assuming $C \geq 3$ and observing that $\gamma^{\frac{1}{1-\gamma}}\leq e^{-1}$)

$$\gamma^{\frac{C\rho}{1-\gamma}} \leq e^{-C\rho}\leq\frac{2\gamma^{\bar{\tau}} - 2\rho - 1}{\gamma^{3\bar{\tau}}} \leq \frac{2\gamma^{\bar{\tau}} - 2\rho - 1}{\gamma^{C\bar{\tau}}}$$

$$\gamma^{C\AP{\bar{\tau}+\frac{\rho}{1-\gamma}}} \leq 2\gamma^{\bar{\tau}} - 2\rho - 1$$

Taking logarithm of both sides

$$C\AP{\bar{\tau}+\frac{\rho}{1-\gamma}} \ln{\gamma} \leq \ln{\AP{2\gamma^{\bar{\tau}} - 2\rho - 1}}$$

$$C\AP{\bar{\tau}+\frac{\rho}{1-\gamma}} \geq \frac{\ln{\AP{2\gamma^{\bar{\tau}} - 2\rho - 1}}}{ \ln{\gamma}}$$

Combining with the inequality we had before, we get

$$\Ea{\mu^\RMD\bowtie\pi}{(1-\delta)^{\tau_{S^\star}}} \geq 1 - C\delta\AP{\bar{\tau}+\frac{\rho}{1-\gamma}}$$

\#Proof of Proposition A.N5

By Proposition A.N4, we have

$$\frac{1}{2}\AP{\EU_{\upsilon}^{\pi^* S}(\gamma)-\EU_{\upsilon}^{\pi\Re^*}(\gamma)} \leq \EU_{\upsilon^\RME}^{\pi^* S^\star}(\gamma)-\EU_{\upsilon^\RME}^{\pi}(\gamma)$$

Note that $\tilde{M}^\RME$ is a $\delta$-perturbation of $M^\RME$ and $\upsilon^{\RME\tilde{M}^\RME}=\upsilon^{\tilde{M}\RME}$. Conditions i,ii,iii of Proposition A.N7 hold tautologically due to Definition A.N3. Therefore, we can apply Proposition A.N7 and get

$$\frac{1}{2}\AP{\EU_{\upsilon}^{\pi^* S}(\gamma)-\EU_{\upsilon}^{\pi\Re^*}(\gamma)} \leq \EU_{\upsilon^{\tilde{M}\RME}}^{\pi^* S^\star}(\gamma)-\EU_{\upsilon^{\tilde{M}\RME}}^{\tilde{\pi}}(\gamma) + 2\AP{2-\Ea{\mu^{\tilde{M}\RME}\bowtie\pi^*S^\star}{\AP{1-2\delta}^{\tau_{S^\star}}}-\Ea{\mu^{\tilde{M}\RME}\bowtie\tilde{\pi}}{\AP{1-2\delta}^{\tau_{S^\star}}}}$$

The only difference between $\mu^{\tilde{M}\RME}$ and $\mu^{\tilde{M}\RMD}$ is the appearance of $\Re$ instead of $\Im$. Therefore, we can rewrite the above as

$$\frac{1}{2}\AP{\EU_{\upsilon}^{\pi^* S}(\gamma)-\EU_{\upsilon}^{\pi\Re^*}(\gamma)} \leq \EU_{\upsilon^{\tilde{M}\RME}}^{\pi^* S^\star}(\gamma)-\EU_{\upsilon^{\tilde{M}\RME}}^{\tilde{\pi}}(\gamma) + 2\AP{2-\Ea{\mu^{\tilde{M}\RMD}\bowtie\pi^*S^\star}{\AP{1-2\delta}^{\tau_{S^\star}}}-\Ea{\mu^{\tilde{M}\RMD}\bowtie\tilde{\pi}}{\AP{1-2\delta}^{\tau_{S^\star}}}}$$


Applying Proposition A.N3 to each of the last two terms, we get

$$\frac{1}{2}\AP{\EU_{\upsilon}^{\pi^* S}(\gamma)-\EU_{\upsilon}^{\pi\Re^*}(\gamma)} \leq \EU_{\upsilon^{\tilde{M}\RME}}^{\pi^* S^\star}(\gamma)-\EU_{\upsilon^{\tilde{M}\RME}}^{\tilde{\pi}}(\gamma) + 4C\delta\AP{2\bar{\tau}+\frac{\max\AP{\EU_{\upsilon^{\tilde{M}\RMD}}^{\pi^* S^\star}(\gamma)-\EU_{\upsilon^{\tilde{M}\RMD}}^{\tilde{\pi}}(\gamma),0}}{1-\gamma}}$$

***

Finally, we are read to prove the main theorem.

\#Proof of Theorem 1

For every $k \in [N]$, denote $\tilde{M}^k$ and $\tilde{\sigma}^k$ the $\delta$-perturbations of $M^k$ and $\sigma^k$ respectively and $\pi^k$ the deterministic proper mitigation policy for $\tilde{M}^k$ of Definition N6. Denote $\tilde{\upsilon}^k:=\upsilon^{k\tilde{M}^k}$ and define $\Hy:=\{\tilde{\upsilon}^{k\RMD},\tilde{\upsilon}^{k\RME}\}_{k \in [N]}$. Observe that $\tilde{\sigma}^{k}$ is $\epsilon$-sane relatively to $\pi^k$ in the sense of $\tilde{M}^{k\RMD}$ and $\tilde{M}^{k\RME}$ both: condition i of Definition A.N1 follows by Proposition A.N6 from conditions ii and iii of Definition N6, and condition ii of Definition A.N1 follows from condition iv of Definition N6. Moreover, by Proposition A.N2, we have

$$\Abs{\frac{\D\V_{\tilde{M}^\RMD\pi^k}(s,\gamma)}{\D\gamma}} = O\AP{\bar{\tau}_1}$$

$$\Abs{\frac{\D^2\V_{\tilde{M}^\RMD\pi^k}(s,\gamma)}{\D\gamma^2}} = O\AP{\bar{\tau}_2}$$

$$\Abs{\frac{\D\V_{\tilde{M}^\RME\pi^k}(s,\gamma)}{\D\gamma}} = O\AP{\bar{\tau}_1}$$

$$\Abs{\frac{\D^2\V_{\tilde{M}^\RME\pi^k}(s,\gamma)}{\D\gamma^2}} = O\AP{\bar{\tau}_2}$$

Here, we used that $M^\RMF_k$ is fixed (and thus so are $\bar{\tau}_{1,2}^\RMF$, by conditions i-iii) and that $\bar{\tau}_1 = O\AP{\bar{\tau}_2^{1/2}}$.

Condition iv implies that all the universes in $\Hy$ have a common reward function (notice that transition to a corrupted state induces the observation $\bot$ whereas transition to a state in $\SF_M$ in the universe $\tilde{\upsilon}^{k\RMD}$ induces the observation $\Im$). Therefore, we can use Lemma A.N1 to conclude that there exists an $\overline{\In^\star}$-policy $\pi^\sharp$ s.t.

$$\EU_{\tilde{\upsilon}^{k\RMD}}^{\pi^kS^{k\star}}(1-\alpha) - \EU_{\overline{\tilde{\upsilon}^{k\RMD}}\AB{\tilde{\sigma}^k S^{k\star}}}^{\pi^\sharp}(1-\alpha) \leq O\AP{\bar{\tau}_2 \alpha + (\bar{\tau}_1 \alpha)^{1/4}}$$

$$\EU_{\tilde{\upsilon}^{k\RME}}^{\pi^kS^{k\star}}(1-\alpha) - \EU_{\overline{\tilde{\upsilon}^{k\RME}}\AB{\tilde{\sigma}^k S^{k\star}}}^{\pi^\sharp}(1-\alpha) \leq O\AP{\bar{\tau}_2 \alpha + (\bar{\tau}_1 \alpha)^{1/4}}$$

It is easy to see that $\AB{\tilde{\sigma}^k S^{k\star}}\underline{\pi}^\sharp$ is a $\delta$-perturbation of $\AB{\sigma^k S^{k\star}}\underline{\pi}^\sharp$ over $S^{k\star}$. Applying Proposition A.N5, we get

$$\frac{1}{3}\AP{\EU_{\upsilon^k}^{\pi^k S^{k}}(1-\alpha)-\EU_{\upsilon^k}^{\AB{\sigma^k S^{k\star}}\underline{\pi}^\sharp\Re^*}(1-\alpha)} \leq O\AP{\bar{\tau}_2 \alpha + (\bar{\tau}_1 \alpha)^{1/4} + \delta\AP{\bar{\tau}_1+\frac{\bar{\tau}_2 \alpha + (\bar{\tau}_1 \alpha)^{1/4}}{\alpha}}}$$

\Comment{Given $h = a_0 b_0 o_0 a_1 b_1 o_1 \ldots a_{n-1} b_{n-1} o_{n-1} \in \overline{\A \times \Ob}^n$, we use the notation 

$$\bar{\Re}^*h := a_0 b_0 o_0 \Re a_1 b_1 o_1 \Re \ldots a_{n-1} b_{n-1} o_{n-1} \Re \in \overline{\A \times \Ob'}^n$$

We define $\pi^*$ as by $\pi^*(h) := \pi^\star\AP{\bar{\Re}^*h}$.}

Define $\pi^*$ as follows. Given $h = a_0 b_0 o_0 a_1 b_1 o_1 \ldots a_{n-1} b_{n-1} o_{n-1} \in \overline{\A \times \Ob}^n$, we set

$$\pi^*(h) := \pi^\sharp\AP{a_0 b_0 o_0 \Re a_1 b_1 o_1 \Re \ldots a_{n-1} b_{n-1} o_{n-1} \Re}$$

Clearly $\AB{\sigma^k S^{k\star}}\underline{\pi}^\sharp\Re^* = \AB{\sigma^k S^{k}}\underline{\pi}^*$ and we get

$$\EU_{\upsilon^k}^{\pi^k S^{k}}(1-\alpha)-\EU_{\bar{\upsilon}^k\AB{\sigma^k S^{k}}}^{\pi^*}(1-\alpha) \leq O\AP{\max\AP{\frac{\delta}{\alpha},1}\cdot\AP{(\bar{\tau}_1 \alpha)^{1/4} + \bar{\tau}_2 \alpha}+\bar{\tau}_1\delta}$$

By condition i of Definition N6, this implies

$$\EU_{\upsilon^k}^{*}(1-\alpha)-\EU_{\bar{\upsilon}^k\AB{\sigma^k S^{k}}}^{\pi^*}(1-\alpha) = O\AP{\max\AP{\frac{\delta}{\alpha},1}\cdot\AP{(\bar{\tau}_1 \alpha)^{1/4} + \bar{\tau}_2 \alpha}+\bar{\tau}_1\delta}$$

\section{Appendix B}

Given $p=(a,o)\in\A\times\Ob$, we denote $p^\A:=a$, $p^\Ob:=o$.

\#Proposition B.N1

Consider a universe $\upsilon=(\mu,r)$ which an $\Ob$-realization of an MDP $M$ with state function $S$, a stationary policy $\pi^*: \St_M \M \A$, an arbitrary $\In$-policy $\pi^0$ and some $\gamma \in (0,1)$. Then,

$$\EU_{\upsilon}^{\pi^* S}(\gamma) - \EU_{\upsilon}^{\pi^0}(\gamma)=\sum_{n=0}^\infty {\gamma^n \Ea{x\sim\mu\bowtie\pi^0}{\V_{M\pi^*}\AP{S\AP{x_{:n}},\gamma}-\Q_{M\pi^*}\AP{S\AP{x_{:n}},x_n^\A,\gamma}}}$$

\#Proof of Proposition B.N1

For the sake of encumbering the notation less, we will omit the parameter $\gamma$ in functions that depend on it. We will use $S$ implicitly, i.e. given $F$ a function on $\St_M$ and $h \in \HD{\mu}$, $F(h):=F\AP{S(h)}$. Finally, we will omit $M\pi^*$, using the shorthand notations $\V:=\V_{M\pi^*}$, $\Q:=\Q_{M\pi^*}$.

For any $x \in \HD^\omega \mu$, it is easy to see that

$$\EU_{\upsilon}^{\pi^* S}=\V\AP{\Estr}=\sum_{n=0}^\infty \gamma^n \AP{\V\AP{x_{:n}}-\gamma\V\AP{x_{:n+1}}}$$

$$\Ut^{r}(x)=(1-\gamma)\sum_{n=0}^\infty \gamma^n r\AP{x_{:n}}$$

$$\EU_{\upsilon}^{\pi^* S} - \Ut^{r}(x)=\sum_{n=0}^\infty \gamma^n \AP{\V\AP{x_{:n}}-(1-\gamma)r\AP{x_{:n}}-\gamma\V\AP{x_{:n+1}}}$$

$$\EU_{\upsilon}^{\pi^* S} - \Ut^{r}(x)=\sum_{n=0}^\infty \gamma^n \AP{\V\AP{x_{:n}}-\Q\AP{x_{:n},x_n^\A}+\Q\AP{x_{:n},x_n^\A}-(1-\gamma)r\AP{x_{:n}}-\gamma\V\AP{x_{:n+1}}}$$

Taking expected value over $x$, we get

$$\EU_{\upsilon}^{\pi^* S} - \EU_{\upsilon}^{\pi^0}=\sum_{n=0}^\infty \gamma^n \AP{\Ea{\mu\bowtie\pi^0}{\V\AP{x_{:n}}-\Q\AP{x_{:n},x_n^\A}}+\Ea{\mu\bowtie\pi^0}{\Q\AP{x_{:n},x_n^\A}-(1-\gamma)r\AP{x_{:n}}-\gamma\V\AP{x_{:n+1}}}}$$

It is easy to see that the second term vanishes, yielding the desired result.

\#Proposition B.N3

Consider some $\tau\in(0,\infty)$, $T\in\Nats^+$, a universe $\upsilon=(\mu,r)$ that is an $\Ob$-realization of $M$ with state function $S$, a stationary policy $\pi^*: \St_M \M \A$ and an arbitrary $\In$-policy $\pi^0: \FH \M \A$. For any $n \in \Nats$, let $\pi^*_n$ be an $\In$-policy s.t. for any $h \in \HD{\mu}$

$$\pi^*_n(h):=\begin{cases} \pi^0(h) \text{ if } \Abs{h} < nT \\ \pi^*(h) \text{ otherwise} \end{cases}$$

Assume that

i. For any $h \in \HD{\mu}$ $$\Supp{\pi^0(h)} \subseteq \A_{M\pi^*}^0\AP{S(h)}$$

ii. For any $s \in \St_M$ and $\gamma\in(0,1)$ $$\Abs{\frac{\D\V_{M\pi}\AP{s,\gamma}}{\D\gamma}} \leq \tau$$

Then, for any $\gamma\in(0,1)$,

$$\EU^{\pi^*}_\upsilon(\gamma)-\EU^{\pi^0}_\upsilon(\gamma) \leq (1-\gamma)\sum_{n=0}^\infty \sum_{m=0}^{T-1} \gamma^{nT+m}\left(\E{x\sim\mu\bowtie\pi^*_n}\left[r\left(x_{:nT+m}\right)\right]-\E{x\sim\mu\bowtie\pi^0}\left[r\left(x_{:nT+m}\right)\right]\right) + O\left(\frac{1-\gamma}{1-\gamma^T}\right)???$$

\#Proof of Proposition B.N3

For the sake of encumbering the notation less, we will use $S$ implicitly, i.e. given $F$ a function on $\St_M$ and $h \in \HD{\mu}$, $F(h):=F\AP{S(h)}$. Also, we will omit $M\pi^*$, using the shorthand notations $\V:=\V_{M\pi^*}$, $\Q:=\Q_{M\pi^*}$.

By Proposition B.N1, for any $l \in \Nats$

$$\EU_{\upsilon}^{\pi^*}(\gamma) - \EU_{\upsilon}^{\pi_l^*}(\gamma) = \sum_{n=0}^\infty{\gamma^n \Ea{x\sim\mu\bowtie\pi_l^*}{\V\Big(x_{:n},\gamma\Big)-\Q\AP{x_{:n},x_n^\A,\gamma}}}$$

$\pi^*_l$ coincides with $\pi^*$ after $lT$, therefore the corresponding expected values vanish.

$$\EU_{\upsilon}^{\pi^*}(\gamma) - \EU_{\upsilon}^{\pi_l^*}(\gamma) = \sum_{n=0}^{lT-1}{\gamma^n \Ea{x\sim\mu\bowtie\pi^0}{\V\Big(x_{:n},\gamma\Big)-\Q\AP{x_{:n},x_n^\A,\gamma}}}$$

$$\EU_{\upsilon}^{\pi_{l}^*}(\gamma) - \EU_{\upsilon}^{\pi_{l+1}^*}(\gamma) = \sum_{n=lT}^{(l+1)T-1}{\gamma^n \Ea{x\sim\mu\bowtie\pi^0}{\V\Big(x_{:n},\gamma\Big)-\Q\AP{x_{:n},x_n^\A,\gamma}}}$$

$$(1-\gamma)\sum_{n=0}^\infty {\gamma^n\AP{\Ea{x \sim \mu\bowtie\pi^*_l}{r\AP{x_{:n}}}-\Ea{x \sim \mu\bowtie\pi^*_{l+1}}{r\AP{x_{:n}}}}} = \sum_{n=lT}^{(l+1)T-1}{\gamma^n \Ea{x\sim\mu\bowtie\pi^0}{\V\Big(x_{:n},\gamma\Big)-\Q\AP{x_{:n},x_n^\A,\gamma}}}$$

$\pi^*_l$ and $\pi^*_{l+1}$ coincide until $lT$, therefore

$$(1-\gamma)\sum_{n=lT}^\infty {\gamma^n\AP{\Ea{x \sim \mu\bowtie\pi^*_l}{r\AP{x_{:n}}}-\Ea{x \sim \mu\bowtie\pi^*_{l+1}}{r\AP{x_{:n}}}}} = \sum_{n=lT}^{(l+1)T-1}{\gamma^n \Ea{x\sim\mu\bowtie\pi^0}{\V\Big(x_{:n},\gamma\Big)-\Q\AP{x_{:n},x_n^\A,\gamma}}}$$

Denote $\rho^*_l:=\mu\bowtie\pi^*_l$, $\rho^0:=\mu\bowtie\pi^0$. We also use the shorthand notations $r_n:=r\AP{x_{:n}}$, $\V_n(\gamma):=\V\AP{x_{:n},\gamma}$, $\Q_n(\gamma):=\Q\AP{x_{:n},x_n^\A,\gamma}$. Both $\pi^*_l$ and $\pi^*_{l+1}$ coincide with $\pi^*$ after $(l+1)T$, therefore

$$(1-\gamma)\sum_{n=lT}^{(l+1)T-1} {\gamma^n\AP{\Ea{\rho^*_l}{r_n}-\Ea{\rho^0}{r_n}}} + \gamma^{(l+1)T}\AP{\Ea{\rho^*_l}{\V_{(l+1)T}(\gamma)}-\Ea{\rho^0}{\V_{(l+1)T}(\gamma)}}= \sum_{n=lT}^{(l+1)T-1}{\gamma^n \Ea{\rho^0}{\V_n(\gamma)-\Q_n(\gamma)}}$$

Denote $\V'(s,\gamma):=\frac{\D\V(s,\gamma)}{\D\gamma}$. By the mean value theorem, for each $s\in\St_M$ there is $\gamma^*\in(\gamma,1)$ s.t.

$$\V(s,\gamma) = \V^0(s) - \V'(s,\gamma^*)\cdot(1-\gamma)$$

???

Since $\pi^0$ is 0-optimal, we get

$$(1-\gamma)\sum_{n=lT}^{(l+1)T-1} {\gamma^n\AP{\Ea{\rho^*_l}{r_n}-\Ea{\rho^0}{r_n}}} + O\AP{\gamma^{(l+1)T}(1-\gamma)}= \sum_{n=lT}^{(l+1)T-1}{\gamma^n \Ea{\rho^0}{\V_n-\Q_n}}$$

Summing over $l$, we get

$$(1-\gamma)\sum_{l=0}^\infty\sum_{n=lT}^{(l+1)T-1} {\gamma^n\AP{\Ea{\rho^*_l}{r_n}-\Ea{\rho^0}{r_n}}} + O\AP{\frac{\gamma^T(1-\gamma)}{1-\gamma^{T}}}= \sum_{n=0}^{\infty}{\gamma^n \Ea{\rho^0}{\V_n-\Q_n}}$$

Applying Proposition B.1 to the right hand side

$$(1-\gamma)\sum_{l=0}^\infty\sum_{n=lT}^{(l+1)T-1} {\gamma^n\AP{\Ea{\rho^*_l}{r_n}-\Ea{\rho^0}{r_n}}} + O\AP{\frac{\gamma^T(1-\gamma)}{1-\gamma^{T}}}= \EU_{\upsilon}^{*}(\gamma) - \EU_{\upsilon}^{\pi^0}(\gamma)$$

\#Proof of Lemma A.N1

???

Fix $\gamma \in (0,1)$, $\delta\in\left(0,N^{-1}\right)$ and $T \in \Nats^+$. For each $k \in [N]$, suppose $\upsilon^k$ is an $\Ob$-realization of $M^k$ with state function $S^k$ and denote $\nu^k:=\bar{\mu}^k\left[\sigma^k\right]$. To avoid cumbersome notation, whenever $M^k$ should appear a subscript, we will replace it by $k$. Let $(\Omega,P \in \Delta\Omega)$ be a probability space\Comment{ and $\{\F_n \subseteq 2^\Omega\}_{n \in \Nats \sqcup \{-1\}}$ a filtration of $\Omega$}. Let $K: \Omega \rightarrow [N]$ be \Comment{measurable w.r.t. $\F_{-1}$}a random variable and the following be stochastic processes\Comment{ adapted to $\F$}

$$\Z_n,\tilde{\Z}_n: \Omega \rightarrow \Delta[N]$$

$$\J_n: \Omega \rightarrow [N]$$

$$\Psi_n: \Omega \rightarrow 2^\A$$

$$A_n: \Omega \rightarrow \Ada$$

$$\Theta_n: \Omega \rightarrow \Ado$$

We also define $A\Theta_{:n}: \Omega \rightarrow \Adfh$ by

$$A\Theta_{:n}:= A_0\Theta_0A_1\Theta_1 \ldots A_{n-1}\Theta_{n-1}$$

(The following conditions on $A$ and $\Theta$ imply that the range of the above is indeed in $\Adfh$.) Let $\D$ and $\D^{!k}$ be as in Proposition A.2 (we assume w.l.o.g. that $\epsilon < \frac{1}{\Abs{\A}}$). We construct $\Omega$\Comment{, $\F$}, $K$, $\Z$, $\tilde{\Z}$, $\J$, $\Psi$, $A$ and $\Theta$ s.t $K$ is uniformly distributed and for any $k \in [N]$, $l \in \Nats$, $m \in [T]$ and $o \in \Ob$, denoting $n = lT+m$

$$\tilde{\Z}_0(k)\equiv\frac{1}{N}$$

$$\Z_{n}(k) = \frac{\tilde{\Z}_{n}(k)[[\tilde{\Z}_{n}(k) \geq \delta]] }{\sum_{j = 0}^{N-1}\tilde{\Z}_{n}(j)[[\tilde{\Z}_{n}(j) \geq \delta]]}$$

$$\Pr\left[\J_{l} = k \mid Z_{lT}\right] = \Z_{lT}\left(k\right)$$

$$\Psi_{n} = \A^1_{\J_l}\left(S^{\J_l}(A\Theta_{:n})\right)$$

$$\Pr\left[\Theta_{n} = o \mid A\Theta_{:n}\right] = \nu^K\left(o \mid A\Theta_{:n}\right)$$

$$A_n = \D\left(A\Theta_{:n}, \Psi_n\right)$$

$$\tilde{\Z}_{n+1}(k)\sum_{j = 0}^{N-1} \Z_n(j) [[A_n = \D^{!j}\left(A\Theta_{:n}, \Psi_n\right)]] \nu^j(\Theta_n \mid A\Theta_{:n}A_n)=\Z_{n}(k) [[A_n = \D^{!k}\left(A\Theta_{:n}, \Psi_n\right)]] \nu^k\left(\Theta_{n} \mid A\Theta_{:n}A_{n}\right)$$

Note that the last equation has the form of a Bayesian update which is allowed to be arbitrary when update is on "impossible" information.

We now construct the $\Adi$-policy $\pi^*$ s.t. for any $n \in \Nats$, $h \in \Adfh$ s.t. $\Pr\left[A\Theta_{:n}=h\right] > 0$ and $a \in \Ada$

$$\pi^*(a \mid h):=\Pr\left[A_n = a \mid A\Theta_{:n} = h\right]$$

That is, we perform Thompson sampling at time intervals of size $T$, moderated by the delegation routine $\D$, and discard from our belief state hypotheses whose probability is below $\delta$ and hypotheses sampling which resulted in recommending "unsafe" actions i.e. actions that $\D$ refused to perform.

In order to prove $\pi^*$ has the desired property, we will define the stochastic processes $\Z^!$, $\tilde{\Z}^!$, $\J^!$, $\Psi^!$, $A^!$ and $\Theta^!$, each process of the same type as its shriekless counterpart (thus $\Omega$ is constructed to accommodate them). These processes are required to satisfy the following:

$$\tilde{\Z}^!_0(k)\equiv\frac{1}{N}$$

$$\Z_{n}^!(k) = \frac{\tilde{\Z}^!_{n}(k)[[\tilde{\Z}^!_{n}(k) \geq \delta]] }{\sum_{j = 0}^{N-1}\tilde{\Z}^!_{n}(j)[[\tilde{\Z}^!_{n}(j) \geq \delta]]}[[\tilde{\Z}^!_{n}(K) \geq \delta]] + [[K = k]]\cdot [[\tilde{\Z}^!_{n}(K) < \delta]]$$

$$\Pr\left[\J^!_{l} = k \mid Z^!_{lT}\right] = \Z^!_{lT}\left(k\right)$$

$$\Psi^!_{n} = \A^1_{\J^!_l}\left(S^{\J^!_l}(A\Theta^!_{:n})\right)$$

$$\Pr\left[\Theta^!_{n} = o \mid A\Theta^!_{:n}\right] = \nu^K\left(o \mid A\Theta^!_{:n}\right)$$

$$A^!_n = \D^{!K}\left(A\Theta^!_{:n}, \Psi^!_n\right)$$

$$\tilde{\Z}^!_{n+1}(k)=\frac{\Z^!_{n}(k) [[A^!_n = \D^{!k}\left(A\Theta^!_{:n}, \Psi^!_n\right)]] \nu^k\left(\Theta^!_{n} \mid A\Theta^!_{:n}A^!_{n}\right)}{\sum_{j = 0}^{N-1} \Z^!_n(j) [[A^!_n = \D^{!j}\left(A\Theta^!_{:n}, \Psi^!_n\right)]] \nu^j(\Theta^!_n \mid A\Theta^!_{:n}A^!_n)}$$

For any $k \in [N]$, we construct the $\Adi$-policy $\pi^{?k}$ s.t. for any $n \in \Nats$, $h \in \Adfh$ s.t. $\Pr\left[A\Theta^!_{:n}=h,\ K = k\right] > 0$ and $a \in \Ada$

$$\pi^{?k}(a \mid h):=\Pr\left[A^!_n = a \mid A\Theta^!_{:n} = h,\ K = k\right]$$

Given any $\Adi$-policy $\pi$ and $\In$-policy $\sigma$ we define $\alpha_{\sigma\pi}: \FH \M \Adfh$ by

$$\alpha_{\sigma\pi} (g \mid h) := [[h = \underline{g}]]C_h\prod_{n = 0}^{\Abs{h}-1} \sum_{a \in \A}\left([[g_n \in \bot a\Ob]] \pi\left(\bot \mid g_{:n}\right)\sigma\left(a \mid h_{:n}\right)+[[g_n \in a\bot\Ob]]\pi\left(a \mid g_{:n}\right)\right)$$

Here, $C_h \in \Reals$ is a constant defined s.t. the probabilities sum to 1. We define the $\In$-policy $\left[\sigma\right]\underline{\pi}$ by

$$\left[\sigma\right]\underline{\pi}(a \mid h):=\Pr_{g \sim \alpha_{\sigma\pi}(h)}\left[\pi\left(g\right)=a \lor \left(\pi\left(g\right)=\bot \land \sigma(h)=a\right)\right]$$

Condition iii of Proposition A.2 and condition i of $\epsilon$-sanity for $\sigma^k$ imply that for any $h \in \HD{\mu^k}$

$$\Supp{\left[\sigma^k\right]\underline{\pi}^{?k}(h)} \subseteq \A^0_k\left(S^k\left(h\right)\right)$$

This means we can apply Proposition A.5 and get

$$\EU^*_{\upsilon^k}(\gamma)-\EU^{\pi^{?k}}_{\bar{\upsilon}^k[\sigma^k]}(\gamma) \leq (1-\gamma)\sum_{n=0}^\infty \sum_{m=0}^{T-1} \gamma^{nT+m}\left(\E{x\sim\mu^k\bowtie\pi^{*k}_n}\left[r\left(x_{:nT+m}\right)\right]-\E{x\sim\nu^k\bowtie\pi^{?k}}\left[r\left(\underline{x}_{:nT+m}\right)\right]\right) + O\left(\frac{1-\gamma}{1-\gamma^T}\right)$$

Here, the $\In$-policy $\pi^{*k}_n$ is defined as $\pi^*_n$ in Proposition A.5. We also define the $\Adi$-policies $\pi^{!k}_n$ and $\pi^{!!k}_n$ by

$$\pi^{!k}_n(a \mid h):=\begin{cases} \pi^{?k}(a \mid h) \text{ if } \Abs{h} < nT \\ \Pr\left[A^!_{\Abs{h}} = a \mid A\Theta^!_{:{\Abs{h}}} = h,\ K = k,\ \J^!_n = k\right] \text{ otherwise} \end{cases}$$

$$\pi^{!!k}_n(a \mid h):=\begin{cases} \pi^{?k}(a \mid h) \text{ if } \Abs{h} < nT \\ \pi^{!k}_n(a \mid h) + \pi^{!k}_n(\bot \mid h) \cdot \pi^{*k}_n\left(a \mid \underline{h}\right) \text{ if } \Abs{h} \geq nT \text{ and } a \ne \bot \\ 0 \text{ if } \Abs{h} \geq nT \text{ and } a = \bot \end{cases}$$

Denote $\rho^{*k}_n:=\mu^k\bowtie\pi^{*k}_n$, $\rho^{!!k}_n:=\nu^k\bowtie\pi^{!!k}_n$, $\rho^{!k}_n:=\nu^k\bowtie\pi^{!k}_n$, $\rho^{?k}:=\nu^k\bowtie\pi^{?k}$, $R^{?k}=\EU^*_{\upsilon^k}(\gamma)-\EU^{\pi^{?k}}_{\bar{\upsilon}^k[\sigma^k]}(\gamma)$. For each $n \in \Nats$, denote

$$\EU_n^{*k}(\gamma):=\frac{1-\gamma}{1-\gamma^T}\sum_{m=0}^{T-1} \gamma^{m}\E{x\sim\rho^{*k}_n}\left[r\left(x_{:nT+m}\right)\right]$$

$$\EU_n^{!!k}(\gamma):=\frac{1-\gamma}{1-\gamma^T}\sum_{m=0}^{T-1} \gamma^{m}\E{x\sim\rho^{!!k}_n}\left[r\left(\underline{x}_{:nT+m}\right)\right]$$

$$\EU_n^{!k}(\gamma):=\frac{1-\gamma}{1-\gamma^T}\sum_{m=0}^{T-1} \gamma^{m}\E{x\sim\rho^{!k}_n}\left[r\left(\underline{x}_{:nT+m}\right)\right]$$

$$\EU_n^{?k}(\gamma):=\frac{1-\gamma}{1-\gamma^T}\sum_{m=0}^{T-1} \gamma^{m}\E{x\sim\rho^{?k}}\left[r\left(\underline{x}_{:nT+m}\right)\right]$$

We have

$$R^{?k} \leq (1-\gamma^T)\sum_{n=0}^\infty \gamma^{nT} \left(\EU^{*k}_n(\gamma)-\EU^{?k}_n(\gamma)\right) + O\left(\frac{1-\gamma}{1-\gamma^T}\right)$$

$$R^{?k} \leq (1-\gamma^T)\sum_{n=0}^\infty \gamma^{nT} \left(\EU^{*k}_n(\gamma)-\EU^{!!k}_n(\gamma)+\EU^{!!k}_n(\gamma)-\EU^{!k}_n(\gamma)+\EU^{!k}_n(\gamma)-\EU^{?k}_n(\gamma)\right) + O\left(\frac{1-\gamma}{1-\gamma^T}\right)$$

Condition iv of Proposition A.2 and condition ii of $\epsilon$-sanity for $\sigma^k$ imply that, given $h \in \HD{\nu^k}$ s.t. $\Abs{h} \geq nT$

$$\Supp{\pi^{!k}_n(h)} \subseteq \A^1_k\left(S^k\left(\underline{h}\right)\right) \cup \{\bot\}$$

$$\Supp{\pi^{!!k}_n(h)} \subseteq \A^1_k\left(S^k\left(\underline{h}\right)\right)$$

Therefore, we can apply Proposition A.4 to the terms $\EU^{*k}_n(\gamma)-\EU^{!!k}_n(\gamma)$ and get

$$R^{?k} \leq (1-\gamma^T)\sum_{n=0}^\infty \gamma^{nT} \left(\EU^{!!k}_n(\gamma)-\EU^{!k}_n(\gamma)+\EU^{!k}_n(\gamma)-\EU^{?k}_n(\gamma)\right) + O\left(\frac{1-\gamma}{1-\gamma^T}+T\frac{(1-\gamma)^2}{1-\gamma^T}\right)$$

We have

$$\EU^{!!k}_n(\gamma)-\EU^{!k}_n(\gamma) \leq \Pr_{x\sim\rho^{!k}_n}\left[\exists m \in [T]: x_{nT+m} \in \bot\Ado\right]$$

Thus, using condition i of Proposition A.2, we can bound the contribution of the $\EU^{!!k}_n(\gamma)-\EU^{!k}_n(\gamma)$ terms and get

$$R^{?k} \leq (1-\gamma^T)\sum_{n=0}^\infty \gamma^{nT} \left(\EU^{!k}_n(\gamma)-\EU^{?k}_n(\gamma)\right) + O\left(\frac{1-\gamma^T}{\delta}+\frac{1-\gamma}{1-\gamma^T}+T\frac{(1-\gamma)^2}{1-\gamma^T}\right)$$

We denote

$$\xi(\gamma,T,\delta):=\frac{1-\gamma^T}{\delta}+\frac{1-\gamma}{1-\gamma^T}+T\frac{(1-\gamma)^2}{1-\gamma^T}$$

Define the random variables $\Sqn{U^!_n : \Omega \rightarrow [0,1]}$ by 

$$U^!_n:=\frac{1-\gamma}{1-\gamma^T}\sum_{m=0}^{T-1} \gamma^{m} r\left(A\Theta^!_{:nT+m}\right)$$

Averaging the previous inequality over $k$, we get

$$\frac{1}{N}\sum_{k=0}^{N-1}R^{?k} \leq (1-\gamma^T)\sum_{n=0}^\infty \gamma^{nT} \left(\E{}\left[U^!_n \mid \J^!_n = K\right]-\E{}\left[U^!_n\right]\right) + O\left(\xi(\gamma,T,\delta)\right)$$

$$\frac{1}{N}\sum_{k=0}^{N-1}R^{?k} \leq (1-\gamma^T)\sum_{n=0}^\infty \gamma^{nT} \E{}\left[\E{}\left[U^!_n \mid \J^!_n = K,\ Z^!_{nT}\right]-\E{}\left[U^!_n \mid Z^!_{nT}\right]\right] + O\left(\xi(\gamma,T,\delta)\right)$$

$$\frac{1}{N}\sum_{k=0}^{N-1}R^{?k} = \sqrt{(1-\gamma^T)\sum_{n=0}^\infty \gamma^{nT} \E{}\left[\left(\E{}\left[U^!_n \mid \J^!_n = K,\ Z^!_{nT}\right]-\E{}\left[U^!_n \mid Z^!_{nT}\right]\right)^2\right]} + O\left(\xi(\gamma,T,\delta)\right)$$

We apply Proposition A.1 to each term in the sum over $n$.

$$\frac{1}{N}\sum_{k=0}^{N-1}R^{?k} = \sqrt{(1-\gamma^T)\sum_{n=0}^\infty \gamma^{nT} \E{}\left[\frac{1}{2\delta}\I{}\left[K;\J^!_n,U^!_n \mid Z^!_{nT}\right]\right]} + O\left(\xi(\gamma,T,\delta)\right)$$

$$\frac{1}{N}\sum_{k=0}^{N-1}R^{?k} = \sqrt{\frac{1-\gamma^T}{2\delta}\sum_{n=0}^\infty \gamma^{nT} \E{}\left[\En\Big(Z^!_{nT}\Big)-\En\left(Z^!_{(n+1)T}\right)\right]} + O\left(\xi(\gamma,T,\delta)\right)$$

$$\frac{1}{N}\sum_{k=0}^{N-1}R^{?k} = \sqrt{\frac{1-\gamma^T}{2\delta}\ln N} + O\left(\frac{1-\gamma^T}{\delta}+\frac{1-\gamma}{1-\gamma^T}+T\frac{(1-\gamma)^2}{1-\gamma^T}\right)$$

$$\frac{1}{N}\sum_{k=0}^{N-1}R^{?k} = O\left(\sqrt{\frac{1-\gamma^T}{\delta}} +\frac{1-\gamma}{1-\gamma^T}+T\frac{(1-\gamma)^2}{1-\gamma^T}\right)$$

Condition ii of Proposition A.2 implies that

$$\Dtv\left(\frac{1}{N}\sum_{k=0}^{N-1}{\bar{\nu}^k\left[\sigma^k\right]\bowtie\pi^*},\ \frac{1}{N}\sum_{k=0}^{N-1}{\bar{\nu}^k\left[\sigma^k\right]\bowtie\pi^{?k}}\right) \leq 2(N-1)\delta$$

Here, the factor of 2 comes from the difference between the equations for $Z_n$ and $Z^!_n$ (we can construct and intermediate policy between $\pi^*$ and $\pi^{?k}$ and use the triangle inequality for $\Dtv$). We conclude

$$\EU^*_{\upsilon^k}(\gamma)-\EU^{\pi^{*}}_{\bar{\upsilon}^k[\sigma^k]}(\gamma) = O\left(\delta+\sqrt{\frac{1-\gamma^T}{\delta}} +\frac{1-\gamma}{1-\gamma^T}+T\frac{(1-\gamma)^2}{1-\gamma^T}\right)$$

Now we set $\delta:=\left(1-\gamma\right)^{1/4}$,  $T:=\Floor{\left(1-\gamma\right)^{-1/4}}$. Since $\gamma^T \rightarrow 1$ as $\gamma \rightarrow 1$, we can use the approximation $1-\gamma^T \approx T(1-\gamma) \approx (1-\gamma)^{3/4}$. We get

$$\EU^*_{\upsilon^k}(\gamma)-\EU^{\pi^{*}}_{\bar{\upsilon}^k[\sigma^k]}(\gamma) = O\left((1-\gamma)^{1/4}\right)$$

\section{Appendix C}

TBD

\#Proposition C.N1

Consider a probability space $(\Omega, P \in \Delta\Omega)$, $N \in \Nats$, $R \subseteq [0,1]$ a finite set and random variables $U: \Omega \rightarrow R$, $K: \Omega \rightarrow [N]$ and $\J: \Omega \rightarrow [N]$. Assume that $K_*P = J_*P = \zeta \in \Delta[N]$ and $\I{}[K;J] = 0$. Then

$$\I{}\left[K;J,U\right] \geq 2 \left(\min_{i \in [N]} {\zeta(i)}\right) \left(\E{}\left[U \mid J = K\right]-\E{}\left[U\right]\right)^2$$

\#Proposition C.N2

Fix an interface $\In=(\A,\Ob)$, $N \in \Nats$, $\epsilon \in (0,\frac{1}{\Abs{\A}})$, $\delta \in (0,\frac{1}{N})$. Consider some $\{\sigma^k: \FH \M \A\}_{k \in [N]}$. Then, there exist $\D: \Adfh \times 2^\A \rightarrow \Ada$ and $\{\D^{!k}: \Adfh \times 2^\A \rightarrow \Ada\}_{k \in [N]}$ with the following properties. Given $x \in \left(2^\A \times \Adao\right)^*$, we denote $\underline{x}$ its projection to $\Adfh$. Thus, $\underline{\underline{x}}\in\FH$.
Given  $\mu$ an $\In$-environment, $\pi: \HD{\mu} \M 2^\A$, $\D': \Adfh \times 2^\A \rightarrow \Ada$ and $k \in [N]$, we can define $\Xi\left[\mu,\sigma^k,\D',\pi\right]\in \Delta\left(2^\A \times \Adao\right)^\omega$ as follows
 
$$\Xi\left[\mu,\sigma^k,\D',\pi\right]\left(\B,a,o \mid x\right):=\pi\left(\B \mid \underline{\underline{x}}\right)\D'\left(a \mid \underline{x},\B\right) \bar{\mu}[\sigma^k]\left(o \mid \underline{x}a\right)$$

We require that for every $\pi$, $\mu$ and $k$ as above, the following conditions hold

i. $$\E{x \sim\Xi\left[\mu,\sigma^k,\D^{!k},\pi\right]}\left[\Abs{\{n \in \Nats \mid x_n \in 2^\A \times \bot \times \bar{\Ob}\}}\right] \leq \frac{\ln N}{\delta \ln\left(1 + \epsilon(1-\epsilon)^{(1-\epsilon)/\epsilon}\right)}=O\left(\frac{\ln N}{\delta \epsilon}\right)$$

ii. $\Dtv\left(\frac{1}{N}\sum_{j=0}^{N-1}{\Xi\left[\mu,\sigma^j,\D,\pi\right]},\frac{1}{N}\sum_{j=0}^{N-1}{\Xi\left[\mu,\sigma^j,\D^{!j},\pi\right]}\right) \leq (N-1)\delta$

iii. For all $x \in \HD{\bar{\mu}[\sigma^k]}$, if $\D^{!k}\left(x,\pi\left(\underline{x}\right)\right) \ne \bot$ then $\sigma^k\left(\D^{!k}\left(x,\pi\left(\underline{x}\right)\right) \mid \underline{x}\right) > 0$

iv. For all $x \in \HD{\bar{\mu}[\sigma^k]}$, if $\D^{!k}\left(x,\pi\left(\underline{x}\right)\right) \not\in \pi\left(\underline{x}\right) \cup \{\bot\}$ then $\forall a \in \pi\left(\underline{x}\right): \sigma^k\left(a \mid \underline{x}\right) \leq \epsilon$

\end{document}



