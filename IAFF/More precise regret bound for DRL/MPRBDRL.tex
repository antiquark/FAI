%&latex
\documentclass[a4paper]{article}

\usepackage[a4paper,margin=1in]{geometry}
\usepackage[affil-it]{authblk}
\usepackage{cite}
\usepackage[unicode]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{commath}

\newcommand{\Comment}[1]{}

\newcommand{\Bool}{\{0,1\}}
\newcommand{\Words}{{\Bool^*}}

% operators that are separated from the operand by a space
\DeclareMathOperator{\Sgn}{sgn}
\DeclareMathOperator{\Supp}{supp}
\DeclareMathOperator{\Stab}{stab}
\DeclareMathOperator{\Img}{Im}
\DeclareMathOperator{\Dom}{dom}

% autosize deliminaters
\newcommand{\AP}[1]{\left(#1\right)}
\newcommand{\AB}[1]{\left[#1\right]}
\newcommand{\AC}[1]{\left\{#1\right\}}

% operators that require brackets
\newcommand{\Pa}[2]{\underset{#1}{\operatorname{Pr}}\AB{#2}}
\newcommand{\PP}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{Pr}}}
\newcommand{\PPP}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{Pr}}}
\newcommand{\E}[1]{\underset{#1}{\operatorname{E}}}
\newcommand{\Ea}[2]{\underset{#1}{\operatorname{E}}\AB{#2}}
\newcommand{\EE}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{E}}}
\newcommand{\EEE}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{E}}}
\newcommand{\I}[1]{\underset{#1}{\operatorname{I}}}
\newcommand{\Ia}[2]{\underset{#1}{\operatorname{I}}\AB{#2}}
\newcommand{\II}[2]{\underset{\substack{#1 \\ #2}}{\operatorname{I}}}
\newcommand{\III}[3]{\underset{\substack{#1 \\ #2 \\ #3}}{\operatorname{I}}}
\newcommand{\Var}{\operatorname{Var}}

% operators that require parentheses
\newcommand{\En}{\operatorname{H}}
\newcommand{\Ena}[1]{\operatorname{H}\AP{#1}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\End}{\operatorname{End}}
\newcommand{\Sym}{\operatorname{Sym}}

\newcommand{\Prj}{\operatorname{pr}}

\newcommand{\D}{\mathrm{d}}
\newcommand{\KL}[2]{\operatorname{D}_{\mathrm{KL}}(#1 \| #2)}
\newcommand{\Dtv}{\operatorname{d}_{\text{tv}}}
\newcommand{\Dtva}[1]{\operatorname{d}_{\text{tv}}\AP{#1}}

\newcommand{\Argmin}[1]{\underset{#1}{\operatorname{arg\,min}}\,}
\newcommand{\Argmax}[1]{\underset{#1}{\operatorname{arg\,max}}\,}

\newcommand{\Nats}{\mathbb{N}}
\newcommand{\Ints}{\mathbb{Z}}
\newcommand{\Rats}{\mathbb{Q}}
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\Coms}{\mathbb{C}}

\newcommand{\Sq}[2]{\{#1\}_{#2 \in \Nats}}
\newcommand{\Sqn}[1]{\Sq{#1}{n}}

\newcommand{\Estr}{\boldsymbol{\lambda}}

\newcommand{\Lim}[1]{\lim_{#1 \rightarrow \infty}}
\newcommand{\LimInf}[1]{\liminf_{#1 \rightarrow \infty}}
\newcommand{\LimSup}[1]{\limsup_{#1 \rightarrow \infty}}

\newcommand{\Abs}[1]{\left\vert #1 \right\vert}
\newcommand{\Norm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\Floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\Ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\Chev}[1]{\left\langle #1 \right\rangle}
\newcommand{\Quote}[1]{\left\ulcorner #1 \right\urcorner}

\newcommand{\Alg}{\xrightarrow{\text{alg}}}
\newcommand{\M}{\xrightarrow{\text{k}}}
\newcommand{\PF}{\xrightarrow{\circ}}

% Paper specific

\newcommand{\Ob}{\mathcal{O}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\St}{\mathcal{S}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\In}{\mathcal{I}}
\newcommand{\FH}{(\A \times \Ob)^*}
\newcommand{\IH}{(\A \times \Ob)^\omega}
\newcommand{\Ado}{\bar{\Ob}}
\newcommand{\Ada}{\bar{\A}}
\newcommand{\Adi}{{\bar{\In}}}
\newcommand{\Adao}{\overline{\A \times \Ob}}
\newcommand{\Adfh}{\Adao^*}
\newcommand{\Adih}{\Adao^\omega}
\DeclareMathOperator{\HD}{hdom}
\newcommand{\Hy}{\mathcal{H}}
\newcommand{\UC}{\mathcal{U}}

\newcommand{\RMC}{\mathrm{C}}
\newcommand{\RMD}{\mathrm{D}}
\newcommand{\RME}{\mathrm{E}}
\newcommand{\RMF}{\mathrm{F}}

\newcommand{\SF}{\St^{\RMF}}
\newcommand{\SD}{\St^{\RMD}}
\newcommand{\SC}{\St^{\RMC}}
\newcommand{\MF}{M^{\RMF}}
\newcommand{\MD}{M^{\RMD}}
\newcommand{\ME}{M^{\RME}}
\newcommand{\TF}{\bar{\tau}^{\RMF}}
\newcommand{\PD}{\pi^{\RMD}}
\newcommand{\UD}{\upsilon^{\RMD}}

\newcommand{\Ut}{\operatorname{U}}
\newcommand{\V}{\operatorname{V}}
\newcommand{\Q}{\operatorname{Q}}
\newcommand{\EU}{\operatorname{EU}}

\newcommand{\Dl}{\mathcal{D}}
\newcommand{\Do}{\mathfrak{D}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\Z}{Z}
\newcommand{\J}{J}

\newcommand{\Pd}{P}

\begin{document}

We derive a regret bound for [DRL](https://agentfoundations.org/item?id=1656) reflecting dependence on:

* Number of hypotheses

* Mixing time of MDP hypotheses

* The probability with which the advisor takes optimal actions

That is, the regret bound we get is fully explicit up to a multiplicative constant (which can also be made explicit). Currently we focus on plain (as opposed to [catastrophe](https://agentfoundations.org/item?id=1715)) and uniform (finite number of hypotheses, uniform prior) DRL, although this result can and should be extended to the catastrophe and/or non-uniform settings.

***

Appendix A contains the proofs...

\section{Notation}

Whatever...

\section{Results}

First, we briefly recall some properties of Markov chains.

\#Definition 1

Consider $\St$ a finite set and $\T: \St \M \St$. We say that $k \in \Nats^+$ is a *period of $\T$* when there is $s \in \St$ an essential state of $\T$ (that is, $\T^\infty(s \mid s) > 0$) s.t. $k$ is its period, i.e. $k = \gcd \AC{n \in \Nats^+ \mid \T^n(s \mid s) > 0}$. We denote $\Pd_\T$ the set of periods of $\T$.

***

The following is a corollary of the Perron-Frobenius theorem which we give without proof. *[I believe this is completely standard and would be grateful to get a source for this which treats the reducible case; of course I can produce the proof but it seems redundant.]*

\#Proposition 1

Consider $\St$ a finite set and $\T: \St \M \St$. Then, there are $F_\T \in (0,\infty)$, $\lambda_\T\in(0,1)$, $\zeta: \St \M \Pd_\T$ and $\xi: \St \times \Pd_\T \M \St$ s.t. for any $s \in \St_M$

$$\forall k \in \Pd_T: \T^k \xi(s,k) = \xi(s,k)$$

$$\forall n \in \Nats: \Dtva{\T^n(s),\Ea{k \sim \zeta(s)}{\T^n \xi(s,k)}} \leq F_\T \lambda_{\T}^{-n}$$

***

For the purpose of this essay, we will use a definition of local sanity slightly stronger than what [previously](https://agentfoundations.org/item?id=1656) appeared as "Definition 4." We think this strengthening is not substantial, but also the current analysis can be generalized to the weaker case by adding a term proportional to the 2nd derivative of $\V$ (or the 2nd moment of the mixing time). We leave out the details for the time being.

\#Definition 2

Let $\upsilon = (\mu,r)$ be a universe and $\gamma,\epsilon \in (0,1)$. A policy $\pi$ is said to be *locally $\epsilon$-sane for $(\upsilon,\gamma)$* when there are $M$, $S$ and $\UC_M \subseteq \St_M$ (the set of uncorrupt states) s.t. $\upsilon$ is an $\Ob$-realization of $M$ with state function $S$, $S(\Estr) \in \UC_M$ and for any $h \in \HD{\mu}$, if $S(h) \in \UC_M$ then

i. $$\forall a \in \Supp{\pi(h)}: \T_M\AP{\UC_M \mid S(h),a} = 1$$

ii. $$\Supp{\pi(h)} \subseteq \A_M^0\left(S(h)\right)$$

iii. $$\exists a \in \A: \pi(a \mid h) > \epsilon,\ \Q_M\AP{S(h),a,\gamma} = \V_M\AP{S(h),\gamma}$$

%$$\exists a \in \A_M^\omega\left(S(h)\right): \pi(a \mid h) > \epsilon$$

***

Note that for $1 - \gamma \ll 1$, the condition $\Q_M\AP{S(h),a,\gamma} = \V_M\AP{S(h),\gamma}$ is equivalent to $a \in \bigcap_{k \in \Nats} \A_M^k(s)$.

We obtain the following regret bound.

\#Theorem 1

There is some $C \in (0,\infty)$ s.t. the following holds.

Consider $\In$ an interface, $\alpha,\epsilon \in (0,1)$ and $\Hy = \{\upsilon^k = (\mu^k,r^k) \in \Upsilon_{\In}\}_{k \in [N]}$ for some $N \in \Nats$. Assume that for each $k \in [N]$, $\sigma^k$ is locally $\epsilon$-sane for $(\upsilon^k,1-\alpha)$. For each $k \in [N]$, let $M^k$ be the corresponding MDP and $\UC^k \subseteq \St_{M^k}$ the corresponding set of uncorrupt states. Assume further that for any $k,j \in \Nats$ and $h \in \HD{\mu^k} \cap \HD{\mu^j}$, if $S^k(h) \in \UC^k$ and $S^j(h) \in \UC^j$, then $r^k(h)=r^j(h)$. Then, there is an $\bar{\In}$-policy $\pi^*$ s.t. for any $k \in [N]$

$$\EU_{\upsilon^k}^*(1-\alpha) - \EU_{\bar{\upsilon}^k\left[\sigma^k\right]}^{\pi^*}(1-\alpha) \leq C\AP{\frac{\alpha N^5 \ln{N} \sum_{j = 0}^{N-1} \max_{s \in \UC_k} \sup_{\gamma \in [1-\alpha,1)} \Abs{\frac{\D\V_{M^j}(s,\gamma)}{\D\gamma}}}{\epsilon}}^{1/4}$$

***

The factor $\max_{s \in \UC_k} \sup_{\gamma \in [1-\alpha,1]} \Abs{\frac{\D\V_{M^j}(s,\gamma)}{\D\gamma}}$ might seem difficult to understand. However, it can be bounded as follows.

\#Proposition 2

Let $M$ be an MDP, $\pi$ a Blackwell optimal policy for $M$ and $F \in (0,\infty)$, $\lambda \in (0,1)$, $\Pd \subseteq \Nats^+$ as in Proposition 1 applied to the Markov chain $\T_{M\pi}$. Then

$$\max_{s \in \St_M} \sup_{\gamma \in (0,1)} \Abs{\frac{\D\V_M(s,\gamma)}{\D\gamma}} = O\AP{\frac{F}{1-\lambda}+\max{\Pd}}$$

***

Theorem 1 and Proposition 2 immediately give the following:

\#Corollary 1

There is some $C' \in (0,\infty)$ s.t. the following holds.

Under the conditions of Theorem 1, let $\pi^k$ be a Blackwell optimal policy for $M^k$ s.t. 

$$\T_{M^k \pi^k}\AP{\UC^k \mid \UC^k} = 1$$ 

Assuming w.l.o.g. all uncorrupt states are reachable from $S^k(\Estr)$, $\pi^k$ is guaranteed to exist thanks to condition iii of Definition 2 (if some uncorrupt state is unreachable, we can consider it to be corrupt.) Let $F^k\in(0,\infty)$, $\lambda^k\in(0,1)$ and $\Pd^k \subseteq \Nats^+$ be as in Proposition 1, for the Markov chain $\T_{M^k\pi^k}: \UC^k \M \UC^k$. Then, there is an $\bar{\In}$-policy $\pi^*$ s.t. for any $k \in [N]$ 

$$\EU_{\upsilon^k}^*(1-\alpha) - \EU_{\bar{\upsilon}^k\left[\sigma^k\right]}^{\pi^*}(1-\alpha) \leq C'\AP{\frac{\alpha N^5 \ln{N} \sum_{j = 0}^{N-1} \AP{\frac{F^j}{1-\lambda^j}+\max{\Pd^j}}}{\epsilon}}^{1/4}$$

\section{Appendix A}

The following appeared in a [previous essay](https://agentfoundations.org/item?id=1723) as "Proposition C.1".

\#Proposition A.N1

Fix an interface $\In=(\A,\Ob)$, $N \in \Nats$, $\epsilon \in (0,\frac{1}{\Abs{\A}})$, $\eta \in (0,\frac{1}{N})$. Consider some $\{\sigma^k: \FH \M \A\}_{k \in [N]}$. Then, there exist $\Dl: \Adfh \times \A \rightarrow \Ada$ and $\{\Dl^{!k}: \Adfh \times \A \rightarrow \Ada\}_{k \in [N]}$ with the following properties. Given $x \in \left(2^\A \times \Adao\right)^*$, we denote $\underline{x}$ its projection to $\Adfh$. Thus, $\underline{\underline{x}}\in\FH$.
Given  $\mu$ an $\In$-environment, $\pi: \HD{\mu} \M \A$, $\Dl': \Adfh \times \A \rightarrow \Ada$ and $k \in [N]$, we can define $\Xi\left[\mu,\sigma^k,\Dl',\pi\right]\in \Delta\left(\A \times \Adao\right)^\omega$ as follows
 
$$\Xi\left[\mu,\sigma^k,\Dl',\pi\right]\left(b,a,o \mid x\right):=\pi\left(b \mid \underline{\underline{x}}\right)\Dl'\left(a \mid \underline{x},b\right) \bar{\mu}[\sigma^k]\left(o \mid \underline{x}a\right)$$

We require that for every $\pi$, $\mu$ and $k$ as above, the following conditions hold

i. $$\E{x \sim\Xi\left[\mu,\sigma^k,\Dl^{!k},\pi\right]}\left[\Abs{\{n \in \Nats \mid x_n \in \A \times \bot \times \bar{\Ob}\}}\right] \leq \frac{\ln N}{\eta \ln\left(1 + \epsilon(1-\epsilon)^{(1-\epsilon)/\epsilon}\right)}=O\left(\frac{\ln N}{\eta \epsilon}\right)$$

ii. $\Dtv\left(\frac{1}{N}\sum_{j=0}^{N-1}{\Xi\left[\mu,\sigma^j,\Dl,\pi\right]},\frac{1}{N}\sum_{j=0}^{N-1}{\Xi\left[\mu,\sigma^j,\Dl^{!j},\pi\right]}\right) \leq (N-1)\eta$

iii. For all $x \in \HD{\bar{\mu}[\sigma^k]}$, if $\Dl^{!k}\left(x,\pi\left(\underline{x}\right)\right) \ne \bot$ then $\sigma^k\left(\Dl^{!k}\left(x,\pi\left(\underline{x}\right)\right) \mid \underline{x}\right) > 0$

iv. For all $x \in \HD{\bar{\mu}[\sigma^k]}$, if $\Dl^{!k}\left(x,\pi\left(\underline{x}\right)\right) \not\in \AC{\pi\left(\underline{x}\right), \bot}$ then $\sigma^k\left(\pi\left(\underline{x}\right) \mid \underline{x}\right) \leq \epsilon$

***

The following is a simple special case??? of what appeared there as "Proposition B.2".

\#Proposition A.N2

Consider some $\tau\in(0,\infty)$, $T\in\Nats^+$, a universe $\upsilon=(\mu,r)$ that is an $\Ob$-realization of $M$ with state function $S$ and an arbitrary $\In$-policy $\pi^0: \FH \M \A$. Let $\pi^*$ be a Blackwell optimal policy for $M$, and for any $n \in \Nats$, let $\pi^*_n$ be an $\In$-policy s.t. for any $h \in \HD{\mu}$

$$\pi^*_n(h):=\begin{cases} \pi^0(h) \text{ if } \Abs{h} < nT \\ \pi^*\AP{S(h)} \text{ otherwise} \end{cases}$$

Assume that

i. For any $h \in \HD{\mu}$ $$\Supp{\pi^0(h)} \subseteq \A_{M\pi^*}^0\AP{S(h)}$$

ii. For any $s \in \St_M$ and $\gamma\in(0,1)$??? $$\Abs{\frac{\D\V_{M}\AP{s,\gamma}}{\D\gamma}} \leq \tau$$

Then, for any $\gamma\in(0,1)$ s.t. $1-\gamma \ll 1$,

$$\EU^{*}_\upsilon(\gamma)-\EU^{\pi^0}_\upsilon(\gamma) \leq (1-\gamma)\sum_{n=0}^\infty \sum_{m=0}^{T-1} \gamma^{nT+m}\left(\E{x\sim\mu\bowtie\pi^*_n}\left[r\left(x_{:nT+m}\right)\right]-\E{x\sim\mu\bowtie\pi^0}\left[r\left(x_{:nT+m}\right)\right]\right) + \frac{2\tau\gamma^T(1-\gamma)}{1-\gamma^T}$$

***

?

\#Proposition A.N3

\#Proof of Theorem 1

TBD

\end{document}



