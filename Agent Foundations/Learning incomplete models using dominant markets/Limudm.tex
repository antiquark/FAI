%&latex
\documentclass[a4paper]{article}

\usepackage[a4paper,margin=1in]{geometry}
\usepackage[affil-it]{authblk}
\usepackage{cite}
\usepackage[unicode]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{commath}

\newcommand{\Comment}[1]{}

\newcommand{\Bool}{\{0,1\}}
\newcommand{\Words}{{\Bool^*}}

% operators that are separated from the operand by a space
\DeclareMathOperator{\Sgn}{sgn}
\DeclareMathOperator{\Supp}{supp}
\DeclareMathOperator{\Stab}{stab}
\DeclareMathOperator{\Img}{Im}

% operators that require brackets
\DeclareMathOperator{\Prb}{Pr}
\DeclareMathOperator{\E}{E}
\newcommand{\EE}[2]{\operatorname{E}_{\substack{#1 \\ #2}}}
\newcommand{\EEE}[3]{\operatorname{E}_{\substack{#1 \\ #2 \\ #3}}}
\DeclareMathOperator{\Var}{Var}

% operators that require parentheses
\DeclareMathOperator{\Ent}{H}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Sym}{Sym}

\DeclareMathOperator{\Prj}{pr}

\newcommand{\KL}[2]{\operatorname{D}_{\mathrm{KL}}(#1 \| #2)}
\newcommand{\Dtv}{\operatorname{d}_{\text{tv}}}

\newcommand{\Argmin}[1]{\underset{#1}{\operatorname{arg\,min}}\,}
\newcommand{\Argmax}[1]{\underset{#1}{\operatorname{arg\,max}}\,}

\newcommand{\Nats}{\mathbb{N}}
\newcommand{\Ints}{\mathbb{Z}}
\newcommand{\Rats}{\mathbb{Q}}
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\Coms}{\mathbb{C}}

\newcommand{\Sq}[2]{\{#1\}_{#2 \in \Nats}}
\newcommand{\Sqn}[1]{\Sq{#1}{n}}

\newcommand{\Estr}{\boldsymbol{\lambda}}

\newcommand{\Lim}[1]{\lim_{#1 \rightarrow \infty}}
\newcommand{\LimInf}[1]{\liminf_{#1 \rightarrow \infty}}
\newcommand{\LimSup}[1]{\limsup_{#1 \rightarrow \infty}}

\newcommand{\Abs}[1]{\lvert #1 \rvert}
\newcommand{\Norm}[1]{\lVert #1 \rVert}
\newcommand{\Floor}[1]{\lfloor #1 \rfloor}
\newcommand{\Ceil}[1]{\lceil #1 \rceil}
\newcommand{\Chev}[1]{\langle #1 \rangle}
\newcommand{\Quote}[1]{\ulcorner #1 \urcorner}

\newcommand{\Alg}{\xrightarrow{\textnormal{alg}}}
\newcommand{\Markov}{\xrightarrow{\textnormal{mk}}}

\newcommand{\Prob}{\mathcal{P}}

% Paper specific

\newcommand{\Ob}{\mathcal{O}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\UM}{\mathcal{U}}
\newcommand{\W}{\operatorname{W}}
\newcommand{\SW}{\operatorname{\Sigma W}}
\newcommand{\I}{\operatorname{id}}
\newcommand{\Lip}{\operatorname{Lip}}
\newcommand{\NormL}[1]{\Norm{#1}_{\operatorname{Lip}}}
\newcommand{\Dkr}{\operatorname{d}_{\text{KR}}}
\newcommand{\Ball}{\operatorname{B}}
\newcommand{\F}{\mathcal{F}}

\begin{document}

*This post is formal treatment of the idea outlined [here](https://agentfoundations.org/item?id=1197).*

Given a countable set of [incomplete models], we define a forecasting function that converges in the Kantorovich-Rubinstein metric with probability 1 to every one of the models which is satisfied by the true environment. This is analogous to Blackwell-Dubins [merging of opinions](https://projecteuclid.org/euclid.aoms/1177704456), for complete models, except that Kantorovich-Rubinstein convergence is weaker than convergence in total variation. The forecasting function is a [dominant stochastic market](https://agentfoundations.org/item?id=1327) for a suitably constructed set of traders.

***

Appendix A contains the proofs of key lemmas and theorems. Appendix B contains the proofs of technical propositions used in Appendix A, which are mostly straightforward. Appendix C restates the theorems about dominant stochastic markets for ease of reference. Appendix D states a variant of the Michael selection theorem due to Yannelis and Prabhakar which is used in Appendix A.

\section{Notation}

Given ${X}$ a metric space, ${x \in X}$ and $r \in \Reals$, ${\Ball_r(x):=\{y \in X \mid d(x,y) < r\}}$.

Given ${X}$ a topological space:

* ${\I_X: X \rightarrow X}$ is the identity mapping.

* ${\Prob(X)}$ is the space of Borel probability measures on ${X}$ equipped with the weak* topology.

* ${C(X)}$ is the Banach space of continuous functions ${X \rightarrow \Reals}$ with uniform norm.

* $\T(X):= C(\Prob(X) \times X)$

* ${\mathcal{B}}(X)$ is the Borel ${\sigma}$-algebra on ${X}$.

* ${\UM(X)}$ is the ${\sigma}$-algebra of universally measurable sets on ${X}$.

* Given ${\mu \in \Prob(X)}$, ${\Supp \mu}$ denotes the support of ${\mu}$. 

Given ${X}$ and ${Y}$ measurable spaces, ${K: X \Markov\ Y}$ is a Markov kernel from ${X}$ to ${Y}$. For any ${x \in X}$, we have ${K(x) \in \Prob(Y)}$. Given ${\mu \in \Prob(X)}$, ${\mu \ltimes K \in \Prob(X \times Y)}$ is the semidirect product of ${\mu}$ and ${K}$ and ${K_*\mu \in \Prob(Y)}$ is the pushforward of ${\mu}$ by ${K}$.

Given ${X}$, ${Y}$ Polish spaces, ${\pi: X \rightarrow Y}$ Borel measurable and ${\mu \in \Prob(X)}$, we denote ${\mu \mid \pi}$ the set of Markov kernels ${K: Y \Markov X}$ s.t. ${\pi_* \mu \ltimes K}$ is supported on the graph of ${\pi}$ and ${K_*\pi_* \mu = \mu}$. By the disintegration theorem, ${\mu \mid \pi}$ is always non-empty and any two kernels in ${\mu \mid \pi}$ coincide ${\pi_*\mu}$-almost everywhere.

\section{Results}

Consider ${X}$ any compact Polish metric space and ${d: X \times X \rightarrow \Reals}$ its metric. We denote ${\Lip(X)}$ the Banach space of Lipschitz continuous functions ${X \rightarrow \Reals}$ with the norm

$$\NormL{f}:=\max_{x} \Abs{f(x)} + \sup_{x \ne y}\frac{\Abs{f(x)-f(y)}}{d(x,y)}$$

${\Prob(X)}$ (as before, with the weak topology) can be regarded as a compact subset of ${\Lip(X)'}$ (with the strong topology), yielding a metrization of ${\Prob(X)}$ which we will call the Kantorovich-Rubinstein metric ${\Dkr}$:

$$\Dkr(\mu,\nu):=\sup_{\NormL{f} \leq 1} \Abs{\E_\mu[f] - \E_\nu[f]}$$

In fact, the above differs from the standard definition of the Kantorovich-Rubinstein metric (a.k.a. 1st Wasserstein metric, a.k.a. earth's mover metric), but this abuse of terminology is mild since the two are strongly equivalent.

Now consider ${\Phi \subseteq \Prob(X)}$ convex. We will describe a class of trading strategies that are designed to exploit any ${\mu \in \Phi}$.

\#Definition N6

${\tau \in \T(X)}$ is said to be *profitable for ${\Phi}$* when for all ${\mu \in \Prob(X)}$, ${\nu \in \Phi}$ we have

$$\E_\nu[\tau(\mu)] \geq \E_\mu[\tau(\mu)] + \Dkr(\mu,\Phi)^2$$

(The fact that $\Dkr$ appears squared in this equation is somewhat arbitrary. Other choices are possible.)

\#Lemma N4

Consider ${Y}$ another compact Polish space and ${\Phi \subseteq Y \times \Prob(X)}$ closed. For any ${y \in Y}$, define ${\Phi_y \subseteq \Prob(X)}$ by

$${\Phi_y := \{\mu \in \Prob(X) \mid (y,\mu) \in \Phi\}}$$ 

Assume that for any ${y \in Y}$, ${\Phi_y}$ is convex. Then, there exists ${\upsilon: Y \rightarrow \T(X)}$ measurable w.r.t. ${\UM(Y)}$ and ${\B(\T(X))}$ s.t. for all ${y \in Y}$, ${\Norm{\upsilon(y)} \leq 2}$ and ${\upsilon(y)}$ is profitable for ${\Phi_y}$ (instead of 2, the norm can be bounded by ${1+\epsilon}$ for any ${\epsilon > 0}$, but for our purposes any uniform bound is sufficient).

***

For each ${n \in \Nats}$, let ${\Ob_n}$ be a compact subset of $\Reals^{D(n)}$ ($D: \Nats \rightarrow \Nats$ is arbitrary). Denote 

$${Y_n:=\prod_{m < n} \Ob_m}$$

${Y_n}$ is a compact subset of ${\Reals^{\sum_{m < n} D(m)}}$. We will regard it as equipped with the Euclidean metric. Given ${n \leq m}$, ${\pi_{nm}: Y_m \rightarrow Y_n}$ denotes the projection mapping. Denote 

$${X = \prod_{n = 0}^\infty \Ob_n}$$

${X}$ is a compact Polish space. For each ${n \in \Nats}$ we denote ${\pi_{n}: X \rightarrow Y_n}$ the projection mapping. Given ${y \in Y_n}$, we denote ${X_y:=\pi_{n}^{-1}(y)}$, a closed subspace of ${X}$. Given $n \in \Nats$ and $x \in X$, we have $x(n):=\pi_{n}(x) \in Y_n$ and $x_n \in \Ob_n$.

The following definition provides a notion of updating an incomplete model by observations:

\#Definition N7

Consider ${\Phi \subseteq \Prob(X)}$. For any ${n \in \Nats}$ and ${y \in Y_n}$, we define ${\Phi_y'' \subseteq \Prob(X)}$ by

$$\Phi_y'':=\{\lim_{r \rightarrow 0} (\mu \mid \pi_{n}^{-1}(\Ball_r(y))) \mid \mu \in \Phi\}$$

Note that the limit in the definition above need not exist for every ${\mu \in \Phi}$.

Denote ${\Phi_y'}$ the convex hull of ${\Phi_y''}$ and define ${\Phi_n' \subseteq Y_n \times \Prob(X)}$ by

$$\Phi_n':=\{(y,\mu) \in Y_n \times \Prob(X) \mid \mu \in \Phi_y'\}$$

Finally, we define ${\Phi_n \subseteq Y_n \times \Prob(X)}$ to be the closure of ${\Phi_n'}$. Given ${y \in Y_n}$, we define ${\Phi_y \subseteq \Prob(X)}$ by

$$\Phi_y:=\{\mu \in \Prob(X) \mid (y,\mu) \in \Phi_n\}$$

***

Note that the above definition uses the Euclidean metric on ${Y_n}$. This is the only place through which the assumption that ${\Ob_n}$ is a compact subset of ${R^{D(n)}}$ (rather than an arbitrary compact Polish space) enters. This is used the in the proof of Lemma N5 below, via the Lebesgue differentiation theorem.

Fix a family of metrizations of ${X}$: ${\{d_n: X \times X \rightarrow \Reals\}_{n \in \Nats}}$. The reason we need a family rather than a single metric is that convergence in ${\Dkr}$ is trivial unless we renormalize the metric for each ${n}$. On the other hand, completely arbitrary renormalization is allowed. For example, assuming the diameters of $\Ob_n$ are uniformly bounded, we can take 

$$d_n(x^1,x^2)= \max_{m \in \Nats} c_{nm} d(x^1_m,x^2_m)$$

Here, ${\{c_{nm} > 0\}_{n,m \in \Nats}}$ are required to satisfy ${\lim_{m \rightarrow \infty} c_{nm} = 0}$. To get a non-trivial result, we need the ${c_{nm}}$ to fall slower with ${m}$ as ${n}$ increases. The stronger we make this trend, the stronger conclusion we get (although it always remains weaker than convergence in total variation).

\#Lemma N5

Consider ${\Phi \subseteq \Prob(X)}$ and ${\epsilon > 0}$. For every ${n \in \Nats}$, denote ${\Dkr^n}$ the Kantorovich-Rubinstein metric associated with ${d_n}$. Define ${\Phi_n^\epsilon \subseteq Y_n \times \Prob(X)}$ by 

$$\Phi_n^\epsilon:=\{(y,\mu) \in Y_n \times \Prob(X) \mid \Dkr^n(\mu,\Phi_y) \leq \epsilon\}$$

For every ${y \in Y_n}$, we define ${\Phi^\epsilon_y \subseteq \Prob(X)}$ by

$$\Phi^\epsilon_y:=\{\mu \in \Prob(X) \mid (y,\mu) \in \Phi^\epsilon_n\}$$

Let ${\upsilon}$ be a metastrategy s.t. for each ${n \in \Nats}$ and ${y \in Y_n}$, ${\upsilon_n(y)}$ is profitable for ${\Phi^\epsilon_y}$. Then, ${\upsilon}$ is profitable for any ${\mu^* \in \Phi}$.

***

Combining Theorem N2 and Lemma N5, it is easy to get the following:

\#Corollary N6

Consider ${\Phi \subseteq \Prob(X)}$, ${\epsilon > 0}$ and ${\upsilon}$ a metastrategy s.t. for each ${n \in \Nats}$ and ${y \in Y_n}$, ${\upsilon_n(y)}$ is profitable for ${\Phi^\epsilon_y}$. Let ${M}$ be a market which dominates ${T_\upsilon}$. Then, for any ${\mu^* \in \Phi}$ and ${\mu^*}$-almost any ${x \in X}$:

$$\limsup_{n \rightarrow \infty} \Dkr^n(M_n(x(n)),\Phi_{x(n)}) \leq \epsilon$$

***

Thus, if we construct a set of traders ${T_{\upsilon_k}}$ as in Corollary N6 where ${\upsilon_k}$ corresponds to ${\epsilon=\frac{1}{k}}$, then a market dominating all of these traders would have to converge to ${\Phi_{y_n}}$ with ${\mu^*}$-probability 1. Putting this together with Lemma N4 (so that ${\upsilon_k}$ as above actually exists) and Theorem N1 we finally get

\#Theorem N7

Consider any ${H \subseteq 2^{\Prob(X)}}$ countable. Then, there exists a market ${M^H}$ s.t. for any ${\Phi \in H}$, ${\mu^* \in \Phi}$ and ${\mu^*}$-almost any ${x \in X}$:

$$\lim_{n \rightarrow \infty} \Dkr^n(M^H_n(x(n)),\Phi_{x(n)}) = 0$$

***

This leaves an interesting open question, namely whether the counterpart of Theorem N7 with ${\Dkr}$ replaced by total variation distance is true.

\section{Appendix A}

TBD

\section{Appendix B}

TBD

\section{Appendix C}

The following are the theorems about dominant stochastic markets proven [before](https://agentfoundations.org/item?id=1327).

\#Theorem N1

Given any countable set of traders $R$, there is a market ${M}$ s.t. ${M}$ dominates all ${T \in R}$.

\#Theorem N2

Consider ${\mu^* \in \Prob(X)}$, ${\{K_n \in \mu^* \mid \pi_{n}\}_{n \in \Nats}}$, ${\upsilon}$ a trading metastrategy profitable for ${\mu^*}$ and ${M}$ a market. Assume ${M}$ dominates ${T_\upsilon}$. Then, for ${\mu^*}$-almost any ${x \in X}$:

$$\lim_{n \rightarrow \infty} (\E_{K_n(x(n))}[\upsilon(x(n),M_n(x(n)))]-\E_{M_n(x(n))}[\upsilon(x(n),M_n(x(n)))])= 0$$

\section{Appendix D}

The following theorem appears in [Yannelis and Prabhakar]\Comment{(https://www.biz.uiowa.edu/faculty/nyannelis/publications/Existence_of_Maximal_Elements_and_Equilibria_in_Linear_Topological_Spaces.pdf)} as Theorem 3.1.

\#Theorem N3

Consider $X$ a paracompact Hausdorff topological space and $Y$ a topological vector space. Suppose $F: X \rightarrow 2^Y$ is s.t.

(i) For each $x \in X$, $F(x) \ne \varnothing$.

(ii) For each $x \in X$, $F(x)$ is convex.

(iii) For each $y \in Y$, $\{x \in X \mid y \in F(x)\}$ is open.

Then, there exists $f: X \rightarrow Y$ continuous s.t. for all $x \in X$, $f(x) \in F(x)$.

\end{document}

