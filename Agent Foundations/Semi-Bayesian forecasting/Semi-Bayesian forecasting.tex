%&latex
\documentclass[a4paper]{article}

\usepackage[a4paper,margin=1in]{geometry}
\usepackage[affil-it]{authblk}
\usepackage{cite}
\usepackage[unicode]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{commath}
\usepackage{bm}

\newcommand{\Bool}{\{0,1\}}
\newcommand{\Words}{{\Bool^*}}

% operators that are separated from the operand by a space
\DeclareMathOperator{\Sgn}{sgn}
\DeclareMathOperator{\Supp}{supp}
\DeclareMathOperator{\Stab}{stab}
\DeclareMathOperator{\Img}{Im}

% operators that require brackets
\DeclareMathOperator{\Prb}{Pr}
\DeclareMathOperator{\E}{E}
\newcommand{\EE}[2]{\operatorname{E}_{\substack{#1 \\ #2}}}
\newcommand{\EEE}[3]{\operatorname{E}_{\substack{#1 \\ #2 \\ #3}}}
\DeclareMathOperator{\Var}{Var}

% operators that require parentheses
\DeclareMathOperator{\Ent}{H}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Sym}{Sym}

\DeclareMathOperator{\Prj}{pr}

\newcommand{\KL}[2]{\operatorname{D}_{\mathrm{KL}}(#1 \| #2)}
\newcommand{\Dtv}{\operatorname{d}_{\textnormal{tv}}}

\newcommand{\Argmin}[1]{\underset{#1}{\operatorname{arg\,min}}\,}
\newcommand{\Argmax}[1]{\underset{#1}{\operatorname{arg\,max}}\,}

\newcommand{\Nats}{\mathbb{N}}
\newcommand{\Ints}{\mathbb{Z}}
\newcommand{\Rats}{\mathbb{Q}}
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\Coms}{\mathbb{C}}

\newcommand{\Estr}{\bm{\lambda}}

\newcommand{\Lim}[1]{\lim_{#1 \rightarrow \infty}}
\newcommand{\LimInf}[1]{\liminf_{#1 \rightarrow \infty}}
\newcommand{\LimSup}[1]{\limsup_{#1 \rightarrow \infty}}

\newcommand{\Abs}[1]{\lvert #1 \rvert}
\newcommand{\Norm}[1]{\lVert #1 \rVert}
\newcommand{\Floor}[1]{\lfloor #1 \rfloor}
\newcommand{\Ceil}[1]{\lceil #1 \rceil}
\newcommand{\Chev}[1]{\langle #1 \rangle}
\newcommand{\Quote}[1]{\ulcorner #1 \urcorner}

\newcommand{\Alg}{\xrightarrow{\textnormal{alg}}}
\newcommand{\Markov}{\xrightarrow{\textnormal{mk}}}

\newcommand{\Prob}{\mathcal{P}}

% Paper specific

\newcommand{\Act}{\mathcal{A}}
\newcommand{\Obs}{\mathcal{O}}
\newcommand{\ObsO}{\Obs^\omega}
\newcommand{\Pol}{\Obs^* \rightarrow \Act}
\newcommand{\CC}{\mathcal{P}_{\operatorname{C}}}

\begin{document}

*This post continues the research programme of attacking the grain of truth problem by departure from the Bayesian paradigm. In the [previous post](https://agentfoundations.org/item?id=1046), I suggested using Savage's minimax regret decision rule, but here I fall back to the simple minimax decision rule. This is because the mathematics is considerably simpler, and minimax should be sufficient to get IUD play in general games and Nash equilibrium in zero-sum two-player games. I hope to build on these results to get analogous results for minimax regret in the future.*

We consider "semi-Bayesian" agents following the minimax expected utility decision rule, in oblivious environments with full monitoring (a setting that we will refer to as "forecasting"). This setting is considered in order to avoid the need to enforce exploration, as a preparation for analysis of general environments. We show that such agents satisfy a certain asymptotic optimality theorem. Intuitively, this theorem means that whenever the environment satisfies an incomplete model that is included in the prior, the agent will eventually learn this model i.e. extract at least as much utility as can be guaranteed for this model.

The proofs are in Appendix A.

\section{Notation}

Given ${X}$ a topological space, ${\Prob(X)}$ will denote the space of Borel probability measures on ${X}$. We regard it as a topological space using the weak${^*}$ topology. We denote ${\CC(X)}$ the set of non-empty convex closed subsets of ${\Prob(X)}$.

Given ${\mathcal{X}}$ a finite set, ${\mathcal{X}^*}$ denotes the set of finite strings in alphabet ${\mathcal{X}}$, i.e. ${\mathcal{X}^*:=\bigsqcup_{n \in \Nats} \mathcal{X}^n}$. ${\mathcal{X}^\omega}$ denotes the set of infinite strings in alphabet ${\mathcal{X}}$. Given ${x \in \mathcal{X}^* \sqcup \mathcal{X}^\omega}$, ${\Abs{x} \in \Nats \sqcup \{\infty\}}$ is the length of string. Given ${0 \leq n < \Abs{x}}$, ${x_n \in \mathcal{X}}$ is the ${n}$-th symbol in ${x}$. Given ${0 \leq n \leq \Abs{x}}$, ${x_{<n}}$ is the prefix of ${x}$ of length ${n}$. Given ${x,y \in \mathcal{X}^* \sqcup \mathcal{X}^\omega}$, the notations ${x \sqsubset y}$, ${x \sqsubseteq y}$, ${x \not\sqsubset y}$ and ${x \not\sqsubseteq y}$ mean "${x}$ is a proper prefix of ${y}$", "${x}$ is a prefix of ${y}$" and their negations. ${\Estr_\mathcal{X} \in \mathcal{X}^*}$ is the empty string and ${\mathcal{X}^{+}:=\mathcal{X}^* \setminus \Estr_\mathcal{X}}$. 

\section{Elementary properties of minimax}

Fix ${S}$ and ${E}$ compact Polish spaces, ${S}$ representing the agent's pure policies and ${E}$ representing the pure environments. Let ${u: S \times E \rightarrow \Reals}$ be a continuous utility function.

\subsection{Proposition 1}

Consider ${\Phi \subseteq \Prob(E)}$. There exists 

$${\pi^* \in \Argmax{\pi \in \Prob(S)} \inf_{\mu \in \Phi} \E_{\rho \times \mu}[u]}$$

Moreover, let ${\bar{\Phi}}$ be the closure of the convex hull of ${\Phi}$. Then, the same ${\rho^*}$ satisfies

$${\pi^* \in \Argmax{\pi \in \Prob(S)} \min_{\mu \in \bar{\Phi}} \E_{\rho \times \mu}[u]}$$

We will say that such a ${\pi^*}$ is a *minimax policy for ${\Phi}$*.

\subsection{Proposition 2}

Consider ${\Phi, \Phi' \in \CC(E)}$ and ${p \in [0,1]}$. Then, there is ${\nu^* \in \Phi'}$ s.t. any minimax policy for ${p\Phi+(1-p)\Phi'}$ is a minimax policy for ${p\Phi+(1-p)\nu^*}$.

***

In particular, Proposition 2 implies that a minimax policy for ${\Phi}$ is the optimal policy for some ${\mu^* \in \Phi}$.

Now we ask what policy is implemented by "subagents" created by a minimax policy. Suppose ${S = S_1 \times S_2}$, where ${S_2}$ represents the pure policies of the subagent. Assume that there is a Borel set ${A \subseteq E}$ (the condition for the creation of the subagent), a finite set ${T}$ (the part of the policy executed before the creation of the subagent), a Borel measurable mapping ${\alpha: S_1 \rightarrow T}$ and continuous functions ${u_1: S_1 \times E \rightarrow \Reals}$ and ${u_2: S_2 \times T \times E \rightarrow \Reals}$ s.t. 

$${u(s_1,s_2,e)=u_1(s_1,e)+\chi_A(e) u_2(s_2,\alpha(s_1),e)}$$

Consider ${\Phi \in \CC(E)}$ and ${\pi^* \in \Prob(S)}$ minimax for ${\Phi}$. Denote ${\Prj_{1,2}: S \rightarrow S_{1,2}}$ the projection mappings. Define ${\pi_1^* \in \Prob(S_1)}$ by

$$\pi_1^* := \Prj_{1*}\pi^*$$

Define ${\pi_2^*: T \rightarrow \Prob(S_2)}$ by

$$\pi_2^*(t) := \Prj_{2*} (\pi^* \mid \alpha^{-1}(t) \times S_2)$$

\subsection{Proposition 3}

$$\pi_2^* \in \Argmax{\pi_2: T \rightarrow \Prob(S_2)} \min_{\mu \in \Phi} (\E_{\pi_1^* \times \mu}[u_1] + \mu(A) \E_{t \sim \alpha_*\pi_1^*}[\E_{\pi_2^*(t) \times \mu}[u_2(t)]])$$

***

At this point, it should be possible to make do without ${T}$ and the associated decomposition of ${u}$ by instead decomposing ${\pi^*}$ into ${\pi_1^*}$ and a Markov kernel from ${S_1}$ to ${S_2}$. However, we won't need the general case.

In general, ${\pi_2^*}$ is not a minimax policy for any natural model i.e. the minimax decision rule is not "dynamically consistent". However, if we assume a certain factorization condition, it is. Specifically, assume ${E_1, E_2}$ are compact Polish, ${f: E_1 \times E_2 \rightarrow E}$ is Borel measurable, ${\bar{u}_1: S_1 \times E_1 \rightarrow \Reals}$ and ${\bar{u}_2: S_2 \times T \times E_2 \rightarrow \Reals}$ are continuous s.t. 

$${u_1(s_1,f(e_1,e_2))=\bar{u}_1(s_1,e_1)}$$

$${u_2(s_2,t,f(e_1,e_2))=\bar{u}_1(s_2,t,e_2)}$$

Further assume that ${A_1 \subseteq E_1}$ is Borel s.t. ${f^{-1}(A) = A_1 \times E_2}$ and ${\Phi_{1,2} \in \CC(E_{1,2})}$ are s.t. ${\Phi}$ is the closure of the convex hull of ${f(\Phi_1 \times \Phi_2)}$.

\subsection{Proposition 4}

$$\pi_2^* \in \Argmax{\pi_2: T \rightarrow \Prob(S_2)} \min_{\mu \in \Phi_2} \E_{t \sim \alpha_*\pi_1^*}[\E_{\pi_2^*(t) \times \mu}[\bar{u}_2(t)]]$$

Moreover, define ${\bar{S}_2:=T \rightarrow S_2}$ equipped with the product topology, define ${\bar{\pi}_2^* \in \Prob(\bar{S}_2)}$ by

$${\bar{\pi}_2^* := \prod_{t \in T} \pi_2^*(t)}$$

Define ${\bar{E}_2:=T \times E_2}$ and define ${\bar{\Phi}_2 \in \CC(\bar{E}_2)}$ by

$$\bar{\Phi}_2:=\{\alpha_* \pi_1^* \times \mu \mid \mu \in \Phi_2\}$$

Finally, define ${\hat{u}_2: \bar{S}_2 \times \bar{E}_2 \rightarrow \Reals}$ by

$$\hat{u}_2(s,t,e):=\bar{u}_2(s(t),t,e)$$

Then, ${\bar{\pi}_2^*}$ is a minimax policy for ${\bar{\Phi}_2}$ w.r.t. the utility function ${\hat{u}_2}$.

\section{Asymptotic optimality}

Fix finite sets ${\Act}$ (actions) and ${\Obs}$ (observations). We now assume that ${E=\ObsO}$ and ${S=\Pol}$ with the product topology. We fix ${\gamma: \Nats \rightarrow \Reals^{\geq 0}}$ a time discount function satisfying ${\sum_n \gamma(n) < \infty}$ and ${r: (\Act \times \Obs)^* \rightarrow \Reals}$ a bounded reward function. Given ${e \in E}$ and ${s \in S}$, we define ${e^s \in (\Act \times \Obs)^\omega}$ by

$${e^s_n:=(s(e_{<n}),e_n)}$$

The utility function is then given by

$$u(s,e)=\sum_{n \in \Nats} \gamma(n) r(e^s_{<n})$$

We will need a notation for a combination of two policies where the agent switches for one to another when observing some ${x \in \Obs^*}$. Given ${n \in \Nats}$, ${s: \Pol}$, ${x \in \Obs^n}$ and ${t: \Act^n \times \Pol}$, we define ${s \otimes_x t: \Pol}$ by

$$(s \otimes_x t)(y):=\begin{cases}s(y) \text{ if } y \not\sqsupseteq x \\t(s(\Estr_\Obs),s(x_{<1}), s(x_{<2}) \ldots s(x_{<{n-1}}),z) \text{ if } y=xz\end{cases}$$

Given ${\pi \in \Prob(\Pol)}$ and ${\rho \in \Prob(\Act^n \times \Pol)}$, ${\pi \otimes_x \rho \in \Prob(\Pol)}$ is defined as the pushforward of the operation above.

Note that changing the policy after a certain event cannot change utility more than the probability of the event times the corresponding time discount factor. That is, we have the following:

\subsection{Proposition 5}

$$\Abs{\E_{(\pi \otimes_x \rho) \times \mu}[u]-\E_{\pi \times \mu}[u]} \leq (\sup r - \inf r) \Prb_{e \sim \mu}[x \sqsubset e] \sum_{n = \Abs{x}}^\infty \gamma(n)$$

***

We are now ready to formulate the optimality theorem. Consider ${\Phi,\Phi' \in \CC(\ObsO)}$ and ${p \in [0,1]}$. Denote ${\Psi = p \Phi + (1-p) \Phi'}$. We think of ${\Psi}$ as the prior, ${\Phi}$ as one of the models in the prior (assigned probability ${p}$) and ${\Phi'}$ as the convex combination of all other models. Let ${\pi^* \in \Prob(\Pol)}$ be a minimax policy for ${\Psi}$. Define ${v: \Obs^* \rightarrow \Reals}$ by

$$v(x):=\max_{\rho \in \Prob(\Act^{\Abs{x}} \times \Obs^* \rightarrow \Act)} \min_{\mu \in \Phi} \E_{(\pi^* \otimes_x \rho) \times \mu}[u]$$

That is, ${v}$ is the expected utility that can be guaranteed by changing the policy following ${x}$, assuming that the true environment is in ${\Phi}$. We claim that if the true environment is in ${\Phi}$, then after sufficient time ${\pi^*}$ will achieve at least as much utility as can be guaranteed for ${\Phi}$ (guaranteed under the constraint of following ${\pi^*}$ until the point of making the current observations). That is, ${v}$ can only be greater than ${\E_{\pi^* \times \mu}[u]}$ by a quantity that goes to 0 with probability 1, even after normalizing according to Proposition~5:

\subsection{Theorem}

$$\forall \mu \in \Phi: \Prb_{e \sim \mu}[\lim_{n \rightarrow \infty} \max(\frac{v(e_{<n})-\E_{\pi^* \times \mu}[u]}{\Prb_{e' \sim \mu}[x \sqsubset e'] \sum_{m = n}^\infty \gamma(m)},0)=0] = 1$$

***

Compared to the Bayesian case, ${v(x)}$ has the strange property that its definition depends on rewards other than those received after observing ${x}$. This is a direct consequence of the dynamic inconsistency of minimax. In order to get an asymptotic optimality property without this dependence, we need the model to satisfy a factorization condition similar to Proposition 4.

\subsection{Definition}

Consider ${\Phi \in \CC(\ObsO)}$ and ${x \in \Obs^*}$. Define ${f_x: \ObsO \times \ObsO \rightarrow \ObsO}$ by

$${f_x(e_1,e_2):=\begin{cases}e_1 \text{ if } x \not\sqsubset e_1 \\xe_2 \text{ if } x \sqsubset e_1\end{cases}}$$

${\Phi}$ is said to *factorize at ${x}$* when there are ${\Phi_1, \Phi_2 \subseteq \Prob(\ObsO)}$ s.t. ${\Phi}$ is the closure of the convex hull of ${f_x(\Phi_1 \times \Phi_2)}$.

Given ${e \in \ObsO}$, ${\Phi}$ is said to *factorize over ${e}$* when there are infinitely many ${n \in \Nats}$ s.t. ${\Phi}$ factorizes at ${e_{<n}}$.

Given a time discount function ${\gamma}$, ${\Phi}$ is said to *factorize frequently over ${e}$* (w.r.t. ${\gamma}$) when there is an increasing sequence ${\{n_k \in \Nats\}_{k \in \Nats}}$ s.t.

i. ${\Phi}$ factorizes at ${e_{<n_k}}$ for all ${k}$.

ii. There is ${\epsilon > 0}$ s.t. for all ${k}$

$$\frac{\sum_{n = n_{k+1}-1}^\infty \gamma(n)}{\sum_{n = n_{k}}^\infty \gamma(n)} > \epsilon$$

For example, for geometric discount (${\gamma(n)=\beta^n)}$, condition ii means that ${n_{k+1}-n_k}$  is bounded.

${\Phi}$ is said to *factorize everywhere* when 

$${\forall \mu \in \Phi: \Prb_{e \sim \mu}[\Phi \text{ factorizes over } e] = 1}$$

${\Phi}$ is said to *factorize frequently everywhere* (w.r.t. ${\gamma}$) when

$${\forall \mu \in \Phi: \Prb_{e \sim \mu}[\Phi \text{ factorizes frequently over } e] = 1}$$

***

Note that any singleton ${\{\mu\}}$ factorizes frequently everywhere w.r.t. any time discount function. More generally, we can give the following explicit description of models that factorize everywhere:

\subsection{Construction}

Consider any ${F: \Obs^* \rightarrow \CC(\Obs^+)}$ (${\Obs^+}$ is considered to be a discrete space). Assume that for any ${x \in \Obs}$, there is ${A_x \subseteq \Obs^+}$ prefix-free s.t. any ${\mu \in F(x)}$ is supported on ${A_x}$.

We define ${X_F \subseteq \Obs^*}$ as the minimal set with the following properties:

i. ${\Estr_\Obs \in X_F}$

ii. If ${x \in X_F}$, ${\mu \in F(x)}$ and ${y \in \Obs^+}$ is s.t. ${\mu(y) > 0}$, then ${xy \in X_F}$.

We define ${\Phi_F \subseteq \Prob(\ObsO)}$ as follows. ${\mu \in \Phi_F}$ iff for any ${x \in X_F}$, there is ${\mu_x \in F(x)}$ s.t. for any ${y \in \Obs^+}$, if ${\mu_x(y) > 0}$ then

$$\Prb_{e \sim \mu}[xy \sqsubset e] = \Prb_{e \sim \mu}[x \sqsubset e] \mu_x(y)$$

\subsection{Proposition 6}

For any ${F}$ as above, ${\Phi_F \in \CC(\ObsO)}$ and factorizes everywhere.

***

It is also easy to use the above construction to get ${\Phi}$ that factorizes frequently everywhere w.r.t. given ${\gamma}$ (for example, if we require that for every ${x \in X_F}$, ${F(x)}$ is supported on strings of uniformly bounded length, ${\Phi_F}$ will factorize frequently everywhere w.r.t. geometric discount; this condition on ${F}$ is sufficient but not necessary).

Now consider again ${\Phi}$, ${\Psi}$ and ${\pi^*}$ as before.

\subsection{Corollary}

Assume ${\Phi}$ factorizes everywhere.

$$\forall \mu \in \Phi: \Prb_{e \sim \mu}[\lim_{n \rightarrow \infty} \max(\frac{v(e_{<n})-\E_{\pi^* \times \mu}[u]}{\Prb_{e' \sim \mu}[x \sqsubset e'] \sum_{m = n}^\infty \gamma(m)},0)=0] = 1???$$

TBD

%##Appendix
\section{Appendix A}

Bar

\section{Appendix B}

Moo

\end{document}


